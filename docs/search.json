[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kiki",
    "section": "",
    "text": "In summer 2010, I was walking by the (now closed) pet store in Williamsburg, Brooklyn, and I fell in love with a puppy in the window. There was something about her and somehow I knew right away that she was special and that I needed to get her right that second. She was the best impulse purchase of my life and she turned out to be the most amazing, lovable and gentle creature one could imagine. Kiki was absolutely perfect and we loved her more than anything.\n    She moved with us across country (and then came back), flew on a plane to visit her grandparents in Arizona for Christmases and birthdays, and traveled internationally (OK, we drove with her to Canada a few times, but it still counts). When she got sick and could not longer walk far, we got a stroller to take her on walks because she loved being outside and she loved people watching. She was a fighter - once she was given 6 months to live and she made it into 2 years and we fought for her each and every extra day.\n    It’s been 1 year, 1 month, and 19 days since she’s been gone but I love her just as much and I know I always will."
  },
  {
    "objectID": "mp1.html",
    "href": "mp1.html",
    "title": "Mini-Project 1",
    "section": "",
    "text": "In this part, I created the base table for data analysis using the code provided in the assignment. I also modified column names (Task 1) and recoded the values in the ‘Mode’ column to make them easier to understand and use for analysis (Task 2)."
  },
  {
    "objectID": "mp1.html#task-1---creating-syntatic-names",
    "href": "mp1.html#task-1---creating-syntatic-names",
    "title": "Mini-Project 1",
    "section": "Task 1 - Creating Syntatic Names",
    "text": "Task 1 - Creating Syntatic Names"
  },
  {
    "objectID": "mp1.html#task-2---recoding-the-mode-column",
    "href": "mp1.html#task-2---recoding-the-mode-column",
    "title": "Mini-Project 1",
    "section": "",
    "text": "# A tibble: 3 × 2\n  Agency                                                     total_vrm\n  &lt;chr&gt;                                                          &lt;dbl&gt;\n1 MTA New York City Transit                                10832855350\n2 New Jersey Transit Corporation                            5645525525\n3 Los Angeles County Metropolitan Transportation Authority  4354016659\n\n\n\n\n# A tibble: 3 × 2\n  Mode              total_vrm\n  &lt;chr&gt;                 &lt;dbl&gt;\n1 Bus             49444494088\n2 Demand Response 17955073508\n3 Heavy Rail      14620362107\n\n\n\n\n# A tibble: 3 × 1\n    total_vrm\n        &lt;dbl&gt;\n1 14620362107\n2          NA\n3          NA"
  },
  {
    "objectID": "mp1.html#testing-gt-package",
    "href": "mp1.html#testing-gt-package",
    "title": "Mini-Project 1",
    "section": "",
    "text": "#if(!require(“gt”)) install.packages(“gt”) #library(gt)\n#sample_n(USAGE, 100) |&gt; # gt()|&gt; # tab_header( # title=“Table 1” # )"
  },
  {
    "objectID": "mp1.html#part-1---getting-data-ready-for-analysis.",
    "href": "mp1.html#part-1---getting-data-ready-for-analysis.",
    "title": "Mini-Project 1",
    "section": "",
    "text": "In this part, I created the base table for data analysis using the provided in the assignment code. I also modified column names (Task 1) and recoded the values in the ‘Mode’ column to make them easier to understand and use for analysis (Task 2)."
  },
  {
    "objectID": "mp1.html#part-2---analyzing-transit-data.",
    "href": "mp1.html#part-2---analyzing-transit-data.",
    "title": "Mini-Project 1",
    "section": "Part 2 - Analyzing transit data.",
    "text": "Part 2 - Analyzing transit data.\n\nQ1. What transit agency had the most total VRM in this dataset?\nNot surprisingly, MTA New York City Transit has the largest total VRM in this dataset. Its total of 10.8B+ trips is almost double the total miles recorded by New Jersey Transit Corporation, the agency with the second largest result.\n\n\n# A tibble: 3 × 2\n  Agency                                                     total_vrm\n  &lt;chr&gt;                                                          &lt;dbl&gt;\n1 MTA New York City Transit                                10832855350\n2 New Jersey Transit Corporation                            5645525525\n3 Los Angeles County Metropolitan Transportation Authority  4354016659\n\n\n\n\nQ2. What transit mode had the most total VRM in this dataset?\nWith over 49 billion miles, bus has the most total VRM in this dataset.\n\n\n# A tibble: 3 × 2\n  Mode              total_vrm\n  &lt;chr&gt;                 &lt;dbl&gt;\n1 Bus             49444494088\n2 Demand Response 17955073508\n3 Heavy Rail      14620362107\n\n\n\n\nQ3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThere were slightly over 180 million trips on NYC Subway in May 2024.\n\n\n# A tibble: 1 × 1\n  total_trips\n        &lt;dbl&gt;\n1   180458819\n\n\n\n\nQ5. How much did NYC subway ridership fall between April 2019 and April 2020?\nNYC subway ridership fell by 92% between April 2019 and April 2020 because of Covid pandemic.\n\n\n# A tibble: 1 × 3\n  apr19_trips apr20_trips pct_change\n        &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1   232223929    20254269     -0.913"
  },
  {
    "objectID": "mp1.html#task-1-2---getting-data-ready-for-analysis.",
    "href": "mp1.html#task-1-2---getting-data-ready-for-analysis.",
    "title": "Mini-Project 1",
    "section": "",
    "text": "In this part, I created the base table for data analysis using the code provided in the assignment. I also modified column names (Task 1) and recoded the values in the ‘Mode’ column to make them easier to understand and use for analysis (Task 2)."
  },
  {
    "objectID": "mp1.html#task-3---analyzing-transit-data.",
    "href": "mp1.html#task-3---analyzing-transit-data.",
    "title": "Mini-Project 1",
    "section": "Task 3 - Analyzing transit data.",
    "text": "Task 3 - Analyzing transit data.\n\nQ1. What transit agency had the most total VRM in this dataset?\nNot surprisingly, MTA New York City Transit has the largest total mileage in this dataset. Its total of 10.8B+ trips is almost double of the amount attributed to New Jersey Transit Corporation, the agency with the second largest result.\n\n\n\n\n\n\n\n\nTop 3 Transit Agencies by Total VRM\n\n\nAgency\nTOTAL_VRM\n\n\n\n\nMTA New York City Transit\n10,832,855,350\n\n\nNew Jersey Transit Corporation\n5,645,525,525\n\n\nLos Angeles County Metropolitan Transportation Authority\n4,354,016,659\n\n\n\n\n\n\n\n\n\nQ2. What transit mode had the most total VRM in this dataset?\nWith over 49 billion miles, bus has the most total VRM in this dataset.\n\nUSAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(TOTAL_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  mutate(TOTAL_VRM = comma(TOTAL_VRM, digits = 0)) |&gt;\n  slice_max(TOTAL_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Modes by Total VRM\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Modes by Total VRM\n\n\nMode\nTOTAL_VRM\n\n\n\n\nBus\n49,444,494,088\n\n\nDemand Response\n17,955,073,508\n\n\nHeavy Rail\n14,620,362,107\n\n\n\n\n\n\n\n\n\nQ3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThere were slightly over 180 million trips recorded on NYC Subway in May 2024.\n\n\n\n\n\n\n\n\nNYC Subway Trips in May'24\n\n\nTOTAL_TRIPS\n\n\n\n\n180,458,819\n\n\n\n\n\n\n\n\n\nQ5. How much did NYC subway ridership fall between April 2019 and April 2020?\nNYC subway ridership fell by 91% between April 2019 and April 2020 because of Covid pandemic.\n\n\n\n\n\n\n\n\nChange in NYC Subway Ridership\n\n\nAPR19_TRIPS\nAPR20_TRIPS\nPCT_CHANGE\n\n\n\n\n232,223,929\n20,254,269\n-91%"
  },
  {
    "objectID": "mp1.html#task-4---additional-analysis-of-transit-data.",
    "href": "mp1.html#task-4---additional-analysis-of-transit-data.",
    "title": "Mini-Project 1",
    "section": "Task 4 - Additional analysis of transit data.",
    "text": "Task 4 - Additional analysis of transit data."
  },
  {
    "objectID": "mp1.html#task-5---summary-data-for-2022.",
    "href": "mp1.html#task-5---summary-data-for-2022.",
    "title": "Mini-Project 1",
    "section": "Task 5 - Summary data for 2022.",
    "text": "Task 5 - Summary data for 2022.\nIn this part, I created a summary usage table for 2022 and joined it with available financial data."
  },
  {
    "objectID": "mp1.html#task-6---analysis-of-2022-data.",
    "href": "mp1.html#task-6---analysis-of-2022-data.",
    "title": "Mini-Project 1",
    "section": "Task 6 - Analysis of 2022 data.",
    "text": "Task 6 - Analysis of 2022 data.\n\nQ1. Which transit system (agency and mode) had the most UPT in 2022?\nNot surprisingly, NYC Subway had the largest volume of trips in 2022.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by UPT\n\n\n2022\n\n\nTRANSIT_SYSTEM\nUPT_TOTAL\n\n\n\n\nMTA New York City Transit_Heavy Rail\n1,793,073,801\n\n\nMTA New York City Transit_Bus\n458,602,305\n\n\nLos Angeles County Metropolitan Transportation Authority_Bus\n193,637,448\n\n\n\n\n\n\n\n\n\nQ2.Which transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\nIn 2022, ferryboat managed by Port Imperial Ferry Corp. had the highest farebox recovery ratio of 1.43.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Farebox Recovery\n\n\n2022\n\n\nTRANSIT_SYSTEM\nFAREBOX_RECOVERY\n\n\n\n\nPort Imperial Ferry Corporation_Ferryboat\n1.43\n\n\nHyannis Harbor Tours, Inc._Ferryboat\n1.41\n\n\nTrans-Bridge Lines, Inc._Commuter Bus\n1.33\n\n\n\n\n\n\n\n\n\nQ3.Which transit system (agency and mode) has the lowest expenses per UPT?\nIn 2022, North Carolina State University Bus had the lowest expenses per UPT of $1.18 per unlinked passenger trip.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Expenses per UPT\n\n\n2022\n\n\nTRANSIT_SYSTEM\nEXPENSES_PER_UPT\n\n\n\n\nNorth Carolina State University_Bus\n$1.18\n\n\nAnaheim Transportation Network_Bus\n$1.28\n\n\nUniversity of Iowa_Bus\n$1.54\n\n\n\n\n\n\n\n\n\nQ4.Which transit system (agency and mode) has the highest total fares per UPT?\nIn 2022, ferryboat managed by Cape May Lewes Ferry garnered the highest total fares per UPT of $9.23 per unlinked passenger trip.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Fares per UPT\n\n\n2022\n\n\nTRANSIT_SYSTEM\nFARES_PER_UPT\n\n\n\n\nCape May Lewes Ferry_Ferryboat\n$9.23\n\n\nVirginia Railway Express_Commuter Rail\n$9.01\n\n\nPort Imperial Ferry Corporation_Ferryboat\n$8.90\n\n\n\n\n\n\n\n\n\nQ5.Which transit system (agency and mode) has the lowest expenses per VRM?\nIn 2022, Vanpool managed by Metropolitan Transportation Commission achieved the lowest expenses per VRM of $0.44 per vehicle revenue mile.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Expenses per VRM\n\n\n2022\n\n\nTRANSIT_SYSTEM\nEXPENSES_PER_VRM\n\n\n\n\nMetropolitan Transportation Commission_Vanpool\n$0.44\n\n\nSan Joaquin Council_Vanpool\n$0.50\n\n\nSan Diego Association of Governments_Vanpool\n$0.54\n\n\n\n\n\n\n\n\n\nQ6.Which transit system (agency and mode) has the highest total fares per VRM?\nIn 2022, ferryboat managed by Cape May Lewes Ferry achieved higher fares per VRM than any other large transit system with UPT of at least 400,000.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Fares per VRM\n\n\n2022\n\n\nTRANSIT_SYSTEM\nFARES_PER_VRM\n\n\n\n\nCape May Lewes Ferry_Ferryboat\n$93.01\n\n\nWoods Hole, Martha's Vineyard and Nantucket Steamship Authority_Ferryboat\n$91.68\n\n\nAnaheim Transportation Network_Bus\n$9.42\n\n\n\n\n\n\n\n\n\nBased on the farebox recovery ratio, Ferryboat managed by Port Imperial Ferry Corporation appeared to be the most efficient transit system in 2022 among large transit systems with total annual UPT of 400,000+."
  },
  {
    "objectID": "mp1.html#task-4---additional-findings.",
    "href": "mp1.html#task-4---additional-findings.",
    "title": "Mini-Project 1",
    "section": "Task 4 - Additional findings.",
    "text": "Task 4 - Additional findings.\n\nFor additional analysis, I took a deeper look at the NYC transit system data and discovered the following:\n\nBased on the share of UPT, subway has been, by far, the most popular mode of transportation. In any given year, its share of UPT is at least 2X of the second most used transit mode.\nMoreover, based on the changes in the share of UPT, NYC subway usage has been slowly increasing over the years. Between 2002 and 2023, it gained 9 percentage points in relative share, going from 68.1% of total to 76.6% of total, respectively.\nAt the same time, there has been a corresponding decrease in Bus trips. Between 2002 and 2023, it lost 10 percentage points in relative share, going from 31.9% of total to 21.6% of total, respectively.\nBus Rapid Transit and Commuter Bus are newer modes of transportation, with data on their usage not available until 2012.\n\n\n\n\n\n\n\n\n\nNYC Transit System - Relative Shares of UPT by Transportation Mode\n\n\nYEAR\nBus\nDemand Response\nHeavy Rail\nBus Rapid Transit\nCommuter Bus\n\n\n\n\n2002\n31.9%\n0.0%\n68.1%\nNA\nNA\n\n\n2003\n31.0%\n0.0%\n69.0%\nNA\nNA\n\n\n2004\n29.0%\n0.1%\n71.0%\nNA\nNA\n\n\n2005\n30.4%\n0.1%\n69.5%\nNA\nNA\n\n\n2006\n29.0%\n0.1%\n70.9%\nNA\nNA\n\n\n2007\n26.5%\n0.1%\n73.4%\nNA\nNA\n\n\n2008\n26.2%\n0.2%\n73.7%\nNA\nNA\n\n\n2009\n26.3%\n0.2%\n73.5%\nNA\nNA\n\n\n2010\n25.2%\n0.2%\n74.6%\nNA\nNA\n\n\n2011\n24.1%\n0.1%\n75.7%\nNA\nNA\n\n\n2012\n22.5%\n0.1%\n76.0%\n0.9%\n0.4%\n\n\n2013\n22.2%\n0.2%\n76.7%\n0.6%\n0.4%\n\n\n2014\n21.4%\n0.2%\n77.5%\n0.6%\n0.4%\n\n\n2015\n21.6%\n0.2%\n77.3%\n0.6%\n0.4%\n\n\n2016\n21.4%\n0.2%\n77.2%\n0.8%\n0.4%\n\n\n2017\n20.1%\n0.2%\n78.5%\n0.9%\n0.4%\n\n\n2018\n20.5%\n0.2%\n78.0%\n0.9%\n0.4%\n\n\n2019\n20.0%\n0.1%\n78.7%\n0.9%\n0.3%\n\n\n2020\n26.2%\n0.2%\n72.2%\n1.1%\n0.3%\n\n\n2021\n22.7%\n0.1%\n75.9%\n0.9%\n0.3%\n\n\n2022\n20.1%\n0.1%\n78.7%\n0.7%\n0.4%\n\n\n2023\n21.6%\n0.1%\n76.8%\n1.2%\n0.3%\n\n\n2024\n23.0%\n0.1%\n75.2%\n1.4%\n0.4%"
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "",
    "text": "In this paper, we will look at high-level fiscal performance of US public transit systems. This work is not meant to be an in-depth analysis of the stated topic but rather an introductory, high-level overview. We will use data from the National Transit Database to analyze main indicators of usage and financial performance and determine what constitutes efficiency.\nData sources used and data availability and limitations are documented in detail in the assignment and could be accessed here."
  },
  {
    "objectID": "mp01.html#task-1-2---getting-data-ready-for-analysis.",
    "href": "mp01.html#task-1-2---getting-data-ready-for-analysis.",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Task 1 & 2 - Getting data ready for analysis.",
    "text": "Task 1 & 2 - Getting data ready for analysis.\nIn this part, I created the base table for data analysis using the code provided in the assignment. I also modified column names (Task 1) and recoded the values in the ‘Mode’ column to make them easier to understand and use for analysis (Task 2). Please use the\n\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\n\n# Let's start with Fare Revenue\n\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n  select(\n    -`State/Parent NTD ID`,\n    -`Reporter Type`,\n    -`Reporting Module`,\n    -`TOS`,\n    -`Passenger Paid Fares`,\n    -`Organization Paid Fares`\n  ) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`) |&gt;\n  group_by(\n    `NTD ID`, # Sum over different `TOS` for the same `Mode`\n    `Agency Name`, # These are direct operated and sub-contracted\n    `Mode`\n  ) |&gt; # of the same transit modality\n  # Not a big effect in most munis (significant DO\n  # tends to get rid of sub-contractors), but we'll sum\n  # to unify different passenger experiences\n  summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n  ungroup()\n\n# Next, expenses\n\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n  select(\n    `NTD ID`,\n    `Agency`,\n    `Total`,\n    `Mode`\n  ) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n# Monthly Transit Numbers\n\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet = \"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(\n    -`Legacy NTD ID`,\n    -`Reporter Type`,\n    -`Mode/Type of Service Status`,\n    -`UACE CD`,\n    -`TOS`\n  ) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n    names_to = \"Month\",\n    values_to = \"UPT\"\n  ) |&gt;\n  drop_na() |&gt;\n  mutate(Month = my(Month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet = \"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(\n    -`Legacy NTD ID`,\n    -`Reporter Type`,\n    -`Mode/Type of Service Status`,\n    -`UACE CD`,\n    -`TOS`\n  ) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n    names_to = \"Month\",\n    values_to = \"VRM\"\n  ) |&gt;\n  drop_na() |&gt;\n  group_by(\n    `NTD ID`, `Agency`, `UZA Name`,\n    `Mode`, `3 Mode`, Month\n  ) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(Month = my(Month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\n## Task 1 - Creating syntatic names\n\nnames(USAGE)[3] &lt;- \"Metro_Area\"\n\n## Task 2 - Recoding the Mode column\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode = case_when(\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    Mode == \"MG\" ~ \"Monorail Automated Guideway\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"\n  ))\n\n\nsample_n(USAGE, 100) |&gt;\n  mutate(Month = as.character(Month)) |&gt;\n  DT::datatable(\n    filter='top'\n  )"
  },
  {
    "objectID": "mp01.html#task-3---analyzing-transit-data.",
    "href": "mp01.html#task-3---analyzing-transit-data.",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Task 3 - Analyzing transit data.",
    "text": "Task 3 - Analyzing transit data.\n\nQ1. What transit agency had the most total VRM in this dataset?\nNot surprisingly, MTA New York City Transit has the largest total mileage in this dataset. Its total of 10.8B+ trips is almost double of the amount attributed to New Jersey Transit Corporation, the agency with the second largest result.\n\n# installing and loading additional libraries\n\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\n\nUSAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(TOTAL_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  mutate(TOTAL_VRM = comma(TOTAL_VRM, digits = 0)) |&gt;\n  slice_max(TOTAL_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Agencies by Total VRM\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Agencies by Total VRM\n\n\nAgency\nTOTAL_VRM\n\n\n\n\nMTA New York City Transit\n10,832,855,350\n\n\nNew Jersey Transit Corporation\n5,645,525,525\n\n\nLos Angeles County Metropolitan Transportation Authority\n4,354,016,659\n\n\n\n\n\n\n\n\n\nQ2. What transit mode had the most total VRM in this dataset?\nWith over 49 billion miles, bus has the most total VRM in this dataset.\n\nUSAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(TOTAL_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  mutate(TOTAL_VRM = comma(TOTAL_VRM, digits = 0)) |&gt;\n  slice_max(TOTAL_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Modes by Total VRM\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Modes by Total VRM\n\n\nMode\nTOTAL_VRM\n\n\n\n\nBus\n49,444,494,088\n\n\nDemand Response\n17,955,073,508\n\n\nHeavy Rail\n14,620,362,107\n\n\n\n\n\n\n\n\n\nQ3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThere were slightly over 180 million trips recorded on NYC Subway in May 2024.\n\nUSAGE |&gt;\n  dplyr::filter(\n    Mode == \"Heavy Rail\",\n    Agency == \"MTA New York City Transit\",\n    Month == \"2024-05-01\"\n  ) |&gt;\n  summarize(TOTAL_TRIPS = sum(UPT, na.rm = TRUE)) |&gt;\n  mutate(TOTAL_TRIPS = comma(TOTAL_TRIPS, digits = 0)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"NYC Subway Trips in May'24\"\n  )\n\n\n\n\n\n\n\nNYC Subway Trips in May'24\n\n\nTOTAL_TRIPS\n\n\n\n\n180,458,819\n\n\n\n\n\n\n\n\n\nQ5. How much did NYC subway ridership fall between April 2019 and April 2020?\nNYC subway ridership fell by 91% between April 2019 and April 2020 because of Covid pandemic.\n\nUSAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\" & Mode == \"Heavy Rail\") |&gt;\n  summarise(\n    APR19_TRIPS = sum(dplyr::case_when(Month == \"2019-04-01\" ~ UPT, TRUE ~ 0), na.rm = TRUE),\n    APR20_TRIPS = sum(dplyr::case_when(Month == \"2020-04-01\" ~ UPT, TRUE ~ 0), na.rm = TRUE),\n    PCT_CHANGE = (APR20_TRIPS - APR19_TRIPS) / APR19_TRIPS\n  ) |&gt;\n  mutate(\n    PCT_CHANGE = scales::percent(PCT_CHANGE),\n    APR19_TRIPS = comma(APR19_TRIPS, digits = 0),\n    APR20_TRIPS = comma(APR20_TRIPS, digits = 0)\n  ) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Change in NYC Subway Ridership\"\n  )\n\n\n\n\n\n\n\nChange in NYC Subway Ridership\n\n\nAPR19_TRIPS\nAPR20_TRIPS\nPCT_CHANGE\n\n\n\n\n232,223,929\n20,254,269\n-91%"
  },
  {
    "objectID": "mp01.html#task-4---additional-findings.",
    "href": "mp01.html#task-4---additional-findings.",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Task 4 - Additional findings.",
    "text": "Task 4 - Additional findings.\n\nFor additional analysis, I took a deeper look at the NYC transit system data and discovered the following:\n\nBased on the share of UPT, subway has been, by far, the most popular mode of transportation. In any given year, its share of UPT is at least 2X of the second most used transit mode.\nMoreover, based on the changes in the share of UPT, NYC subway usage has been slowly increasing over the years. Between 2002 and 2023, it gained 9 percentage points in relative share, going from 68.1% of total to 76.6% of total, respectively.\nAt the same time, there has been a corresponding decrease in Bus trips. Between 2002 and 2023, it lost 10 percentage points in relative share, going from 31.9% of total to 21.6% of total, respectively.\nBus Rapid Transit and Commuter Bus are newer modes of transportation, with data on their usage not available until 2012.\n\n\n# create df with annual totals\n\nnyc_annual_df &lt;- USAGE |&gt;\n  mutate(YEAR = format(as.Date(Month), \"%Y\")) |&gt;\n  dplyr::filter(Agency == \"MTA New York City Transit\") |&gt;\n  group_by(YEAR) |&gt;\n  summarize(TOTAL_TRIPS_ALL = sum(UPT, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# create df with annual totals by mode\n\nnyc_mode_df &lt;- USAGE |&gt;\n  mutate(YEAR = format(as.Date(Month), \"%Y\")) |&gt;\n  dplyr::filter(Agency == \"MTA New York City Transit\") |&gt;\n  group_by(YEAR, Mode) |&gt;\n  summarize(TOTAL_TRIPS = sum(UPT, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# join 2 dfs and calculate shares by mode\n\nnyc_joined_df &lt;- nyc_mode_df |&gt;\n  left_join(nyc_annual_df, by = \"YEAR\")\n\nnyc_joined_df2 &lt;- nyc_joined_df |&gt;\n  mutate(SHARE = TOTAL_TRIPS / TOTAL_TRIPS_ALL) |&gt;\n  mutate(SHARE = scales::percent(SHARE, accuracy = 0.1)) |&gt;\n  select(-TOTAL_TRIPS, -TOTAL_TRIPS_ALL)\n\n# pivot wide\n\nnyc_mode_df_pivoted &lt;- pivot_wider(nyc_joined_df2,\n  id_cols = YEAR,\n  names_from = Mode,\n  values_from = SHARE\n)\n\nnyc_mode_df_pivoted |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"NYC Transit System - Relative Shares of UPT by Transportation Mode\"\n  )\n\n\n\n\n\n\n\nNYC Transit System - Relative Shares of UPT by Transportation Mode\n\n\nYEAR\nBus\nDemand Response\nHeavy Rail\nBus Rapid Transit\nCommuter Bus\n\n\n\n\n2002\n31.9%\n0.0%\n68.1%\nNA\nNA\n\n\n2003\n31.0%\n0.0%\n69.0%\nNA\nNA\n\n\n2004\n29.0%\n0.1%\n71.0%\nNA\nNA\n\n\n2005\n30.4%\n0.1%\n69.5%\nNA\nNA\n\n\n2006\n29.0%\n0.1%\n70.9%\nNA\nNA\n\n\n2007\n26.5%\n0.1%\n73.4%\nNA\nNA\n\n\n2008\n26.2%\n0.2%\n73.7%\nNA\nNA\n\n\n2009\n26.3%\n0.2%\n73.5%\nNA\nNA\n\n\n2010\n25.2%\n0.2%\n74.6%\nNA\nNA\n\n\n2011\n24.1%\n0.1%\n75.7%\nNA\nNA\n\n\n2012\n22.5%\n0.1%\n76.0%\n0.9%\n0.4%\n\n\n2013\n22.2%\n0.2%\n76.7%\n0.6%\n0.4%\n\n\n2014\n21.4%\n0.2%\n77.5%\n0.6%\n0.4%\n\n\n2015\n21.6%\n0.2%\n77.3%\n0.6%\n0.4%\n\n\n2016\n21.4%\n0.2%\n77.2%\n0.8%\n0.4%\n\n\n2017\n20.1%\n0.2%\n78.5%\n0.9%\n0.4%\n\n\n2018\n20.5%\n0.2%\n78.0%\n0.9%\n0.4%\n\n\n2019\n20.0%\n0.1%\n78.7%\n0.9%\n0.3%\n\n\n2020\n26.2%\n0.2%\n72.2%\n1.1%\n0.3%\n\n\n2021\n22.7%\n0.1%\n75.9%\n0.9%\n0.3%\n\n\n2022\n20.1%\n0.1%\n78.7%\n0.7%\n0.4%\n\n\n2023\n21.6%\n0.1%\n76.8%\n1.2%\n0.3%\n\n\n2024\n23.0%\n0.1%\n75.2%\n1.4%\n0.4%"
  },
  {
    "objectID": "mp01.html#task-5---summary-data-for-2022.",
    "href": "mp01.html#task-5---summary-data-for-2022.",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Task 5 - Summary data for 2022.",
    "text": "Task 5 - Summary data for 2022.\nIn this part, I created a summary usage table for 2022 and joined it with available financial data.\n\n### 2022 table\n\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt;\n  select(\n    `NTD ID`,\n    Agency,\n    Metro_Area,\n    Mode,\n    UPT,\n    VRM,\n    Month\n  ) |&gt;\n  filter(year(Month) == \"2022\") |&gt;\n  group_by(\n    `NTD ID`,\n    Agency,\n    Metro_Area,\n    Mode\n  ) |&gt;\n  summarise(\n    TOTAL_VRM = sum(VRM, na.rm = TRUE),\n    TOTAL_UPT = sum(UPT, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\n# recode modes values\n\nFINANCIALS2 &lt;- FINANCIALS |&gt;\n  mutate(Mode = case_when(\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    Mode == \"MG\" ~ \"Monorail Automated Guideway\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"\n  ))\n\n\nUSAGE_AND_FINANCIALS &lt;- left_join(\n  USAGE_2022_ANNUAL,\n  FINANCIALS2,\n  join_by(`NTD ID`, Mode)\n) |&gt;\n  drop_na()\n\n\nsample_n(USAGE_AND_FINANCIALS, 1132) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "mp01.html#task-6---analysis-of-2022-data.",
    "href": "mp01.html#task-6---analysis-of-2022-data.",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Task 6 - Analysis of 2022 data.",
    "text": "Task 6 - Analysis of 2022 data.\n\nQ1. Which transit system (agency and mode) had the most UPT in 2022?\nNot surprisingly, NYC Subway had the largest volume of trips in 2022.\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(TRANSIT_SYSTEM, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(TRANSIT_SYSTEM) |&gt;\n  summarise(UPT_TOTAL = sum(TOTAL_UPT)) |&gt;\n  mutate(UPT_TOTAL = comma(UPT_TOTAL, digits = 0)) |&gt;\n  slice_max(UPT_TOTAL, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by UPT\",\n    subtitle = \"2022\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Systems by UPT\n\n\n2022\n\n\nTRANSIT_SYSTEM\nUPT_TOTAL\n\n\n\n\nMTA New York City Transit_Heavy Rail\n1,793,073,801\n\n\nMTA New York City Transit_Bus\n458,602,305\n\n\nLos Angeles County Metropolitan Transportation Authority_Bus\n193,637,448\n\n\n\n\n\n\n\n\n\nQ2.Which transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\nIn 2022, ferryboat managed by Port Imperial Ferry Corp. had the highest farebox recovery ratio of 1.43.\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(TRANSIT_SYSTEM, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(TRANSIT_SYSTEM) |&gt;\n  filter(sum(TOTAL_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(FAREBOX_RECOVERY = sum(`Total Fares`, na.rm = TRUE) / sum(Expenses, na.rm = TRUE)) |&gt;\n  mutate(FAREBOX_RECOVERY = comma(FAREBOX_RECOVERY, digits = 2)) |&gt;\n  ungroup() |&gt;\n  slice_max(FAREBOX_RECOVERY, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Farebox Recovery\",\n    subtitle = \"2022\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Systems by Farebox Recovery\n\n\n2022\n\n\nTRANSIT_SYSTEM\nFAREBOX_RECOVERY\n\n\n\n\nPort Imperial Ferry Corporation_Ferryboat\n1.43\n\n\nHyannis Harbor Tours, Inc._Ferryboat\n1.41\n\n\nTrans-Bridge Lines, Inc._Commuter Bus\n1.33\n\n\n\n\n\n\n\n\n\nQ3.Which transit system (agency and mode) has the lowest expenses per UPT?\nIn 2022, North Carolina State University Bus had the lowest expenses per UPT of $1.18 per unlinked passenger trip.\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(TRANSIT_SYSTEM, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(TRANSIT_SYSTEM) |&gt;\n  filter(sum(TOTAL_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(EXPENSES_PER_UPT = sum(Expenses, na.rm = TRUE) / sum(TOTAL_UPT, na.rm = TRUE)) |&gt;\n  mutate(EXPENSES_PER_UPT = scales::dollar(EXPENSES_PER_UPT)) |&gt;\n  ungroup() |&gt;\n  slice_min(EXPENSES_PER_UPT, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Expenses per UPT\",\n    subtitle = \"2022\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Systems by Expenses per UPT\n\n\n2022\n\n\nTRANSIT_SYSTEM\nEXPENSES_PER_UPT\n\n\n\n\nNorth Carolina State University_Bus\n$1.18\n\n\nAnaheim Transportation Network_Bus\n$1.28\n\n\nUniversity of Iowa_Bus\n$1.54\n\n\n\n\n\n\n\n\n\nQ4.Which transit system (agency and mode) has the highest total fares per UPT?\nIn 2022, ferryboat managed by Cape May Lewes Ferry garnered the highest total fares per UPT of $9.23 per unlinked passenger trip.\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(TRANSIT_SYSTEM, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(TRANSIT_SYSTEM) |&gt;\n  filter(sum(TOTAL_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(FARES_PER_UPT = sum(`Total Fares`, na.rm = TRUE) / sum(TOTAL_UPT, na.rm = TRUE)) |&gt;\n  mutate(FARES_PER_UPT = scales::dollar(FARES_PER_UPT)) |&gt;\n  ungroup() |&gt;\n  slice_max(FARES_PER_UPT, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Fares per UPT\",\n    subtitle = \"2022\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Systems by Fares per UPT\n\n\n2022\n\n\nTRANSIT_SYSTEM\nFARES_PER_UPT\n\n\n\n\nCape May Lewes Ferry_Ferryboat\n$9.23\n\n\nVirginia Railway Express_Commuter Rail\n$9.01\n\n\nPort Imperial Ferry Corporation_Ferryboat\n$8.90\n\n\n\n\n\n\n\n\n\nQ5.Which transit system (agency and mode) has the lowest expenses per VRM?\nIn 2022, Vanpool managed by Metropolitan Transportation Commission achieved the lowest expenses per VRM of $0.44 per vehicle revenue mile.\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(TRANSIT_SYSTEM, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(TRANSIT_SYSTEM) |&gt;\n  filter(sum(TOTAL_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(EXPENSES_PER_VRM = sum(Expenses, na.rm = TRUE) / sum(TOTAL_VRM, na.rm = TRUE)) |&gt;\n  mutate(EXPENSES_PER_VRM = scales::dollar(EXPENSES_PER_VRM)) |&gt;\n  ungroup() |&gt;\n  slice_min(EXPENSES_PER_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Expenses per VRM\",\n    subtitle = \"2022\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Systems by Expenses per VRM\n\n\n2022\n\n\nTRANSIT_SYSTEM\nEXPENSES_PER_VRM\n\n\n\n\nMetropolitan Transportation Commission_Vanpool\n$0.44\n\n\nSan Joaquin Council_Vanpool\n$0.50\n\n\nSan Diego Association of Governments_Vanpool\n$0.54\n\n\n\n\n\n\n\n\n\nQ6.Which transit system (agency and mode) has the highest total fares per VRM?\nIn 2022, ferryboat managed by Cape May Lewes Ferry achieved higher fares per VRM than any other large transit system with UPT of at least 400,000.\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(TRANSIT_SYSTEM, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(TRANSIT_SYSTEM) |&gt;\n  filter(sum(TOTAL_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(FARES_PER_VRM = sum(`Total Fares`, na.rm = TRUE) / sum(TOTAL_VRM, na.rm = TRUE)) |&gt;\n  mutate(FARES_PER_VRM = scales::dollar(FARES_PER_VRM)) |&gt;\n  ungroup() |&gt;\n  slice_max(FARES_PER_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Fares per VRM\",\n    subtitle = \"2022\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Systems by Fares per VRM\n\n\n2022\n\n\nTRANSIT_SYSTEM\nFARES_PER_VRM\n\n\n\n\nCape May Lewes Ferry_Ferryboat\n$93.01\n\n\nWoods Hole, Martha's Vineyard and Nantucket Steamship Authority_Ferryboat\n$91.68\n\n\nAnaheim Transportation Network_Bus\n$9.42\n\n\n\n\n\n\n\n\n\nBased on the farebox recovery ratio, Ferryboat managed by Port Imperial Ferry Corporation appeared to be the most efficient transit system in 2022 among large transit systems with total annual UPT of 400,000+."
  },
  {
    "objectID": "mp01.html#data-preparation",
    "href": "mp01.html#data-preparation",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Data Preparation",
    "text": "Data Preparation\nIn this part, I created the base table for data analysis using the code provided in the assignment. I also modified column names (per Task 1) and recoded the values in the ‘Mode’ column to make them easier to understand and use for analysis (per Task 2). The base table is provided for review after the code block (please note NTD ID and 3 Modes columns are excluded from the preview).\n\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\n\n# Let's start with Fare Revenue\n\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n  select(\n    -`State/Parent NTD ID`,\n    -`Reporter Type`,\n    -`Reporting Module`,\n    -`TOS`,\n    -`Passenger Paid Fares`,\n    -`Organization Paid Fares`\n  ) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`) |&gt;\n  group_by(\n    `NTD ID`, # Sum over different `TOS` for the same `Mode`\n    `Agency Name`, # These are direct operated and sub-contracted\n    `Mode`\n  ) |&gt; # of the same transit modality\n  # Not a big effect in most munis (significant DO\n  # tends to get rid of sub-contractors), but we'll sum\n  # to unify different passenger experiences\n  summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n  ungroup()\n\n# Next, expenses\n\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n  select(\n    `NTD ID`,\n    `Agency`,\n    `Total`,\n    `Mode`\n  ) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n# Monthly Transit Numbers\n\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet = \"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(\n    -`Legacy NTD ID`,\n    -`Reporter Type`,\n    -`Mode/Type of Service Status`,\n    -`UACE CD`,\n    -`TOS`\n  ) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n    names_to = \"Month\",\n    values_to = \"UPT\"\n  ) |&gt;\n  drop_na() |&gt;\n  mutate(Month = my(Month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet = \"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(\n    -`Legacy NTD ID`,\n    -`Reporter Type`,\n    -`Mode/Type of Service Status`,\n    -`UACE CD`,\n    -`TOS`\n  ) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n    names_to = \"Month\",\n    values_to = \"VRM\"\n  ) |&gt;\n  drop_na() |&gt;\n  group_by(\n    `NTD ID`, `Agency`, `UZA Name`,\n    `Mode`, `3 Mode`, Month\n  ) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(Month = my(Month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\n## Task 1 - Creating syntatic names\n\nnames(USAGE)[3] &lt;- \"Metro_Area\"\n\n## Task 2 - Recoding the Mode column\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode = case_when(\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    Mode == \"MG\" ~ \"Monorail Automated Guideway\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"\n  ))\n\n# base table sampled\n\nsample_n(USAGE, 1000) |&gt;\n  select(-`NTD ID`, -`3 Mode`) |&gt;\n  mutate(Month = as.character(Month)) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "mp01.html#initial-analysys-of-transit-data",
    "href": "mp01.html#initial-analysys-of-transit-data",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Initial analysys of transit data",
    "text": "Initial analysys of transit data\nIn this part, I conducted the initial analysis of transit data by addressing 5 questions provided in Task 3.\n\nQ1. What transit agency had the most total VRM in this dataset?\nNot surprisingly, MTA New York City Transit has the largest total mileage in this dataset. Its total of 10.8B+ trips is almost double of the amount attributed to New Jersey Transit Corporation, the agency with the second largest result.\n\n\n\n\n\n\n\n\nTop 3 Transit Agencies by Total VRM\n\n\nAgency\nTOTAL_VRM\n\n\n\n\nMTA New York City Transit\n10,832,855,350\n\n\nNew Jersey Transit Corporation\n5,645,525,525\n\n\nLos Angeles County Metropolitan Transportation Authority\n4,354,016,659\n\n\n\n\n\n\n\n\n# installing and loading additional libraries\n\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\n\nUSAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(TOTAL_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  mutate(TOTAL_VRM = comma(TOTAL_VRM, digits = 0)) |&gt;\n  slice_max(TOTAL_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Agencies by Total VRM\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Agencies by Total VRM\n\n\nAgency\nTOTAL_VRM\n\n\n\n\nMTA New York City Transit\n10,832,855,350\n\n\nNew Jersey Transit Corporation\n5,645,525,525\n\n\nLos Angeles County Metropolitan Transportation Authority\n4,354,016,659\n\n\n\n\n\n\n\n\n\nQ2. What transit mode had the most total VRM in this dataset?\nWith over 49 billion miles, bus has the most total VRM in this dataset.\n\nUSAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(TOTAL_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  mutate(TOTAL_VRM = comma(TOTAL_VRM, digits = 0)) |&gt;\n  slice_max(TOTAL_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Modes by Total VRM\"\n  )\n\n\n\n\n\n\n\nTop 3 Transit Modes by Total VRM\n\n\nMode\nTOTAL_VRM\n\n\n\n\nBus\n49,444,494,088\n\n\nDemand Response\n17,955,073,508\n\n\nHeavy Rail\n14,620,362,107\n\n\n\n\n\n\n\n\n\nQ3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThere were slightly over 180 million trips recorded on NYC Subway in May 2024.\n\nUSAGE |&gt;\n  dplyr::filter(\n    Mode == \"Heavy Rail\",\n    Agency == \"MTA New York City Transit\",\n    Month == \"2024-05-01\"\n  ) |&gt;\n  summarize(TOTAL_TRIPS = sum(UPT, na.rm = TRUE)) |&gt;\n  mutate(TOTAL_TRIPS = comma(TOTAL_TRIPS, digits = 0)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"NYC Subway Trips in May'24\"\n  )\n\n\n\n\n\n\n\nNYC Subway Trips in May'24\n\n\nTOTAL_TRIPS\n\n\n\n\n180,458,819\n\n\n\n\n\n\n\n\n\nQ5. How much did NYC subway ridership fall between April 2019 and April 2020?\nNYC subway ridership fell by 91% between April 2019 and April 2020 because of Covid pandemic.\n\nUSAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\" & Mode == \"Heavy Rail\") |&gt;\n  summarise(\n    APR19_TRIPS = sum(dplyr::case_when(Month == \"2019-04-01\" ~ UPT, TRUE ~ 0), na.rm = TRUE),\n    APR20_TRIPS = sum(dplyr::case_when(Month == \"2020-04-01\" ~ UPT, TRUE ~ 0), na.rm = TRUE),\n    PCT_CHANGE = (APR20_TRIPS - APR19_TRIPS) / APR19_TRIPS\n  ) |&gt;\n  mutate(\n    PCT_CHANGE = scales::percent(PCT_CHANGE),\n    APR19_TRIPS = comma(APR19_TRIPS, digits = 0),\n    APR20_TRIPS = comma(APR20_TRIPS, digits = 0)\n  ) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Change in NYC Subway Ridership\"\n  )\n\n\n\n\n\n\n\nChange in NYC Subway Ridership\n\n\nAPR19_TRIPS\nAPR20_TRIPS\nPCT_CHANGE\n\n\n\n\n232,223,929\n20,254,269\n-91%"
  },
  {
    "objectID": "mp01.html#initial-analysis-of-transit-data",
    "href": "mp01.html#initial-analysis-of-transit-data",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Initial analysis of transit data",
    "text": "Initial analysis of transit data\nIn this part, I conducted the initial analysis of transit data by addressing the questions provided in Task 3.\n\nQ1. What transit agency had the most total VRM in this dataset?\nNot surprisingly, MTA New York City Transit has the largest total mileage in this dataset. Its total of 10.8B+ vehicle revenue miles is almost double of the amount attributed to New Jersey Transit Corporation, the agency with the second largest result.\n\n\n\n\n\n\n\n\nTop 3 Transit Agencies by Total VRM\n\n\nAgency\nTotal_VRM\n\n\n\n\nMTA New York City Transit\n10,832,855,350\n\n\nNew Jersey Transit Corporation\n5,645,525,525\n\n\nLos Angeles County Metropolitan Transportation Authority\n4,354,016,659\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\n# installing and loading additional libraries\n\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\n\nUSAGE |&gt;\n  group_by(Agency) |&gt;\n  summarize(Total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  mutate(Total_VRM = comma(Total_VRM, digits = 0)) |&gt;\n  slice_max(Total_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Agencies by Total VRM\"\n  )\n\n\n\nQ2. What transit mode had the most total VRM in this dataset?\nWith over 49 billion vehicle revenue miles, bus has the most total VRM of all transit modes.\n\n\n\n\n\n\n\n\nTop 3 Transit Modes by Total VRM\n\n\nMode\nTotal_VRM\n\n\n\n\nBus\n49,444,494,088\n\n\nDemand Response\n17,955,073,508\n\n\nHeavy Rail\n14,620,362,107\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE |&gt;\n  group_by(Mode) |&gt;\n  summarize(Total_VRM = sum(VRM, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  mutate(Total_VRM = comma(Total_VRM, digits = 0)) |&gt;\n  slice_max(Total_VRM, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Modes by Total VRM\"\n  )\n\n\n\nQ3. How many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nThere were slightly over 180 million trips recorded on NYC Subway in May 2024.\n\n\n\n\n\n\n\n\nNYC Subway Trips in May'24\n\n\nTotal_UPT\n\n\n\n\n180,458,819\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE |&gt;\n  dplyr::filter(\n    Mode == \"Heavy Rail\",\n    Agency == \"MTA New York City Transit\",\n    Month == \"2024-05-01\"\n  ) |&gt;\n  summarize(Total_UPT = sum(UPT, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  mutate(Total_UPT = comma(Total_UPT, digits = 0)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"NYC Subway Trips in May'24\"\n  )\n\n\n\nQ5. How much did NYC subway ridership fall between April’19 and April’20?\nNYC subway ridership fell by 91% between April 2019 and April 2020 because of the Covid’19 pandemic.\n\n\n\n\n\n\n\n\nChange in NYC Subway Ridership\n\n\nApril19_Trips\nApril20_Trips\nPct_Change\n\n\n\n\n232,223,929\n20,254,269\n-91%\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE |&gt;\n  filter(Agency == \"MTA New York City Transit\" & Mode == \"Heavy Rail\") |&gt;\n  summarise(\n    April19_Trips = sum(dplyr::case_when(Month == \"2019-04-01\" ~ UPT, TRUE ~ 0), na.rm = TRUE),\n    April20_Trips = sum(dplyr::case_when(Month == \"2020-04-01\" ~ UPT, TRUE ~ 0), na.rm = TRUE),\n    Pct_Change = (April20_Trips - April19_Trips) / April19_Trips\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    Pct_Change = scales::percent(Pct_Change),\n    April19_Trips = comma(April19_Trips, digits = 0),\n    April20_Trips = comma(April20_Trips, digits = 0)\n  ) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Change in NYC Subway Ridership\"\n  )"
  },
  {
    "objectID": "mp01.html#task-4---additional-analysis-of-transit-data",
    "href": "mp01.html#task-4---additional-analysis-of-transit-data",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Task 4 - Additional analysis of transit data",
    "text": "Task 4 - Additional analysis of transit data\nIn this part, I took a deeper look at the NYC transit system data and discovered the following:\n1) Based on the share of UPT, subway has been, by far, the most popular mode of transportation. In any given year, its relative share of UPT is at least 2X of the second most used transit mode.\n2) Moreover, based on the changes in the share of UPT, NYC subway usage has been slowly increasing over the years. Between 2002 and 2023, it gained 9 percentage points in relative share, going from 68.1% of total to 76.6% of total, respectively.\n3) At the same time, there has been a corresponding decrease in Bus trips. Between 2002 and 2023, it lost 10 percentage points in relative share, going from 31.9% of total to 21.6% of total, respectively.\n4) Bus Rapid Transit and Commuter Bus are newer modes of transportation, with data on their usage not available until 2012.\n\n\n\n\n\n\n\n\nNYC Transit System - Relative Shares of UPT by Transportation Mode\n\n\nYEAR\nBus\nDemand Response\nHeavy Rail\nBus Rapid Transit\nCommuter Bus\n\n\n\n\n2002\n31.9%\n0.0%\n68.1%\nNA\nNA\n\n\n2003\n31.0%\n0.0%\n69.0%\nNA\nNA\n\n\n2004\n29.0%\n0.1%\n71.0%\nNA\nNA\n\n\n2005\n30.4%\n0.1%\n69.5%\nNA\nNA\n\n\n2006\n29.0%\n0.1%\n70.9%\nNA\nNA\n\n\n2007\n26.5%\n0.1%\n73.4%\nNA\nNA\n\n\n2008\n26.2%\n0.2%\n73.7%\nNA\nNA\n\n\n2009\n26.3%\n0.2%\n73.5%\nNA\nNA\n\n\n2010\n25.2%\n0.2%\n74.6%\nNA\nNA\n\n\n2011\n24.1%\n0.1%\n75.7%\nNA\nNA\n\n\n2012\n22.5%\n0.1%\n76.0%\n0.9%\n0.4%\n\n\n2013\n22.2%\n0.2%\n76.7%\n0.6%\n0.4%\n\n\n2014\n21.4%\n0.2%\n77.5%\n0.6%\n0.4%\n\n\n2015\n21.6%\n0.2%\n77.3%\n0.6%\n0.4%\n\n\n2016\n21.4%\n0.2%\n77.2%\n0.8%\n0.4%\n\n\n2017\n20.1%\n0.2%\n78.5%\n0.9%\n0.4%\n\n\n2018\n20.5%\n0.2%\n78.0%\n0.9%\n0.4%\n\n\n2019\n20.0%\n0.1%\n78.7%\n0.9%\n0.3%\n\n\n2020\n26.2%\n0.2%\n72.2%\n1.1%\n0.3%\n\n\n2021\n22.7%\n0.1%\n75.9%\n0.9%\n0.3%\n\n\n2022\n20.1%\n0.1%\n78.7%\n0.7%\n0.4%\n\n\n2023\n21.6%\n0.1%\n76.8%\n1.2%\n0.3%\n\n\n2024\n23.0%\n0.1%\n75.2%\n1.4%\n0.4%\n\n\n\n\n\n\n\nPlease see below for the code used to generate aforementioned results:\n\n# create df with annual totals\n\nnyc_annual_df &lt;- USAGE |&gt;\n  mutate(YEAR = format(as.Date(Month), \"%Y\")) |&gt;\n  dplyr::filter(Agency == \"MTA New York City Transit\") |&gt;\n  group_by(YEAR) |&gt;\n  summarize(TOTAL_TRIPS_ALL = sum(UPT, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# create df with annual totals by mode\n\nnyc_mode_df &lt;- USAGE |&gt;\n  mutate(YEAR = format(as.Date(Month), \"%Y\")) |&gt;\n  dplyr::filter(Agency == \"MTA New York City Transit\") |&gt;\n  group_by(YEAR, Mode) |&gt;\n  summarize(TOTAL_TRIPS = sum(UPT, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# join 2 dfs and calculate shares by mode\n\nnyc_joined_df &lt;- nyc_mode_df |&gt;\n  left_join(nyc_annual_df, by = \"YEAR\")\n\nnyc_joined_df2 &lt;- nyc_joined_df |&gt;\n  mutate(SHARE = TOTAL_TRIPS / TOTAL_TRIPS_ALL) |&gt;\n  mutate(SHARE = scales::percent(SHARE, accuracy = 0.1)) |&gt;\n  select(-TOTAL_TRIPS, -TOTAL_TRIPS_ALL)\n\n# pivot wide\n\nnyc_mode_df_pivoted &lt;- pivot_wider(nyc_joined_df2,\n  id_cols = YEAR,\n  names_from = Mode,\n  values_from = SHARE\n)\n\nnyc_mode_df_pivoted |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"NYC Transit System - Relative Shares of UPT by Transportation Mode\"\n  )"
  },
  {
    "objectID": "mp01.html#financial-data-prepation",
    "href": "mp01.html#financial-data-prepation",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Financial data prepation",
    "text": "Financial data prepation\nIn this part, I created a summary usage table for 2022 and joined it with available financial data (per Task 5). The resulting dataset is provided for review after the code block.\n\n# code used to generate financial and usage summary table for 2022\n\n# create 2022 usage data\n\nUSAGE_2022_ANNUAL &lt;- USAGE |&gt;\n  select(\n    `NTD ID`,\n    Agency,\n    Metro_Area,\n    Mode,\n    UPT,\n    VRM,\n    Month\n  ) |&gt;\n  filter(year(Month) == \"2022\") |&gt;\n  group_by(\n    `NTD ID`,\n    Agency,\n    Metro_Area,\n    Mode\n  ) |&gt;\n  summarise(\n    Total_VRM = sum(VRM, na.rm = TRUE),\n    Total_UPT = sum(UPT, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\n# recode modes values in financial data\n\nFINANCIALS2 &lt;- FINANCIALS |&gt;\n  mutate(Mode = case_when(\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    Mode == \"MG\" ~ \"Monorail Automated Guideway\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"\n  ))\n\n# join financial and usage data\n\nUSAGE_AND_FINANCIALS &lt;- left_join(\n  USAGE_2022_ANNUAL,\n  FINANCIALS2,\n  join_by(`NTD ID`, Mode)\n) |&gt;\n  drop_na()\n\n# review the data\n\nsample_n(USAGE_AND_FINANCIALS, 1132) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "mp01.html#analysis-of-2022-financial-and-usage-data",
    "href": "mp01.html#analysis-of-2022-financial-and-usage-data",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Analysis of 2022 financial and usage data",
    "text": "Analysis of 2022 financial and usage data\nIn this part, I addressed the questions outlined in Task 6. Please note that this analysis will be limited to large transit systems only (large transit systems are defined as systems with at least 400,000 total annual UPT).\n\nQ1. Which transit system (agency and mode) had the most UPT in 2022?\nNot surprisingly, NYC Subway had the largest volume of trips in 2022.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by UPT\n\n\n2022\n\n\nTransit_System\nUPT\n\n\n\n\nMTA New York City Transit_Heavy Rail\n1,793,073,801\n\n\nMTA New York City Transit_Bus\n458,602,305\n\n\nLos Angeles County Metropolitan Transportation Authority_Bus\n193,637,448\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(Transit_System, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(Transit_System) |&gt;\n  filter(sum(Total_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(UPT = sum(Total_UPT)) |&gt;\n  ungroup() |&gt;\n  mutate(UPT = comma(UPT, digits = 0)) |&gt;\n  slice_max(UPT, n = 3) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by UPT\",\n    subtitle = \"2022\"\n  )\n\n\n\nQ2.Which transit system (agency and mode) had the highest farebox recovery, defined as the highest ratio of Total Fares to Expenses?\nIn 2022, ferryboat managed by Port Imperial Ferry Corp. had the highest farebox recovery ratio of 1.43.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Farebox Recovery\n\n\n2022\n\n\nTransit_System\nFarebox_Recovery\n\n\n\n\nPort Imperial Ferry Corporation_Ferryboat\n142.8%\n\n\nHyannis Harbor Tours, Inc._Ferryboat\n141.3%\n\n\nTrans-Bridge Lines, Inc._Commuter Bus\n133.3%\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(Transit_System, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(Transit_System) |&gt;\n  filter(sum(Total_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(Farebox_Recovery = sum(`Total Fares`, na.rm = TRUE) / sum(Expenses, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  slice_max(Farebox_Recovery, n = 3) |&gt;\n  mutate(Farebox_Recovery = scales::percent(Farebox_Recovery, accuracy = 0.1)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Farebox Recovery\",\n    subtitle = \"2022\"\n  )\n\n\n\nQ3.Which transit system (agency and mode) has the lowest expenses per UPT?\nIn 2022, North Carolina State University Bus had the lowest expenses per UPT of $1.18 per unlinked passenger trip.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Expenses per UPT\n\n\n2022\n\n\nTransit_System\nExpenses_per_UPT\n\n\n\n\nNorth Carolina State University_Bus\n$1.18\n\n\nAnaheim Transportation Network_Bus\n$1.28\n\n\nUniversity of Iowa_Bus\n$1.54\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(Transit_System, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(Transit_System) |&gt;\n  filter(sum(Total_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(Expenses_Per_UPT = sum(Expenses, na.rm = TRUE) / sum(Total_UPT, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  slice_min(Expenses_Per_UPT, n = 3) |&gt;\n  mutate(Expenses_Per_UPT = scales::dollar(Expenses_Per_UPT)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Expenses per UPT\",\n    subtitle = \"2022\"\n  )\n\n\n\nQ4.Which transit system (agency and mode) has the highest total fares per UPT?\nIn 2022, commuter bus managed by Hampton Jitney Inc. garnered the highest total fares per UPT of $41.30 per unlinked passenger trip.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Fares per UPT\n\n\n2022\n\n\nTransit_System\nFares_per_UPT\n\n\n\n\nHampton Jitney, Inc._Commuter Bus\n$41.30\n\n\nPennsylvania Department of Transportation_Commuter Rail\n$32.26\n\n\nHyannis Harbor Tours, Inc._Ferryboat\n$29.56\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(Transit_System, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(Transit_System) |&gt;\n  filter(sum(Total_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(Fares_per_UPT = sum(`Total Fares`, na.rm = TRUE) / sum(Total_UPT, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  slice_max(Fares_per_UPT, n = 3) |&gt;\n  mutate(Fares_per_UPT = scales::dollar(Fares_per_UPT)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Fares per UPT\",\n    subtitle = \"2022\"\n  )\n\n\n\nQ5.Which transit system (agency and mode) has the lowest expenses per VRM?\nIn 2022, Vanpool managed by Metropolitan Transportation Commission achieved the lowest expenses per VRM of $0.44 per vehicle revenue mile.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Expenses per VRM\n\n\n2022\n\n\nTransit_System\nExpenses_per_VRM\n\n\n\n\nMetropolitan Transportation Commission_Vanpool\n$0.44\n\n\nSan Joaquin Council_Vanpool\n$0.50\n\n\nSan Diego Association of Governments_Vanpool\n$0.54\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(Transit_System, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(Transit_System) |&gt;\n  filter(sum(Total_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(Expenses_per_VRM = sum(Expenses, na.rm = TRUE) / sum(Total_VRM, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  slice_min(Expenses_per_VRM, n = 3) |&gt;\n  mutate(Expenses_per_VRM = scales::dollar(Expenses_per_VRM)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Expenses per VRM\",\n    subtitle = \"2022\"\n  )\n\n\n\nQ6.Which transit system (agency and mode) has the highest total fares per VRM?\nIn 2022, ferryboat managed by Jacksonville Transporation Authority achieved higher fares per VRM than any other large transit system with UPT of at least 400,000.\n\n\n\n\n\n\n\n\nTop 3 Transit Systems by Fares per VRM\n\n\n2022\n\n\nTransit_System\nFares_per_VRM\n\n\n\n\nJacksonville Transportation Authority_Ferryboat\n$157.70\n\n\nChattanooga Area Regional Transportation Authority_Inclined Plane\n$149.30\n\n\nHyannis Harbor Tours, Inc._Ferryboat\n$137.64\n\n\n\n\n\n\n\nPlease see below for the code used to generate the aforementioned results:\n\nUSAGE_AND_FINANCIALS |&gt;\n  unite(Transit_System, c(\"Agency\", \"Mode\")) |&gt;\n  group_by(Transit_System) |&gt;\n  filter(sum(Total_UPT, na.rm = TRUE) &gt;= 400000) |&gt;\n  summarise(Fares_per_VRM = sum(`Total Fares`, na.rm = TRUE) / sum(Total_VRM, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  slice_max(Fares_per_VRM, n = 3) |&gt;\n  mutate(Fares_per_VRM = scales::dollar(Fares_per_VRM)) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 3 Transit Systems by Fares per VRM\",\n    subtitle = \"2022\"\n  )\n\n\n\nConclusion\nThe farebox recovery ratio is one of the key metrics used to evaluate financial performance of transit systems (Source). With the farebox recovery ratio of 142.8%, the ferryboat managed by Port Imperial Ferry Corporation appeared to be the most efficient large transit system in 2022."
  },
  {
    "objectID": "mp01.html#additional-analysis-of-transit-data",
    "href": "mp01.html#additional-analysis-of-transit-data",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Additional Analysis of Transit Data",
    "text": "Additional Analysis of Transit Data\nIn this part, I conducted additional analysis of transit usage data as instructed in Task 4. Focusing on MTA New York City Transit, I analyzed the relative popularity of different transporation options over the years and discovered the following:\n1) Based on the share of UPT, subway has been, by far, the most popular mode of transportation. In any given year, its relative share of UPT is at least 2X of that of the second most used transit mode, Bus.\n2) Moreover, based on the changes in the share of UPT, NYC subway usage has been slowly increasing over the years. Between 2002 and 2023, it gained 9 percentage points in relative share, going from 68.1% of total to 76.8% of total, respectively.\n3) At the same time, there has been a corresponding decrease in Bus trips. Between 2002 and 2023, it lost 10 percentage points in relative share, going from 31.9% of total to 21.6% of total, respectively.\n4) Bus Rapid Transit and Commuter Bus are newer modes of transportation, with data on their usage not available until 2012.\n\n\n\n\n\n\n\n\nNYC Transit System - Relative Shares of UPT by Transportation Mode\n\n\nYEAR\nBus\nDemand Response\nHeavy Rail\nBus Rapid Transit\nCommuter Bus\n\n\n\n\n2002\n31.9%\n0.0%\n68.1%\nNA\nNA\n\n\n2003\n31.0%\n0.0%\n69.0%\nNA\nNA\n\n\n2004\n29.0%\n0.1%\n71.0%\nNA\nNA\n\n\n2005\n30.4%\n0.1%\n69.5%\nNA\nNA\n\n\n2006\n29.0%\n0.1%\n70.9%\nNA\nNA\n\n\n2007\n26.5%\n0.1%\n73.4%\nNA\nNA\n\n\n2008\n26.2%\n0.2%\n73.7%\nNA\nNA\n\n\n2009\n26.3%\n0.2%\n73.5%\nNA\nNA\n\n\n2010\n25.2%\n0.2%\n74.6%\nNA\nNA\n\n\n2011\n24.1%\n0.1%\n75.7%\nNA\nNA\n\n\n2012\n22.5%\n0.1%\n76.0%\n0.9%\n0.4%\n\n\n2013\n22.2%\n0.2%\n76.7%\n0.6%\n0.4%\n\n\n2014\n21.4%\n0.2%\n77.5%\n0.6%\n0.4%\n\n\n2015\n21.6%\n0.2%\n77.3%\n0.6%\n0.4%\n\n\n2016\n21.4%\n0.2%\n77.2%\n0.8%\n0.4%\n\n\n2017\n20.1%\n0.2%\n78.5%\n0.9%\n0.4%\n\n\n2018\n20.5%\n0.2%\n78.0%\n0.9%\n0.4%\n\n\n2019\n20.0%\n0.1%\n78.7%\n0.9%\n0.3%\n\n\n2020\n26.2%\n0.2%\n72.2%\n1.1%\n0.3%\n\n\n2021\n22.7%\n0.1%\n75.9%\n0.9%\n0.3%\n\n\n2022\n20.1%\n0.1%\n78.7%\n0.7%\n0.4%\n\n\n2023\n21.6%\n0.1%\n76.8%\n1.2%\n0.3%\n\n\n2024\n23.0%\n0.1%\n75.2%\n1.4%\n0.4%\n\n\n\n\n\n\n\n(Relative share of UPT is calculated as UPT of a given mode over total annual UPT)\nPlease see below for the code used to generate aforementioned results:\n\n# create df with annual totals\n\nnyc_annual_df &lt;- USAGE |&gt;\n  mutate(YEAR = format(as.Date(Month), \"%Y\")) |&gt;\n  dplyr::filter(Agency == \"MTA New York City Transit\") |&gt;\n  group_by(YEAR) |&gt;\n  summarize(TOTAL_TRIPS_ALL = sum(UPT, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# create df with annual totals by mode\n\nnyc_mode_df &lt;- USAGE |&gt;\n  mutate(YEAR = format(as.Date(Month), \"%Y\")) |&gt;\n  dplyr::filter(Agency == \"MTA New York City Transit\") |&gt;\n  group_by(YEAR, Mode) |&gt;\n  summarize(TOTAL_TRIPS = sum(UPT, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# join 2 dfs and calculate shares by mode\n\nnyc_joined_df &lt;- nyc_mode_df |&gt;\n  left_join(nyc_annual_df, by = \"YEAR\")\n\nnyc_joined_df2 &lt;- nyc_joined_df |&gt;\n  mutate(SHARE = TOTAL_TRIPS / TOTAL_TRIPS_ALL) |&gt;\n  mutate(SHARE = scales::percent(SHARE, accuracy = 0.1)) |&gt;\n  select(-TOTAL_TRIPS, -TOTAL_TRIPS_ALL)\n\n# pivot wide\n\nnyc_mode_df_pivoted &lt;- pivot_wider(nyc_joined_df2,\n  id_cols = YEAR,\n  names_from = Mode,\n  values_from = SHARE\n)\n\nnyc_mode_df_pivoted |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"NYC Transit System - Relative Shares of UPT by Transportation Mode\"\n  )"
  },
  {
    "objectID": "mp01.html#initial-data-preparation",
    "href": "mp01.html#initial-data-preparation",
    "title": "Mini-Project 01: Fiscal Characteristics of Major US Public Transit Systems",
    "section": "Initial data preparation",
    "text": "Initial data preparation\nIn this part, I created the base table for data analysis using the code provided in the assignment. I also modified column naming convention (as instructed in Task 1) and recoded the values in the ‘Mode’ column to make them easier to understand and use for analysis (as instructed in Task 2). The base table is provided for review after the code block (please note NTD ID and 3 Modes columns are excluded from the preview).\n\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\n\n# Let's start with Fare Revenue\n\nFARES &lt;- readxl::read_xlsx(\"2022_fare_revenue.xlsx\") |&gt;\n  select(\n    -`State/Parent NTD ID`,\n    -`Reporter Type`,\n    -`Reporting Module`,\n    -`TOS`,\n    -`Passenger Paid Fares`,\n    -`Organization Paid Fares`\n  ) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`) |&gt;\n  group_by(\n    `NTD ID`, # Sum over different `TOS` for the same `Mode`\n    `Agency Name`, # These are direct operated and sub-contracted\n    `Mode`\n  ) |&gt; # of the same transit modality\n  # Not a big effect in most munis (significant DO\n  # tends to get rid of sub-contractors), but we'll sum\n  # to unify different passenger experiences\n  summarize(`Total Fares` = sum(`Total Fares`)) |&gt;\n  ungroup()\n\n# Next, expenses\n\nEXPENSES &lt;- readr::read_csv(\"2022_expenses.csv\") |&gt;\n  select(\n    `NTD ID`,\n    `Agency`,\n    `Total`,\n    `Mode`\n  ) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\n# Monthly Transit Numbers\n\nTRIPS &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet = \"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(\n    -`Legacy NTD ID`,\n    -`Reporter Type`,\n    -`Mode/Type of Service Status`,\n    -`UACE CD`,\n    -`TOS`\n  ) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n    names_to = \"Month\",\n    values_to = \"UPT\"\n  ) |&gt;\n  drop_na() |&gt;\n  mutate(Month = my(Month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"ridership.xlsx\", sheet = \"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(\n    -`Legacy NTD ID`,\n    -`Reporter Type`,\n    -`Mode/Type of Service Status`,\n    -`UACE CD`,\n    -`TOS`\n  ) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n    names_to = \"Month\",\n    values_to = \"VRM\"\n  ) |&gt;\n  drop_na() |&gt;\n  group_by(\n    `NTD ID`, `Agency`, `UZA Name`,\n    `Mode`, `3 Mode`, Month\n  ) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(Month = my(Month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\n## Task 1 - Creating syntatic names\n\nnames(USAGE)[3] &lt;- \"Metro_Area\"\n\n## Task 2 - Recoding the Mode column\n\nUSAGE &lt;- USAGE |&gt;\n  mutate(Mode = case_when(\n    Mode == \"HR\" ~ \"Heavy Rail\",\n    Mode == \"DR\" ~ \"Demand Response\",\n    Mode == \"FB\" ~ \"Ferryboat\",\n    Mode == \"MB\" ~ \"Bus\",\n    Mode == \"SR\" ~ \"Streetcar Rail\",\n    Mode == \"TB\" ~ \"Trolleybus\",\n    Mode == \"VP\" ~ \"Vanpool\",\n    Mode == \"CB\" ~ \"Commuter Bus\",\n    Mode == \"RB\" ~ \"Bus Rapid Transit\",\n    Mode == \"LR\" ~ \"Light Rail\",\n    Mode == \"YR\" ~ \"Hybrid Rail\",\n    Mode == \"MG\" ~ \"Monorail Automated Guideway\",\n    Mode == \"CR\" ~ \"Commuter Rail\",\n    Mode == \"AR\" ~ \"Alaska Railroad\",\n    Mode == \"TR\" ~ \"Aerial Tramway\",\n    Mode == \"IP\" ~ \"Inclined Plane\",\n    Mode == \"PB\" ~ \"Publico\",\n    Mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"\n  ))\n\n# base table sampled\n\nsample_n(USAGE, 1000) |&gt;\n  select(-`NTD ID`, -`3 Mode`) |&gt;\n  mutate(Month = as.character(Month)) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini-Project 02: Business of Show Business",
    "section": "",
    "text": "In this paper, we will analyze the IMDB data to answer some questions, design a measurement framework for evaluating performance and identify an opportunity for investment.\n\nData Prep\nIn this section, we obtain and prepare data for analysis. Because of the memory and performance issues, we will use small files and further down-select data to enable a more fluid analysis. We will drop titles with fewer than 100 ratings and individuals who worked on only 1 title.\nInstalling and Loading Libraries\n\n\nShow the code\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\nif (!require(\"psych\")) install.packages(\"psych\")\nlibrary(psych)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"sqldf\")) install.packages(\"sqldf\")\nlibrary(sqldf)\nif (!require(\"plotly\")) install.packages(\"plotly\")\nlibrary(plotly)\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nlibrary(ggplot2)\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\nlibrary(RColorBrewer)\n\n\nReading data in\n\n\nShow the code\n## read files in and create dataframes\n\n\nname_basics &lt;- read.csv((\"name_basics_small.csv\"))\ntitle_basics &lt;- read.csv(\"title_basics_small.csv\")\ntitle_episodes &lt;- read.csv(\"title_episodes_small.csv\")\ntitle_ratings &lt;- read.csv(\"title_ratings_small.csv\")\ntitle_crew &lt;- read.csv(\"title_crew_small.csv\")\ntitle_principals &lt;- read.csv(\"title_principals_small.csv\")\n\n# drop records with fewer than 2 titles from name_basics df\n\nname_basics &lt;- name_basics |&gt;\n  filter(str_count(knownForTitles, \",\") &gt; 1)\n\n# drop records with fewer than 100 ratings from title_ratings df\n\ntitle_ratings &lt;- title_ratings |&gt;\n  filter(numVotes &gt;= 100)\n\n\nFurthermore, to ensure consistency across all data sets, we will apply the same filtering, i.e., excluding titles with fewer than 100 ratings, to the rest of the title tables:\n\n\nShow the code\n# filtering title basics df\n\ntitle_basics &lt;- title_basics |&gt;\n  semi_join(\n    title_ratings,\n    join_by(tconst == tconst)\n  )\n\n# filtering title crew df\n\ntitle_crew &lt;- title_crew |&gt;\n  semi_join(\n    title_ratings,\n    join_by(tconst == tconst)\n  )\n\n# filtering title episodes df on title id\n\ntitle_episodes_1 &lt;- title_episodes |&gt;\n  semi_join(\n    title_ratings,\n    join_by(tconst == tconst)\n  )\n\n# filtering title episodes df on parent title id\n\ntitle_episodes_2 &lt;- title_episodes |&gt;\n  semi_join(\n    title_ratings,\n    join_by(parentTconst == tconst)\n  )\n\n# combining filtered title episodes dfs\n\ntitle_episodes &lt;- bind_rows(\n  title_episodes_1,\n  title_episodes_2\n) |&gt;\n  distinct()\n\n## filtering title principals df\n\ntitle_principals &lt;- title_principals |&gt;\n  semi_join(\n    title_ratings,\n    join_by(tconst == tconst)\n  )\n\n# remove dfs we no longer need\n\nrm(title_episodes_1)\nrm(title_episodes_2)\n\n\n\n\nTask 1\n\nCorrect the column types of the title tables using a combination of mutate and the coercion functions as.numeric and as.logical.\n\nTitle Basics\n\nglimpse(title_basics)\n\nRows: 372,198\nColumns: 9\n$ tconst         &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt…\n$ titleType      &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"…\n$ primaryTitle   &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierrot…\n$ originalTitle  &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierrot…\n$ isAdult        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ startYear      &lt;chr&gt; \"1894\", \"1892\", \"1892\", \"1892\", \"1893\", \"1894\", \"1894\",…\n$ endYear        &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\",…\n$ runtimeMinutes &lt;chr&gt; \"1\", \"5\", \"5\", \"12\", \"1\", \"1\", \"1\", \"1\", \"45\", \"1\", \"1\"…\n$ genres         &lt;chr&gt; \"Documentary,Short\", \"Animation,Short\", \"Animation,Come…\n\n\nColumns startYear,endYear and runtimeMinutes are formatted as character/string in the original data set and need to be changed to be numeric.\n\n## recode column types and rename columns\n\ntitle_basics &lt;- title_basics |&gt;\n  mutate(\n    startYear = as.numeric(startYear),\n    endYear = as.numeric(endYear),\n    runtimeMinutes = as.numeric(runtimeMinutes),\n    isAdult = as.logical(isAdult)\n  ) |&gt;\n  rename(\n    start_year = startYear,\n    end_year = endYear,\n    runtime_minutes = runtimeMinutes\n  )\n\nglimpse(title_basics)\n\nRows: 372,198\nColumns: 9\n$ tconst          &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"t…\n$ titleType       &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", …\n$ primaryTitle    &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierro…\n$ originalTitle   &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierro…\n$ isAdult         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ start_year      &lt;dbl&gt; 1894, 1892, 1892, 1892, 1893, 1894, 1894, 1894, 1894, …\n$ end_year        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ runtime_minutes &lt;dbl&gt; 1, 5, 5, 12, 1, 1, 1, 1, 45, 1, 1, 1, 1, 1, 2, 1, 1, 1…\n$ genres          &lt;chr&gt; \"Documentary,Short\", \"Animation,Short\", \"Animation,Com…\n\n\nTitle Crew\n\nglimpse(title_crew)\n\nRows: 371,902\nColumns: 3\n$ tconst    &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt00000…\n$ directors &lt;chr&gt; \"nm0005690\", \"nm0721526\", \"nm0721526\", \"nm0721526\", \"nm00056…\n$ writers   &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"nm0…\n\n\nThere is no need to correct any data types here.\nTitle Episodes\n\nglimpse(title_episodes)\n\nRows: 3,007,178\nColumns: 4\n$ tconst        &lt;chr&gt; \"tt0045960\", \"tt0046855\", \"tt0048378\", \"tt0048562\", \"tt0…\n$ parentTconst  &lt;chr&gt; \"tt0044284\", \"tt0046643\", \"tt0047702\", \"tt0047768\", \"tt0…\n$ seasonNumber  &lt;chr&gt; \"2\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"3\", \"3\", \"…\n$ episodeNumber &lt;chr&gt; \"3\", \"4\", \"6\", \"10\", \"4\", \"20\", \"5\", \"2\", \"20\", \"6\", \"2\"…\n\n\nseasonNumber and episodeNumber columns need to be converted to numeric format.\n\n## recode column types and rename columns\n\ntitle_episodes &lt;- title_episodes |&gt;\n  mutate(\n    seasonNumber = as.numeric(seasonNumber),\n    episodeNumber = as.numeric(episodeNumber)\n  ) |&gt;\n  rename(\n    season_number = seasonNumber,\n    episode_number = episodeNumber\n  )\n\nglimpse(title_episodes)\n\nRows: 3,007,178\nColumns: 4\n$ tconst         &lt;chr&gt; \"tt0045960\", \"tt0046855\", \"tt0048378\", \"tt0048562\", \"tt…\n$ parentTconst   &lt;chr&gt; \"tt0044284\", \"tt0046643\", \"tt0047702\", \"tt0047768\", \"tt…\n$ season_number  &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 8, 1, 10, 6, 2, 8, …\n$ episode_number &lt;dbl&gt; 3, 4, 6, 10, 4, 20, 5, 2, 20, 6, 2, 3, 2, 10, 17, 5, 1,…\n\n\nTitle Principals\n\nglimpse(title_principals)\n\nRows: 6,586,689\nColumns: 6\n$ tconst     &lt;chr&gt; \"tt0000001\", \"tt0000001\", \"tt0000001\", \"tt0000001\", \"tt0000…\n$ ordering   &lt;int&gt; 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 1, 2, 3, 4,…\n$ nconst     &lt;chr&gt; \"nm1588970\", \"nm0005690\", \"nm0005690\", \"nm0374658\", \"nm0721…\n$ category   &lt;chr&gt; \"self\", \"director\", \"producer\", \"cinematographer\", \"directo…\n$ job        &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"producer\", \"director of photography\", \"\\\\N\",…\n$ characters &lt;chr&gt; \"[\\\"Self\\\"]\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\…\n\n\nThere is no need to correct data types here.\nTitle Ratings\n\nglimpse(title_ratings)\n\nRows: 372,198\nColumns: 3\n$ tconst        &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt0…\n$ averageRating &lt;dbl&gt; 5.7, 5.6, 6.5, 5.4, 6.2, 5.0, 5.4, 5.4, 5.4, 6.8, 5.2, 7…\n$ numVotes      &lt;int&gt; 2090, 283, 2094, 184, 2828, 196, 889, 2233, 214, 7699, 3…\n\n\nThere is no need to correct data types here.\nName Basics\n\nglimpse(name_basics)\n\nRows: 2,460,608\nColumns: 6\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;chr&gt; \"1899\", \"1924\", \"1934\", \"1949\", \"1918\", \"1915\", \"189…\n$ deathYear         &lt;chr&gt; \"1987\", \"2014\", \"\\\\N\", \"1982\", \"2007\", \"1982\", \"1957…\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\n\nbirthYear and deathYear columns need to be formatted as numeric.\n\n## recode column types and rename columns\n\nname_basics &lt;- name_basics |&gt;\n  mutate(\n    birthYear = as.numeric(birthYear),\n    deathYear = as.numeric(deathYear)\n  ) |&gt;\n  rename(\n    birth_year = birthYear,\n    death_year = deathYear\n  )\n\nglimpse(name_basics)\n\nRows: 2,460,608\nColumns: 6\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birth_year        &lt;dbl&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ death_year        &lt;dbl&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\n\n\n\nTask 2 - Instructor-Provided Questions\n\nQ1. How many movies are in our data set? How many TV series? How many TV episodes?\nTo answer this question, we will use the title basics data set, which contains release and production information.\nContent type is captured in the titleType column. We have 131,662 movies, 29,789 TV Series and 155,722 TV episodes.\n\n# get a count of records by content types\n\ndf1 &lt;- title_basics |&gt;\n  group_by(titleType) |&gt;\n  summarize(number_of_records = n()) |&gt;\n  ungroup() |&gt;\n  mutate(number_of_records = comma(number_of_records, digits = 0)) |&gt;\n  rename(title_type = titleType) |&gt;\n  arrange(desc(number_of_records))\n\n# plot the resulting df\n\nfig_content_count_type &lt;- plot_ly(\n  data = df1,\n  y = ~ reorder(title_type, number_of_records),\n  x = ~number_of_records,\n  type = \"bar\",\n  orientation = \"h\",\n  marker = list(color = \"cerulean\"),\n  width = 500,\n  height = 300\n)\n\nfig_content_count_type &lt;- fig_content_count_type |&gt;\n  layout(\n    title = \"Number of Titles by Content Type\",\n    xaxis = list(title = \"Number of Records\"),\n    yaxis = list(title = \"\")\n  )\n\n\nfig_content_count_type\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interaction options.)\n\n\nQ2. Who is the oldest living person in our data set?\nTo answer this question, we will use the name basics table, which has birth and death records. However, a quick examination of data highlights certain irregularities in death records. It appears that we are missing actual death records for a number of individuals who, despite being born prior to the 20th century, are appear to still be alive.\n\n# list living persons by year of birth\n\n# Subset of data - 10 oldest presumably living persons\nname_basics |&gt;\n  filter(is.na(death_year) & !is.na(birth_year)) |&gt;\n  arrange(birth_year) |&gt;\n  head(10) |&gt;\n  gt()\n\n\n\n\n\n\n\nnconst\nprimaryName\nbirth_year\ndeath_year\nprimaryProfession\nknownForTitles\n\n\n\n\nnm5671597\nRobert De Visée\n1655\nNA\ncomposer,soundtrack\ntt2219674,tt1743724,tt0441074,tt14426058\n\n\nnm7807390\nWilliam Sandys\n1767\nNA\ncomposer,soundtrack\ntt4396584,tt3747572,tt4555594,tt0071007\n\n\nnm1441282\nRichard Dybeck\n1811\nNA\nsoundtrack\ntt0021783,tt0022126,tt0036372,tt0037562\n\n\nnm6711738\nAlbert Monnier\n1815\nNA\nwriter\ntt0329972,tt3966780,tt6793558,tt15175930\n\n\nnm1227803\nC. Hostrup\n1818\nNA\nwriter,composer,actor\ntt0031361,tt0134089,tt0844680,tt14463014\n\n\nnm1329526\nEdouard Martin\n1825\nNA\nwriter\ntt0200268,tt0329972,tt3966780,tt0036496\n\n\nnm1197286\nIon Ivanovici\n1845\nNA\ncomposer,soundtrack\ntt0043412,tt0040391,tt1324061,tt0083697\n\n\nnm0179107\nAttilio Corbell\n1850\nNA\nactor\ntt0009508,tt0009121,tt0182770,tt0007472\n\n\nnm0843185\nAndré Sylvane\n1850\nNA\nwriter\ntt0019480,tt0155273,tt0159028,tt0167460\n\n\nnm0242243\nCharles Dungan\n1853\nNA\nactor\ntt0267008,tt0008259,tt0008876,tt0003634\n\n\n\n\n\n\n\n\n# create a df with records of living persons\n\ndf3 &lt;- name_basics |&gt;\n  filter(is.na(death_year) & !is.na(birth_year)) |&gt;\n  group_by(birth_year) |&gt;\n  summarise(number_of_records = n()) |&gt;\n  ungroup() |&gt;\n  arrange(birth_year)\n\n# plot the resulting df\n\nfig_cnt_living_persons &lt;- plot_ly(\n  data = df3,\n  x = ~birth_year,\n  y = ~number_of_records,\n  type = \"bar\",\n  marker = list(color = \"cerulean\"),\n  width = 500,\n  height = 300\n)\n\nfig_cnt_living_persons &lt;- fig_cnt_living_persons |&gt;\n  layout(\n    title = \"Living Persons by Year of Birth\",\n    xaxis = list(title = \"Year of Birth\"),\n    yaxis = list(title = \"Count of Living Persons\")\n  )\n\nfig_cnt_living_persons\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interaction options.)\nSince we can’t manually verify verify hundreds of questionable records, we will have to use a rule-based approach to answer this question. The oldest verified person to have ever lived was 122 years and 164 days at the time of death so using this age as a threshold, we can filter out all individuals born after 1902, which leaves us with 65 individuals born in 1903.\n\n# list count of living persons by year of birth\n\nname_basics |&gt;\n  filter(is.na(death_year) & !is.na(birth_year) & birth_year &gt; 1902) |&gt;\n  group_by(birth_year) |&gt;\n  summarize(number_of_records = n()) |&gt;\n  ungroup() |&gt;\n  arrange(birth_year) |&gt;\n  head(5) |&gt;\n  gt()\n\n\n\n\n\n\n\nbirth_year\nnumber_of_records\n\n\n\n\n1903\n65\n\n\n1904\n77\n\n\n1905\n68\n\n\n1906\n83\n\n\n1907\n78\n\n\n\n\n\n\n\n\n# list living persons born in 1903\ndf4 &lt;- name_basics |&gt;\n  filter(birth_year == 1903 & is.na(death_year)) |&gt;\n  select(primaryName, birth_year, death_year) |&gt;\n  arrange(primaryName)\n\nsample_n(df4, 65) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\nQ3. There is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\nTo answer this question, we need to use 3 data sets, title ratings,title basics and title episodes.\n\n# create df with list of all TV episodes\n\nlist_tv_epis &lt;- title_basics |&gt;\n  filter(titleType == \"tvEpisode\") |&gt;\n  select(tconst, titleType, primaryTitle)\n\n# create df with list of all TV series\n\nlist_tv_series &lt;- title_basics |&gt;\n  filter(titleType == \"tvSeries\") |&gt;\n  select(tconst, titleType, primaryTitle)\n\n# create df with records of tv episodes\n\ntv_ep_df1 &lt;- inner_join(list_tv_epis, title_episodes, by = \"tconst\")\n\n# join ratings data\n\ntv_ep_df2 &lt;- inner_join(tv_ep_df1, title_ratings, by = \"tconst\")\n\n# find a TV episode meeting criteria\n\ntv_ep_df3 &lt;- tv_ep_df2 |&gt;\n  filter((numVotes &gt;= 200000) & (averageRating == 10))\n\n# map tv series name\n\ntv_ep_ratings_df &lt;- inner_join(tv_ep_df3, list_tv_series, by = c(\"parentTconst\" = \"tconst\"))\n\n# rename columns in the resulting df\ntv_ep_ratings_df |&gt;\n  rename(\n    episode_id = tconst,\n    average_rating = averageRating,\n    number_of_ratings = numVotes,\n    title_type = titleType.x,\n    episode_title = primaryTitle.x,\n    series_id = parentTconst,\n    series_name = primaryTitle.y,\n    parent_title_type = titleType.y\n  ) |&gt;\n  gt()\n\n\n\n\n\n\n\nepisode_id\ntitle_type\nepisode_title\nseries_id\nseason_number\nepisode_number\naverage_rating\nnumber_of_ratings\nparent_title_type\nseries_name\n\n\n\n\ntt2301451\ntvEpisode\nOzymandias\ntt0903747\n5\n14\n10\n227589\ntvSeries\nBreaking Bad\n\n\n\n\n\n\n\nThe TV episode with the perfect 10/10 rating and over 200K reviews is Ozymandias ep.15 season 5 of the cult TV hit Breaking Bad.\n\n\nQ4. What four projects is the actor Mark Hamill most known for?\nTo answer this question, we will use name basics and title basics data sets.\n\n# get title records for mark hamill\n\nmh_df &lt;- name_basics |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  select(primaryName, knownForTitles) |&gt;\n  separate_longer_delim(knownForTitles, \",\")\n\n# map titles names and types on the list of selected content IDs\n\nmh_df2 &lt;- inner_join(mh_df, title_basics, by = c(\"knownForTitles\" = \"tconst\"))\nmh_df2 |&gt;\n  select(knownForTitles, titleType, primaryTitle, start_year) |&gt;\n  rename(\n    title_id = knownForTitles,\n    content_type = titleType,\n    content_title = primaryTitle,\n    year = start_year\n  ) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Titles Mark Hamill is Known For\"\n  )\n\n\n\n\n\n\n\nTitles Mark Hamill is Known For\n\n\ntitle_id\ncontent_type\ncontent_title\nyear\n\n\n\n\ntt0076759\nmovie\nStar Wars: Episode IV - A New Hope\n1977\n\n\ntt2527336\nmovie\nStar Wars: Episode VIII - The Last Jedi\n2017\n\n\ntt0080684\nmovie\nStar Wars: Episode V - The Empire Strikes Back\n1980\n\n\ntt0086190\nmovie\nStar Wars: Episode VI - Return of the Jedi\n1983\n\n\n\n\n\n\n\nMark Hamill is known for his roles in the Star Wars movies, where he first starred in 1977 and most recently in 2017.\n\n\nQ5. What TV series, with more than 12 episodes, has the highest average rating?\nTo answer this question, we need 3 data sets - title_episodes, title ratings and title basics.\n\n# we already have a df with all TV series - we created it in a previous question - list_tv_series\n\n# create a df with records of tv series wirh all episodes\n\nep_filtered_series &lt;- inner_join(title_episodes, list_tv_series, by = c(\"parentTconst\" = \"tconst\"))\n\n# df with tv series with 12+ episodes\n\nseries_num_epis &lt;- ep_filtered_series |&gt;\n  group_by(parentTconst, primaryTitle, titleType) |&gt;\n  summarise(number_of_episodes = n()) |&gt;\n  ungroup() |&gt;\n  arrange(desc(number_of_episodes)) |&gt;\n  filter(number_of_episodes &gt;= 12)\n\ndatatable(series_num_epis)\n\n\n\n\n\nWe have over 20K TV series with 12 or more episodes.\n\n# join tv episodes and series data with ratings data\n\nep_filtered_series_ratings &lt;- inner_join(ep_filtered_series,\n  title_ratings,\n  by = \"tconst\"\n)\n\n# drop all tv series with fewer than 12 episodes\n\nep_filtered_series_ratings2 &lt;- inner_join(ep_filtered_series_ratings,\n  series_num_epis,\n  by = \"parentTconst\"\n)\n\n# calculate average ratings for tv series\n\nep_filtered_series_ratings2 |&gt;\n  group_by(parentTconst, primaryTitle.x) |&gt;\n  summarise(average_rating = mean(averageRating)) |&gt;\n  ungroup() |&gt;\n  rename(\n    tv_series_id = parentTconst,\n    tv_series_title = primaryTitle.x\n  ) |&gt;\n  arrange(desc(average_rating)) |&gt;\n  head(5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 TV Series by Average Rating\",\n    subtitle = \"TV series with 12 or more episodes only\"\n  )\n\n\n\n\n\n\n\nTop 5 TV Series by Average Rating\n\n\nTV series with 12 or more episodes only\n\n\ntv_series_id\ntv_series_title\naverage_rating\n\n\n\n\ntt0409579\nMade\n10.0\n\n\ntt11363282\nThe Real Housewives of Salt Lake City\n10.0\n\n\ntt21278628\nCowboys of Thunder\n10.0\n\n\ntt0060008\nThe Milton Berle Show\n9.9\n\n\ntt0168358\nParkinson\n9.9\n\n\n\n\n\n\n\nThere are 3 TV series that obtained the perfect 10/10 rating - ‘Made’,‘The Real Housewives of Salt Lake City’ and ‘Cowboys of Thunder’.\n\n\nQ6. Is it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons?\nTo answer this question, we will use title basics,title episodes and title ratings data sets:\n\n# create df for TV series 'Happy Days'\n\nhd_df1 &lt;- title_basics |&gt;\n  filter(primaryTitle == \"Happy Days\" & titleType == \"tvSeries\")\n\n# join HD df with detailed TV episodes data\nhd_detail &lt;- inner_join(title_episodes, hd_df1, by = c(\"parentTconst\" = \"tconst\"))\n\n# join ratings data to detailed Happy Days records\n\nhd_detail_ratings &lt;- inner_join(hd_detail, title_ratings, by = \"tconst\")\n\ndatatable(hd_detail_ratings)\n\n\n\n\n\nNow that we have detailed records on all episodes of the Happy Days TV series, we can calculate the average rating for each season.\nIt appears that the earlier seasons of the series indeed had higher average ratings compared to the more recent seasons.\n\n# create df with average rating by season\n\navg_hd_detail_ratings &lt;- hd_detail_ratings |&gt;\n  group_by(season_number) |&gt;\n  summarise(avg_rating_season = mean(averageRating)) |&gt;\n  ungroup() |&gt;\n  arrange(season_number)\n\n# plot the resulting df\n\nfig_hd_seasons &lt;- plot_ly(\n  data = avg_hd_detail_ratings,\n  x = ~season_number,\n  y = ~avg_rating_season,\n  type = \"bar\",\n  marker = list(color = \"cerulean\"),\n  width = 500,\n  height = 300\n)\n\nfig_hd_seasons &lt;- fig_hd_seasons |&gt;\n  layout(\n    title = \"Happy Days - Average Rating by Season\",\n    xaxis = list(title = \"Season #\"),\n    yaxis = list(title = \"Average Rating\")\n  )\n\nfig_hd_seasons\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interaction options.)\n\n\n\nTask 3\n\nDesign a ‘success’ measure for IMDb entries, reflecting both quality and broad popular awareness.\n\nAs we found in Q1 in Task1, movies constitute the absolute majority of records in our data - 131.6K records vs 29.8K for TV series, the next largest category of content. We do not include TV episode in this analysis as TV episodes are not a standalone content. Given the obvious differences in production, marketing, and audience appeal, we will focus on movies for this part of the exercise.\n\n# plot number of records by content type from the earlier question\n\nfig_content_count_type\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interaction options.)\nLet’s start with creating a data frame with ratings data for movies.\n\n# create df with list of all movies\n\nlist_movies &lt;- title_basics |&gt;\n  filter(titleType == \"movie\") |&gt;\n  select(tconst, titleType, primaryTitle, start_year, genres, runtime_minutes, isAdult)\n\n# join with ratings data\n\nmovie_ratings_df &lt;- inner_join(list_movies, title_ratings, by = \"tconst\")\n\nmovie_ratings_df2 &lt;- movie_ratings_df |&gt;\n  rename(\n    title = primaryTitle,\n    title_id = tconst,\n    content_type = titleType,\n    year = start_year,\n    average_rating = averageRating,\n    number_of_votes = numVotes\n  )\n\n# sample movie df\n\nsample_n(movie_ratings_df2, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\nNext we will conduct an explanatory data analysis on our movies data set to better understand the two ratings metrics.\n\n# subset metrics\n\nmovie_ratings_df2_metrics &lt;- movie_ratings_df2 |&gt;\n  select(average_rating, number_of_votes)\n\n# describe metrics\n\nsummary(movie_ratings_df2_metrics)\n\n average_rating   number_of_votes  \n Min.   : 1.000   Min.   :    100  \n 1st Qu.: 5.200   1st Qu.:    195  \n Median : 6.100   Median :    459  \n Mean   : 5.923   Mean   :   8694  \n 3rd Qu.: 6.800   3rd Qu.:   1664  \n Max.   :10.000   Max.   :2942823  \n\n\n\n# histogram of average ratings\n\n# plot a histogram of number of ratings in plotly\navg_ratings_x &lt;- movie_ratings_df2$average_rating\n\nfig_hist_avg_ratings &lt;- plot_ly(\n  x = avg_ratings_x,\n  type = \"histogram\",\n  nbinsx = 100,\n  marker = list(color = \"cerulean\")\n) |&gt;\n  layout(\n    title = \"Distribution of Average Movie Ratings\",\n    xaxis = list(title = \"Average Rating\"),\n    yaxis = list(title = \"Frequency\")\n  )\n\nfig_hist_avg_ratings\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interaction options.)\n\n# histogram of average ratings\n\n# plot a histogram of number of ratings in plotly\n\nnum_ratings_x &lt;- movie_ratings_df2$number_of_votes\n\nfig_distr_number_ratings &lt;- plot_ly(\n  x = num_ratings_x,\n  type = \"histogram\",\n  nbinsx = 80,\n  marker = list(color = \"cerulean\")\n) |&gt;\n  layout(\n    title = \"Distribution of Movie Ratings\",\n    xaxis = list(title = \"Number of Ratings\"),\n    yaxis = list(type = \"log\", title = \"Frequency (Log-Scaled)\")\n  )\n\nfig_distr_number_ratings\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interaction options.)\nLooking at descriptive statistics and statistical plots, we can see that most titles have relatively high average ratings. 50% of all titles have a rating above 6.1, and top 25% of titles have a rating over 6.8. Distribution of number of ratings, on the other hand, has a right skew, meaning that we have only a handful of titles with a very high number of votes.\nSince we need to design a blended performance metric, we need to account for quality and popularity of a title simultaneously which can be done by an averaging of these two metrics. Before we proceed, we need to standardize the data to account for differences in magnitude and distribution of ratings and votes variables:\n\n# calculate mean and standard deviation for ratings and votes data\n\nmovie_ratings_df3 &lt;- movie_ratings_df2 |&gt;\n  mutate(\n    avg_ratings_movies = mean(average_rating),\n    avg_number_ratings = mean(number_of_votes),\n    sd_avg_ratings = sd(average_rating),\n    sd_number_ratings = sd(number_of_votes)\n  )\n\nsample_n(movie_ratings_df3, 1000) |&gt;\n  DT::datatable(options = list(\n    pageLength = 5\n  ))\n\n\n\n\n\nNow we can create standardized metrics for ratings and votes, as well as the blended performance index reflecting the quality of the movie (via average rating) and the popularity of the movie (via number of ratings), with equal weight given to each input.\n\n# create standardized metrics for votes and ratings\n\nmovie_ratings_df4 &lt;- movie_ratings_df3 |&gt;\n  mutate(\n    score_rating = round((average_rating - avg_ratings_movies) / sd_avg_ratings, 2),\n    score_votes = round((number_of_votes - avg_number_ratings) / sd_number_ratings, 2),\n    performance_index = round((score_rating + score_votes) / 2, 2)\n  )\n\nsample_n(movie_ratings_df4, 1000) |&gt;\n  DT::datatable(options = list(\n    pageLength = 5\n  ))\n\n\n\n\n\n\n# descriptive statistics for performance index\n\nmovie_ratings_df4_pi &lt;- movie_ratings_df4 |&gt;\n  select(performance_index)\n\nsummary(movie_ratings_df4_pi)\n\n performance_index  \n Min.   :-1.990000  \n 1st Qu.:-0.360000  \n Median : 0.030000  \n Mean   : 0.000264  \n 3rd Qu.: 0.310000  \n Max.   :27.490000  \n\n\n\n# histogram of performance index\n\npi_x2 &lt;- movie_ratings_df4$performance_index\n\nfig7 &lt;- plot_ly(\n  x = pi_x2,\n  type = \"histogram\",\n  nbinsx = 200,\n  marker = list(color = \"blue\")\n) |&gt;\n  layout(\n    title = \"Distribution of Movie Performance Indices\",\n    xaxis = list(title = \"Performance Index\"),\n    yaxis = list(title = \"Frequency\")\n  )\n\nfig7\n\n\n\n\n\n\n# % of titles with negative PI\n\nmovie_ratings_df4_pi |&gt;\n  summarise(\n    titles_with_negative_pi = sum(performance_index &lt; 0),\n    all_titles = n()\n  ) |&gt;\n  mutate(share_of_titles_with_negative_pi = round(titles_with_negative_pi / all_titles, 2)) |&gt;\n  gt()\n\n\n\n\n\n\n\ntitles_with_negative_pi\nall_titles\nshare_of_titles_with_negative_pi\n\n\n\n\n61673\n131662\n0.47\n\n\n\n\n\n\n\nPerformance index penalizes titles with subpar, i.e., below average, popularity and/or quality. 47% of movies in our data set have negative performance index.\n\nPerformance Index Validation\n\n1.Choose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\n\n\n# top 5 movies\n\nmrdf &lt;- movie_ratings_df4 |&gt;\n  select(title, year, genres, average_rating, number_of_votes, performance_index)\n\nmrdf |&gt;\n  arrange(performance_index) |&gt;\n  slice_max(performance_index, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 Movies by Peformance Index\"\n  )\n\n\n\n\n\n\n\nTop 5 Movies by Peformance Index\n\n\ntitle\nyear\ngenres\naverage_rating\nnumber_of_votes\nperformance_index\n\n\n\n\nThe Shawshank Redemption\n1994\nDrama\n9.3\n2942823\n27.49\n\n\nThe Dark Knight\n2008\nAction,Crime,Drama\n9.0\n2922922\n27.20\n\n\nInception\n2010\nAction,Adventure,Sci-Fi\n8.8\n2595555\n24.20\n\n\nFight Club\n1999\nDrama\n8.8\n2374722\n22.23\n\n\nForrest Gump\n1994\nDrama,Romance\n8.8\n2301630\n21.57\n\n\n\n\n\n\n\nAmong top 5 movies based on performance index, four (with the exception of The Shawshank Redemption) were commercial successes, and The Shawshank Redemption is still widely considered to be one of the beloved and most critically acclaimed movies of all times.\n\n\nChoose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\n\n\n\n# add this to top line to change plot size: , fig.width=4,fig.height=4}\n\n\n# plot ratings and votes data\n\ngfig &lt;- ggplot(data = movie_ratings_df2, aes(x = average_rating, y = number_of_votes)) +\n  geom_point(size = 1, color = \"blue\") +\n  labs(\n    title = \"Movie Quality (Average Rating) and Popularity (Number of Ratings)\",\n    x = \"Average Rating\",\n    y = \"Number of Ratings\"\n  ) +\n  theme_minimal() +\n  theme_bw() +\n  scale_x_log10(label = scales::comma) +\n  scale_y_log10(label = scales::comma)\n\n\ngfig\n\n\n\n\n\n\n\n\nAs seen on this chart, we should have a decent number of movies with average rating of 1-2 and 80K-100K number of ratings, so we will look up titles meeting these criteria:\n\nmovie_ratings_df4 |&gt;\n  filter(average_rating &lt; 3 & number_of_votes &gt;= 75000) |&gt;\n  arrange(desc(performance_index)) |&gt;\n  select(title, year, genres, average_rating, number_of_votes, performance_index) |&gt;\n  gt()\n\n\n\n\n\n\n\ntitle\nyear\ngenres\naverage_rating\nnumber_of_votes\nperformance_index\n\n\n\n\nRadhe\n2021\nAction,Crime,Thriller\n1.9\n180205\n-0.04\n\n\nAdipurush\n2023\nAction,Adventure,Drama\n2.7\n133981\n-0.13\n\n\nMeet the Spartans\n2008\nComedy,Fantasy\n2.8\n112199\n-0.29\n\n\nEpic Movie\n2007\nAdventure,Comedy,Fantasy\n2.4\n110222\n-0.47\n\n\nBattlefield Earth\n2000\nAction,Adventure,Sci-Fi\n2.5\n83786\n-0.66\n\n\nDragonball Evolution\n2009\nAction,Adventure,Fantasy\n2.5\n80118\n-0.70\n\n\nDisaster Movie\n2008\nComedy,Sci-Fi\n1.9\n95170\n-0.80\n\n\nJustin Bieber: Never Say Never\n2011\nDocumentary,Music\n1.7\n76466\n-1.04\n\n\nSadak 2\n2020\nAction,Drama\n1.2\n96825\n-1.06\n\n\n\n\n\n\n\nIndeed, these movies score very poorly on the performance index, and while they have a relatively large volume of ratings, they also have low average ratings.\n\n\nChoose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\n\n\nSteven Spielberg, one of the most famous and successful directors of our time, has 4 very successful projects with performance index of ranging from 4.65 to 14.54, which puts these titles in top 1% of all movies in our data set.\n\n# get title records for Steven Spielberg\n\nbp_df &lt;- name_basics |&gt;\n  filter(primaryName == \"Steven Spielberg\") |&gt;\n  select(primaryName, knownForTitles) |&gt;\n  separate_longer_delim(knownForTitles, \",\")\n\n# map titles names and types on the list of selected content IDs\n\nbp_df2 &lt;- inner_join(bp_df, title_basics, by = c(\"knownForTitles\" = \"tconst\"))\nbp_df3 &lt;- bp_df2 |&gt;\n  select(primaryName, knownForTitles, titleType, primaryTitle) |&gt;\n  rename(\n    name = primaryName,\n    title_id = knownForTitles,\n    content_type = titleType,\n    content_title = primaryTitle\n  )\n\n# select performance index and title\nmovie_pi_df &lt;- movie_ratings_df4 |&gt;\n  select(title_id, average_rating, number_of_votes, performance_index)\n\n# join to SS records\nbp_df4 &lt;- inner_join(bp_df3, movie_pi_df, by = \"title_id\")\ndatatable(bp_df4)\n\n\n\n\n\n\n# percentiles for performance index\n\nquantile(movie_ratings_df4$performance_index, probs = c(0, 0.125, 0.375, 0.625, 0.875, 0.9, 0.95, 0.99, 1))\n\n   0% 12.5% 37.5% 62.5% 87.5%   90%   95%   99%  100% \n-1.99 -0.67 -0.16  0.16  0.51  0.58  0.78  2.00 27.49 \n\n\n\n\nPerform at least one other form of ‘spot check’ validation.\n\n\nAvatar, the highest-grossing movie of all times ($2.9B worldwide gross) has a performance index of 13.2, which puts it in top 1% of our data set.\n\n# select performance index and title\n\nmovie_ratings_df4 |&gt;\n  select(title, genres, year, average_rating, number_of_votes, performance_index) |&gt;\n  filter((title == \"Avatar\") & (year == 2009)) |&gt;\n  gt()\n\n\n\n\n\n\n\ntitle\ngenres\nyear\naverage_rating\nnumber_of_votes\nperformance_index\n\n\n\n\nAvatar\nAction,Adventure,Fantasy\n2009\n7.9\n1402915\n13.2\n\n\n\n\n\n\n\n\n\nCome up with a numerical threshold for a project to be a ‘success’; that is, determine a value such that movies above are all “solid” or better.\n\n\n\n# percentiles for performance index\n\nquantile(movie_ratings_df4$performance_index, probs = c(0, 0.10, 0.20, 0.40, 0.50, 0.60, 0.80, 0.95, 1))\n\n   0%   10%   20%   40%   50%   60%   80%   95%  100% \n-1.99 -0.74 -0.47 -0.12  0.03  0.12  0.38  0.78 27.49 \n\n\nWe will use 0.38 (top 20% score cutoff) as a threshold of success - titles with performance index of 0.38 or higher are high performers.\n\n\nTask 4: Trends in Success Over Time\nWe need to review our records in the context of distribution of titles by decade and genre.\nDue to a low volume of production and a stable share of successful productions over time, we can exclude data prior to 1970.\n\n# add new columns for decade and success\nmovie_ratings_df4 &lt;- movie_ratings_df4 |&gt;\n  mutate(\n    decade = floor(year / 10) * 10,\n    success_flag = case_when(\n      performance_index &gt; 0.38 ~ 1,\n      performance_index &lt;= 0.38 ~ 0\n    )\n  )\n\nmovie_ratings_df4_agg_decade &lt;- movie_ratings_df4 |&gt;\n  select(title_id, title, genres, decade, year, performance_index, success_flag) |&gt;\n  group_by(decade) |&gt;\n  summarise(\n    number_of_titles = n(),\n    number_of_successes = sum(success_flag == 1),\n    number_of_flops = sum(success_flag == 0)\n  ) |&gt;\n  ungroup()\n\n# plot the resulting df\n\nfig_decade &lt;- plot_ly(\n  data = movie_ratings_df4_agg_decade,\n  x = ~decade,\n  y = ~number_of_successes,\n  type = \"bar\",\n  name = \"number of successes\",\n  #  marker = list(color = \"blue\"),\n  width = 500,\n  height = 300\n) |&gt;\n  add_trace(y = ~number_of_flops, name = \"number of flops\")\n\n\nfig_decade &lt;- fig_decade |&gt;\n  layout(\n    title = \"Titles by Decade\",\n    xaxis = list(title = \"Decade\"),\n    yaxis = list(title = \"Count of Titles\"),\n    barmode = \"stack\"\n  )\n\nfig_decade\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interactive options.)\n\n# create a df for genres\n\nmovie_ratings_df4_agg_genres &lt;- movie_ratings_df4 |&gt;\n  select(title_id, title, genres, decade, year, performance_index, success_flag) |&gt;\n  group_by(genres) |&gt;\n  summarise(\n    number_of_titles = n(),\n    number_of_successes = sum(success_flag == 1),\n    number_of_flops = sum(success_flag == 0)\n  ) |&gt;\n  arrange(desc(number_of_titles)) |&gt;\n  ungroup()\n\n# plot the resulting df\n\nfig_genres &lt;- plot_ly(\n  data = movie_ratings_df4_agg_genres,\n  x = ~ reorder(genres, -number_of_titles),\n  y = ~number_of_titles,\n  type = \"bar\",\n  marker = list(color = \"blue\")\n)\n\nfig_genres &lt;- fig_genres |&gt;\n  layout(\n    title = \"Count of Titles by Genre\",\n    xaxis = list(\n      title = \"Genres\",\n      tickangle = -45,\n      tickfont = list(size = 8)\n    ),\n    yaxis = list(title = \"Count of Titles\")\n  )\n\nfig_genres\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interactive options.)\nWe have a very large number of genres with only a handful of titles, so we can exclude these records from our data set to ensure our analysis is as robust as possible.\n\n# top 20 genres by count of titles\n\nmovie_ratings_df4_top20_genres &lt;- movie_ratings_df4_agg_genres |&gt;\n  slice_max(number_of_titles, n = 20)\n\n# subset data by decade and aggregate count successes and flops\n\nmovie_ratings_df4_decade_genres &lt;- movie_ratings_df4 |&gt;\n  filter(year &gt;= 1970) |&gt;\n  select(title_id, title, genres, decade, year, success_flag) |&gt;\n  group_by(genres, decade) |&gt;\n  summarise(\n    number_of_titles = n(),\n    number_of_successes = sum(success_flag == 1),\n    number_of_flops = sum(success_flag == 0)\n  ) |&gt;\n  mutate(percent_of_success = round(number_of_successes / number_of_titles, 2)) |&gt;\n  ungroup()\n\nmovie_ratings_df4_decade_genres_filtered &lt;- inner_join(movie_ratings_df4_decade_genres,\n  movie_ratings_df4_top20_genres,\n  by = \"genres\"\n) |&gt;\n  select(genres, decade, number_of_titles.x, number_of_successes.x, number_of_flops.x, percent_of_success) |&gt;\n  rename(\n    number_of_titles = number_of_titles.x,\n    number_of_successes = number_of_successes.x,\n    number_of_flops = number_of_flops.x\n  )\n\ndatatable(movie_ratings_df4_decade_genres_filtered)\n\n\n\n\n\n\n1.What was the genre with the most “successes” in each decade?\n\nDrama produced more successes than other genres in 1970s (292 titles), 1980s (341 titles),and 1990s (334 titles). Starting in 2000s, Documentary took over with 747 successes in 2000s, 1290 successes in 2010, and 593 successful titles in 2020.\n\n# subset successes by genre and decade\n\nmovie_ratings_df4_decade_genres_filtered_successes_pw &lt;- pivot_wider(\n  movie_ratings_df4_decade_genres_filtered,\n  id_cols = genres,\n  names_from = decade,\n  values_from = number_of_successes\n)\n\n\n\ndatatable(movie_ratings_df4_decade_genres_filtered_successes_pw)\n\n\n\n\n\n\n\nWhat genre consistently has the most “successes”?\n\n\nDrama and documentary collectively produced more successes than other genres (2915 and 2868, respectively), with Documentary emerging as a leading genre in recent decades (2000- present).\n\ngp1 &lt;- ggplot(\n  movie_ratings_df4_decade_genres_filtered,\n  aes(x = decade, y = number_of_successes)\n) +\n  geom_col(fill = \"green4\") +\n  labs(\n    title = \"Successful Productions by Genre\",\n    x = \"Decade\",\n    y = \"Successful Productions\"\n  ) +\n  geom_text(aes(label = number_of_successes),\n    position = position_stack(vjust = 2), # Place labels outside the bars\n    size = 2\n  ) +\n  facet_grid(. ~ genres) +\n  facet_wrap(~genres, ncol = 4, strip.position = \"top\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 8),\n    axis.text.y = element_text(size = 8),\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_text(size = 10),\n    plot.title = element_text(hjust = 0.5, size = 14)\n  )\n\ngp1\n\n\n\n\n\n\n\n\n\n\nWhat genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\n\n\n\n# create a custom color palette\npalette_genres3 &lt;- c(\n  \"dodgerblue2\", \"#E31A1C\", \"green4\", \"#6A3D9A\", \"#FF7F00\",\n  \"black\", \"yellow\", \"skyblue2\", \"#FB9A99\", \"palegreen2\",\n  \"#CAB2D6\", \"#FDBF6F\", \"gray70\", \"khaki2\", \"maroon\",\n  \"orchid1\", \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\",\n  \"green1\", \"yellow4\", \"yellow3\", \"darkorange4\", \"brown\"\n)\n\n# create a chart\n\nfig_top20g &lt;- plot_ly(movie_ratings_df4_decade_genres_filtered,\n  x = ~decade, y = ~percent_of_success,\n  color = ~genres,\n  type = \"scatter\",\n  mode = \"lines\",\n  colors = palette_genres3\n) |&gt;\n  layout(\n    title = \"Top 20 Genres - Percent of Success by Decade\",\n    xaxis = list(title = \"\"),\n    yaxis = list(\n      title = \"Percent of Success\",\n      tickformat = \".0%\",\n      range = c(0, 1)\n    ),\n    legend = list(\n      orientation = \"h\", # Horizontal legend\n      x = 0.5, # Center horizontally\n      xanchor = \"center\", # Align center\n      y = -0.2, # Position below the plot\n      font = list(size = 8) # Smaller font size\n    )\n  )\n\n# Show the plot\n\nfig_top20g\n\n\n\n\n\n(Please note it’s an interactive chart - hover over it for interactive options.)\nDocumentary has produced most successful titles since 2010 (1883 titles) and it has the best success rate of all genres..\n\n4.What genre has become more popular in recent years?\n\nThere has been a spike in success rate for Action genre, going from 5% in 2010s to 21% in 2020s.\nBased on success rate, documentary is a clear standout and should be prioritized for investment opportunity.\n\n\nTask 5: Key Personnel\n\nIdentify (at least) two actors and one director who you will target as the key talent for your movie. Write a short “pitch” as to why they are likely to be successful. You should support your pitch with at least one graphic and one table.\n\nSince we are going to be developing a documentary title, we need to adjust this question a bit and identify a director-writer team as opposed to a director-actors team.\n\n# get a list of titles in documentary genre, made after 1970 , with sufficient level of awareness and high performance index and map director and writer info\n\ndoc_df1 &lt;- sqldf(\n  \"\n    with a as(\n    select title_id,\n    title,\n    decade,\n    performance_index,\n    average_rating,\n    number_of_votes,\n    success_flag\n    from movie_ratings_df4\n    where 1=1\n    and genres='Documentary'\n    and year&gt;=1970\n   and success_flag=1\nand number_of_votes&gt;=5000\n    )\n    select a.*,\n    t.directors,\n    t.writers,\n    n.primaryName as director_name,\n    n2.primaryName as writer_name,\n    tb.start_year\n    from a\n    inner join title_crew t\n    on a.title_id=t.tconst\n    inner join name_basics n\n    on directors=n.nconst\n    inner join name_basics n2\n    on t.writers=n2.nconst\n    inner join title_basics tb\n    on a.title_id=tb.tconst\n    order by a.performance_index desc, a.number_of_votes desc, a.average_rating desc\n\n    ;\n  \"\n)\n\n# calculate performance statistics for director-writer teams\n\ndoc_df2 &lt;- sqldf(\n  \"\nselect director_name,\nwriter_name,\ndirector_name||'-'||writer_name as movie_team,\ncount(title_id) as cnt_movies,\nround(avg(performance_index),2) as avg_performance_index,\nround(avg(average_rating),1) as avg_rating,\nround(avg(number_of_votes),0) as avg_number_of_ratings\nfrom doc_df1\ngroup by 1,2,3\nhaving count(title_id)&gt;1\norder by 4 desc\n    ;\n  \"\n)\n\ndatatable(doc_df2)\n\n\n\n\n\nLooking at the high-performing documentaries from 1970s - present, 3 film makers have produced multiple successful titles: Werner Herzog, Michael Moore and the director-writer duo of Sophie Fiennes and Slavoj Zizek. Since we need to identify a team for our next project, we propose to approach the Fiennes-Zizek duo as they have already demonstrated they can successfully work together, which might not be the case for established solo creators Moore and Herzog.\n\n# plot movie team data\n\n\nfig_movie_team &lt;- plot_ly(\n  data = doc_df2,\n  x = ~avg_rating,\n  y = ~avg_number_of_ratings,\n  type = \"scatter\",\n  mode = \"markers\",\n  marker = list(size = 10),\n  color = ~movie_team\n) |&gt;\n  layout(\n    title = \"Movie Team Performance Comparison\",\n    xaxis = list(title = \"Quality (Average Rating)\"),\n    yaxis = list(\n      title = \"Popularity (Number of Ratings)\"\n    ),\n    legend = list(\n      orientation = \"h\", # Horizontal legend\n      x = 0.5, # Center horizontally\n      xanchor = \"center\", # Align center\n      y = -0.2\n    )\n  )\n\nfig_movie_team\n\n\n\n\n\nTitles produced by Moore and Herzog appear to have a higher awareness among viewers but Fiennes-Zizek work is not far behind, and a more polarizing topic and a targeted marketing and PR campaign can help address this slight shortcoming.\n\n\nTask 6: Finding a Classic Movie to Remake\n\nFind a classic movie to remake with your key talent. The original should have a large number of IMDb ratings, a high average rating, and not have been remade in the past 25 years.\n\nWhen looking at the top documentary titles, Super Size Me is a definite outlier: Super Size Me premiered at the 2004 Sundance Film Festival, where Morgan Spurlock won the Grand Jury Prize for directing the film.The film opened in the US on May 7, 2004, and grossed a total of $11,536,423 worldwide, making it the 7th highest-grossing documentary film of all time.It was nominated for an Academy Award for Best Documentary Feature and won the award for Best Documentary Screenplay from the Writers Guild of America. (Source).\nA 2017 title Super Size Me 2: Holy Chicken! from the same director also performed reasonably well, even in the light of certain issues with with publicity and distribution. It’s important to note that this film was not a remake of a original title as it was focused on the process of opening a fast-food restaurant. (Source)\nGiven the success of the 2004 ‘Super Size Me’ and increasing popularity of the semaglutide drugs, we should consider making a documentary about a weight loss journey and impact of taking this medicine on one’s life, health and mind - a ‘Super Size Me’ journey in reverse. While this movie was released 20 years ago, cultural context, relevancy and timeliness play a huge role in documentary titles success, and for this topic the time is definitely now. Another reason to pursue this opportunity now is an unhappy one as Morgan Spurlock, the writer and director of both ‘Super Size Me’ titles, died in May of this year so re imagining his most famous work could serve as a tribute to Spurlock’s many talents and the impact his vision and creative genius left on our society. As a possible contributor to our project, we can consider Lee Fulkerson, who wrote and directed an award-winning and highly acclaimed documentary Forks Over Knives as he has already successfully explored the topic of self-improvement in his 2011 movie (performance index of 0.73).\n\n\nTask 7: Write and Deliver Your Pitch\nFrom Sophie Fiennes and Slavoj Zizek, the masters of philosophical and psychoanalytical exploration, and Lee Fulkerson, the visionary mind behind an inspiring story of human transformation, inspired by a critically acclaimed hit Super Size Me, comes the modern take on a timeless tale of metamorphosis, obsession and desire to be perfect at any cost. XXS Me: The Beginning coming to Netflix in December 2025."
  },
  {
    "objectID": "mp03_nodata_load.html",
    "href": "mp03_nodata_load.html",
    "title": "Mini-Project 03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "In this paper, we will investigate the claim that the US Electoral College systematically biases election results away from the popular vote.\n\nData Prep\nIn this section, we obtain and prepare data for analysis.\nInstalling and Loading Libraries\n\n\nShow the code\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\nif (!require(\"psych\")) install.packages(\"psych\")\nlibrary(psych)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"sqldf\")) install.packages(\"sqldf\")\nlibrary(sqldf)\nif (!require(\"plotly\")) install.packages(\"plotly\")\nlibrary(plotly)\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nlibrary(ggplot2)\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\nlibrary(RColorBrewer)\n\n\n\n\nTask 3: Exploration of Vote Count Data\n\nQ1. Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\n## read in presidential elections data\n\npres&lt;-read.csv(\"president_1976_2020.csv\")\n#head(pres)\n\n# read in house election vote data \n\nhouse&lt;-read.csv(\"house_1976_2022.csv\")\n#head(house)\n\n\n## create a df with house results for 1976 and 2022\n\nhouse_1976_and_2022 &lt;- sqldf(\n  \"\n   with h76 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=1976\n   group by 1\n   )\n   ,\n   h22 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=2022\n   group by 1\n   )\n   , \n   base as (\n   select h76.state,\n   h76.num_seats,\n   case\n   when h76.num_seats=0 then 1 \n   else h76.num_seats\n   end as number_of_seats_1976,\n   h22.num_seats,\n   case\n   when h22.num_seats=0 then 1 \n   else h22.num_seats\n   end as number_of_seats_2022\n   from h76\n   left join h22\n   on h76.state=h22.state\n   )\n   \n   select state,\n   number_of_seats_1976,\n   number_of_seats_2022,\n   number_of_seats_2022 - number_of_seats_1976 as delta \n   from base \n    ;\n  \"\n)\n\n\n# display states with largest gains in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n   slice_max(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Gains in House Seats\"\n  )\n\n\n\n\n\n\n\nTop 5 States with Largest Gains in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nTEXAS\n24\n38\n14\n\n\nFLORIDA\n15\n28\n13\n\n\nCALIFORNIA\n43\n52\n9\n\n\nARIZONA\n4\n9\n5\n\n\nGEORGIA\n10\n14\n4\n\n\n\n\n\n\n\n\n# display states with largest losses in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n   slice_min(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Losses in House Seats\"\n  )\n\n\n\n\n\n\n\nTop 5 States with Largest Losses in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nNEW YORK\n39\n26\n-13\n\n\nOHIO\n23\n15\n-8\n\n\nPENNSYLVANIA\n25\n17\n-8\n\n\nILLINOIS\n24\n17\n-7\n\n\nMICHIGAN\n19\n13\n-6\n\n\n\n\n\n\n\n\n\nQ2. New York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent). Are there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\nFirst, let’s find states, years, and districts where fusion system was in place\n\n#get a count of political parties candidates received votes from\nhouse_temp1 &lt;- house %&gt;%\n  group_by(state, year, district, candidate) |&gt;\n  summarize(distinct_party_count = n_distinct(party))\n\n#get a list of districts where candidates received votes from more than 1 party\nhouse_temp2&lt;-house_temp1 |&gt;\n  filter(distinct_party_count&gt;1)\n\n#get a list of all years, states and districts where fusion system was used\nhouse_temp3&lt;- house_temp2 |&gt;\n  group_by(state, year, district)\n\n# subset house df to only include results from states, years and districts meeting the criteria \n\nhouse_fusion1 &lt;- inner_join(house,house_temp3, by=c(\"state\"=\"state\",\"year\"=\"year\",\"district\"=\"district\"))\n\n# get elections totals for each candidate in states/years/districts meeting the criteria\nhouse_fusion1_actuals&lt;-house_fusion1 |&gt;\n  group_by(year,state,district,candidate.x) |&gt;\n  summarise(actual_total_votes=sum(candidatevotes)) |&gt;\n  mutate(max_votes=max(actual_total_votes)) |&gt;\n  mutate(is_actual_winner=case_when(actual_total_votes==max_votes ~1,\n                             TRUE ~0)) |&gt;\n  ungroup()\n\n# get candidate votes from their primary party only and determine a winner\n house_fusion1_primaryonly&lt;-house_fusion1 |&gt;\n  filter(party=='DEMOCRAT' | party=='REPUBLICAN') |&gt;\n  group_by(year,state,district,candidate.x) |&gt;\n  summarise(actual_primaryparty_votes=sum(candidatevotes)) |&gt;\n  mutate(max_primary_votes=max(actual_primaryparty_votes)) |&gt;\n  mutate(is_primaryvotesonly_winner=case_when(actual_primaryparty_votes==max_primary_votes ~1,\n                             TRUE ~0)) \n\n#merge 2 datasets\nhouse_fusion_merged&lt;-left_join(house_fusion1_actuals,\n                               house_fusion1_primaryonly,\n                               by=c(\"state\"=\"state\",\n                                    \"year\"=\"year\",\n                                    \"district\"=\"district\",\n                                    \"candidate.x\"=\"candidate.x\")\n                               )\n#filter for records where primary party is either D or R and determine if results would have been different\nhouse_fusion_merged_filtered&lt;-house_fusion_merged |&gt;\n  select(year,state,district,candidate.x,actual_total_votes,actual_primaryparty_votes,is_actual_winner,is_primaryvotesonly_winner) |&gt;\n  mutate(same_winner=case_when(is_actual_winner==is_primaryvotesonly_winner ~1,\n                             TRUE ~0)) |&gt;\n  filter((same_winner==0) & !is.na(actual_primaryparty_votes))\n  \n#display results\nhouse_fusion_merged_filtered |&gt;\n  rename(candidate=candidate.x) |&gt;\n   gt() |&gt;\n  tab_header(\n    title = \"Elections With  Different Results In The Absense of Fusion System\"\n  )\n\n\n\n\n\n\n\nElections With Different Results In The Absense of Fusion System\n\n\nyear\nstate\ndistrict\ncandidate\nactual_total_votes\nactual_primaryparty_votes\nis_actual_winner\nis_primaryvotesonly_winner\nsame_winner\n\n\n\n\n1976\nNEW YORK\n29\nEDWARD W PATTISON\n100663\n95361\n1\n0\n0\n\n\n1976\nNEW YORK\n29\nJOSEPH A MARTINO\n96476\n96476\n0\n1\n0\n\n\n1980\nNEW YORK\n3\nGREGORY W CARMAN\n175904\n149736\n1\n0\n0\n\n\n1980\nNEW YORK\n3\nJEROME A AMBRO JR\n166778\n150778\n0\n1\n0\n\n\n1980\nNEW YORK\n6\nJOHN LEBOUTILLIER\n179524\n143676\n1\n0\n0\n\n\n1980\nNEW YORK\n6\nLESTER L WOLFF\n160418\n148638\n0\n1\n0\n\n\n1984\nNEW YORK\n20\nJOSEPH J DIOGUARDI\n106958\n93518\n1\n0\n0\n\n\n1984\nNEW YORK\n20\nOREN J TEICHER\n102842\n102842\n0\n1\n0\n\n\n1986\nNEW YORK\n27\nGEORGE C WORTLEY\n166860\n154350\n1\n0\n0\n\n\n1986\nNEW YORK\n27\nROSEMARY S POOLER\n164982\n162266\n0\n1\n0\n\n\n1992\nCONNECTICUT\n2\nEDWARD W MUNSTER\n119416\n119416\n0\n1\n0\n\n\n1992\nCONNECTICUT\n2\nSAM GEJDENSON\n123291\n83197\n1\n0\n0\n\n\n1992\nNEW YORK\n3\nPETER T KING\n124727\n108574\n1\n0\n0\n\n\n1992\nNEW YORK\n3\nSTEVE A ORLINS\n116915\n116915\n0\n1\n0\n\n\n1994\nNEW YORK\n1\nGEORGE J HOCHBRUECKNER\n160292\n157384\n0\n1\n0\n\n\n1994\nNEW YORK\n1\nMICHAEL P FORBES\n180982\n144090\n1\n0\n0\n\n\n1996\nNEW YORK\n1\nMICHAEL P FORBES\n233240\n180002\n1\n0\n0\n\n\n1996\nNEW YORK\n1\nNORA L BREDES\n192992\n187632\n0\n1\n0\n\n\n1996\nNEW YORK\n30\nFRANCIS J PORDUM\n200080\n195372\n0\n1\n0\n\n\n1996\nNEW YORK\n30\nJACK QUINN\n242738\n194640\n1\n0\n0\n\n\n2000\nCONNECTICUT\n2\nROB SIMMONS\n114380\n110239\n1\n0\n0\n\n\n2000\nCONNECTICUT\n2\nSAM GEJDENSON\n111520\n111520\n0\n1\n0\n\n\n2006\nNEW YORK\n25\nDAN MAFFEI\n214216\n201210\n0\n1\n0\n\n\n2006\nNEW YORK\n25\nJAMES T WALSH\n221050\n182374\n1\n0\n0\n\n\n2006\nNEW YORK\n29\nERIC J MASSA\n200088\n189218\n0\n1\n0\n\n\n2006\nNEW YORK\n29\nJOHN R \"RANDY\" KUHL JR\n212154\n182766\n1\n0\n0\n\n\n2010\nNEW YORK\n13\nMICHAEL E MCMAHON\n60773\n60773\n0\n1\n0\n\n\n2010\nNEW YORK\n13\nMICHAEL G GRIMM\n65024\n55821\n1\n0\n0\n\n\n2010\nNEW YORK\n19\nJOHN J HALL\n98766\n98766\n0\n1\n0\n\n\n2010\nNEW YORK\n19\nNAN HAYMORTH\n109956\n88734\n1\n0\n0\n\n\n2010\nNEW YORK\n24\nMICHAEL A ARCURI\n89809\n89809\n0\n1\n0\n\n\n2010\nNEW YORK\n24\nRICHARD L HANNA\n101599\n85702\n1\n0\n0\n\n\n2010\nNEW YORK\n25\nANN MARIE BUERKLE\n104602\n81380\n1\n0\n0\n\n\n2010\nNEW YORK\n25\nDANIEL B MAFFEI\n103954\n103954\n0\n1\n0\n\n\n2012\nNEW YORK\n27\nCHRIS COLLINS\n322440\n274500\n1\n0\n0\n\n\n2012\nNEW YORK\n27\nKATHLEEN C HOCHUL\n312438\n280016\n0\n1\n0\n\n\n2018\nNEW YORK\n1\nLEE M ZELDIN\n278054\n243124\n1\n0\n0\n\n\n2018\nNEW YORK\n1\nPERRY GERSHON\n255982\n248426\n0\n1\n0\n\n\n2018\nNEW YORK\n24\nDANA BALTER\n246452\n231804\n0\n1\n0\n\n\n2018\nNEW YORK\n24\nJOHN M KATKO\n273840\n227076\n1\n0\n0\n\n\n2018\nNEW YORK\n27\nCHRIS COLLINS\n280292\n229012\n1\n0\n0\n\n\n2018\nNEW YORK\n27\nNATHAN D MCMURRAY\n278118\n256334\n0\n1\n0\n\n\n2022\nNEW YORK\n4\nANTHONY P D’ESPOSITO\n140622\n129353\n1\n0\n0\n\n\n2022\nNEW YORK\n4\nLAURA A GILLEN\n130871\n130871\n0\n1\n0\n\n\n2022\nNEW YORK\n17\nMICHAEL V LAWLER\n287100\n251476\n1\n0\n0\n\n\n2022\nNEW YORK\n17\nSEAN PATRICK MALONEY\n283460\n266914\n0\n1\n0\n\n\n2022\nNEW YORK\n22\nBRANDON M WILLIAMS\n135544\n116529\n1\n0\n0\n\n\n2022\nNEW YORK\n22\nFRANCIS CONOLE\n132913\n132913\n0\n1\n0\n\n\n\n\n\n\n\n\n#display a list of states, years and districts where election results would have been different\n\nhouse_fusion_merged_filtered |&gt;\n  select(year,state,district,is_actual_winner) |&gt;\n  group_by(year,state,district)|&gt;\n  summarise(num_elections=sum(is_actual_winner)) |&gt;\n  ungroup() |&gt;\n  select(-num_elections) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Summary - Elections With  Different Results In The Absense of Fusion System\"\n  )\n\n\n\n\n\n\n\nSummary - Elections With Different Results In The Absense of Fusion System\n\n\nyear\nstate\ndistrict\n\n\n\n\n1976\nNEW YORK\n29\n\n\n1980\nNEW YORK\n3\n\n\n1980\nNEW YORK\n6\n\n\n1984\nNEW YORK\n20\n\n\n1986\nNEW YORK\n27\n\n\n1992\nCONNECTICUT\n2\n\n\n1992\nNEW YORK\n3\n\n\n1994\nNEW YORK\n1\n\n\n1996\nNEW YORK\n1\n\n\n1996\nNEW YORK\n30\n\n\n2000\nCONNECTICUT\n2\n\n\n2006\nNEW YORK\n25\n\n\n2006\nNEW YORK\n29\n\n\n2010\nNEW YORK\n13\n\n\n2010\nNEW YORK\n19\n\n\n2010\nNEW YORK\n24\n\n\n2010\nNEW YORK\n25\n\n\n2012\nNEW YORK\n27\n\n\n2018\nNEW YORK\n1\n\n\n2018\nNEW YORK\n24\n\n\n2018\nNEW YORK\n27\n\n\n2022\nNEW YORK\n4\n\n\n2022\nNEW YORK\n17\n\n\n2022\nNEW YORK\n22\n\n\n\n\n\n\n\nBased on these results, we can ascertain that the use of fusion system in election barely has any discernible effect on the outcome as the election results would have been different only in a handful of cases.\n\n\nQ3. Do presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state? Does this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\n# get a df with results of presidential elections by state. \n\npres_df1&lt;- sqldf(\n  \"\n  with a as(\n  select year,\n  state,\n  candidate,\n  party_simplified as party,\n  candidatevotes as votes\n  from pres\n  where 1=1\n  and PARTY_SIMPLIFIED in ('DEMOCRAT','REPUBLICAN')\n  GROUP BY 1,2,3,4\n  )\n  ,\n  b as (\n  select a.*,\n  row_number() over(partition by year,state order by votes desc) as is_winner\n  from a\n  )\n  \n  select year,\n  state,\n  candidate,\n  party,\n  votes,\n  case\n  when is_winner=1 then 1 else 0 end as is_pres_winner\n  from b\n  ;\n  \"\n)\n\n\n# get a df with records for house elections filtered to D and R only\n\nhouse_prim_only&lt;-house |&gt;\n  filter(party=='DEMOCRAT' | party=='REPUBLICAN') |&gt;\n  group_by(year,state,party) |&gt;\n  summarize(total_party_votes=sum(candidatevotes)) |&gt;\n  ungroup()\n\n#determine  max votes by year/state elections\nhouse_prim_only_agg &lt;- house_prim_only %&gt;%\n  group_by(year, state) %&gt;%\n  summarize(max_votes = max(total_party_votes, na.rm = TRUE)) |&gt;\n  ungroup()\n  \n#merge 2 dfs\n\nhouse_prim_only_merged&lt;-left_join(house_prim_only,\n                                  house_prim_only_agg,\n                                  by=c(\"state\"=\"state\",\"year\"=\"year\"))\n#identify a winning party\n\nhouse_prim_only_merged2&lt;-house_prim_only_merged |&gt;\n  mutate(house_party_winner=case_when(total_party_votes==max_votes ~1,\n                             TRUE ~0))\n\n\n#join dfs with house and presidential results \n\nhouse_pres_merged&lt;-inner_join(pres_df1,\n                              house_prim_only_merged2,\n                              by=c(\"year\"=\"year\",\n                                   \"state\"=\"state\",\n                                   \"party\"=\"party\"))\n#rename columns for clarity\n\nhouse_pres_merged_for_plot&lt;-house_pres_merged |&gt;\n  select(year,state,candidate,party,votes,is_pres_winner,total_party_votes,house_party_winner) |&gt;\n  rename(presidential_votes=votes,\n         is_party_winner=house_party_winner\n         ) |&gt;\n  mutate(president_more_votes=case_when(presidential_votes&gt;total_party_votes~1,\n                                        TRUE~0)) |&gt;\n  mutate(delta_votes=presidential_votes-total_party_votes)\n\n\n#create a df for D party\ndem_party&lt;-house_pres_merged_for_plot |&gt;\n  filter(party=='DEMOCRAT') |&gt;\n  group_by(state) |&gt;\n  summarize(D_president_more_popular_than_cogress=sum(president_more_votes),\n            D_pct_of_all_elections=D_president_more_popular_than_cogress/12,\n            D_avg_difference_votes=mean(delta_votes)\n            ) |&gt;\n  ungroup() |&gt;\n  mutate(D_avg_difference_rank=rank(-D_avg_difference_votes,ties.method='first'))\n  \n#create a df for R party\nrep_party&lt;-house_pres_merged_for_plot |&gt;\n  filter(party=='REPUBLICAN') |&gt;\n  group_by(state) |&gt;\n  summarize(R_president_more_popular_than_cogress=sum(president_more_votes),\n            R_pct_of_all_elections=R_president_more_popular_than_cogress/12,\n            R_avg_difference_votes=mean(delta_votes)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(R_avg_difference_rank=rank(-R_avg_difference_votes,ties.method='first'))\n            \n            \n\n#join 2 dfs\ndem_rep_df&lt;-inner_join(dem_party,rep_party,by=c(\"state\"=\"state\"))\n\n#display\ndem_rep_df |&gt;\n  DT::datatable(options = list(\n    pageLength = 51\n  ))\n\n\n\n\n\nLooking at Democratic party, we"
  },
  {
    "objectID": "no_data_load_mp03.html",
    "href": "no_data_load_mp03.html",
    "title": "Mini-Project 03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "In this mini-project, we will investigate the claim that the US Electoral College systematically biases election results away from the popular vote.\n\nData Prep\nFirst, we will obtain and prepare data for analysis.\nInstalling and Loading Libraries\n\n\nShow the code\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\nif (!require(\"psych\")) install.packages(\"psych\")\nlibrary(psych)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"sqldf\")) install.packages(\"sqldf\")\nlibrary(sqldf)\nif (!require(\"plotly\")) install.packages(\"plotly\")\nlibrary(plotly)\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nlibrary(ggplot2)\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\nlibrary(RColorBrewer)\nif (!require(\"sf\")) install.packages(\"sf\")\nlibrary(sf)\n\n\n\n\nTask 1.Download Congressional Shapefiles 1976-2012\n\n\nShow the code\ntd &lt;- tempdir()\n\nfor (i in 94:112) {\n  fname &lt;- paste0(\"districts\", formatC(i, width = 3, format = \"d\", flag = \"0\"), \".zip\")\n\n  if (!file.exists(fname)) {\n    url &lt;- paste0(\"https://cdmaps.polisci.ucla.edu/shp/\", fname)\n\n    download.file(url, destfile = fname)\n\n    zip_contents &lt;- unzip(fname, exdir = td)\n    shp_file &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\n    sf_data &lt;- read_sf(shp_file)\n\n    assign(paste0(\"districts\", formatC(i, width = 3, format = \"d\", flag = \"0\"), \"_sf\"), sf_data)\n  }\n}\n\n\n\n\nTask 2.Download Congressional Shapefiles 2014-2022\n\n\nShow the code\nfor (i in 2014:2022) {\n  BASE_URL &lt;- \"https://www2.census.gov/geo/tiger/\"\n  if (i &gt;= 2018) {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd116.zip\")\n  } else if (i &gt; 2015) {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd115.zip\")\n  } else {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd114.zip\")\n  }\n  download_name &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \".zip\")\n\n  if (!file.exists(download_name)) {\n    FILE_URL &lt;- paste0(BASE_URL, file)\n    print(FILE_URL)\n    download.file(FILE_URL, destfile = download_name, mode = \"wb\")\n  }\n}\n\n\n\n\nTask 3: Exploration of Vote Count Data\n\n\nQ1. Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\n\n\n\nShow the code\n## read in presidential elections data\n\npres &lt;- read.csv(\"president_1976_2020.csv\")\n# head(pres)\n\n# read in house election vote data\n\nhouse &lt;- read.csv(\"house_1976_2022.csv\")\n# head(house)\n\n## create a df with house results for 1976 and 2022\n\nhouse_1976_and_2022 &lt;- sqldf(\n  \"\n   with h76 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=1976\n   group by 1\n   )\n   ,\n   h22 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=2022\n   group by 1\n   )\n   ,\n   base as (\n   select h76.state,\n   h76.num_seats,\n   case\n   when h76.num_seats=0 then 1\n   else h76.num_seats\n   end as number_of_seats_1976,\n   h22.num_seats,\n   case\n   when h22.num_seats=0 then 1\n   else h22.num_seats\n   end as number_of_seats_2022\n   from h76\n   left join h22\n   on h76.state=h22.state\n   )\n\n   select state,\n   number_of_seats_1976,\n   number_of_seats_2022,\n   number_of_seats_2022 - number_of_seats_1976 as delta\n   from base\n    ;\n  \"\n)\n\n\n# display states with largest gains in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n  slice_max(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Gains in House Seats\"\n  )\n\n\n\n\n\n\n\n\nTop 5 States with Largest Gains in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nTEXAS\n24\n38\n14\n\n\nFLORIDA\n15\n28\n13\n\n\nCALIFORNIA\n43\n52\n9\n\n\nARIZONA\n4\n9\n5\n\n\nGEORGIA\n10\n14\n4\n\n\n\n\n\n\n\nTexas, Florida, California, Arizona and Georgia had largest gains in house seats between 1976 and 2022.\n\n\nShow the code\n# display states with largest losses in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n  slice_min(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Losses in House Seats\"\n  )\n\n\n\n\n\n\n\n\nTop 5 States with Largest Losses in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nNEW YORK\n39\n26\n-13\n\n\nOHIO\n23\n15\n-8\n\n\nPENNSYLVANIA\n25\n17\n-8\n\n\nILLINOIS\n24\n17\n-7\n\n\nMICHIGAN\n19\n13\n-6\n\n\n\n\n\n\n\nNew York, Ohio, Pennsylvania, Illinois and Michigan had largest losses in house seats between 1976 and 2022.\n\nQ2. New York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent). Are there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\n\nFirst, let’s find states, years, and districts where fusion system was used in elections.\n\n\nShow the code\n# get a count of political parties candidates received votes from\nhouse_temp1 &lt;- house %&gt;%\n  group_by(state, year, district, candidate) |&gt;\n  summarize(distinct_party_count = n_distinct(party))\n\n# get a list of districts where candidates received votes from more than 1 party\nhouse_temp2 &lt;- house_temp1 |&gt;\n  filter(distinct_party_count &gt; 1)\n\n# get a list of all years, states and districts where fusion system was used\nhouse_temp3 &lt;- house_temp2 |&gt;\n  group_by(state, year, district)\n\n# subset house df to only include results from states, years and districts meeting the criteria\n\nhouse_fusion1 &lt;- inner_join(house, house_temp3, by = c(\"state\" = \"state\", \"year\" = \"year\", \"district\" = \"district\"))\n\n# get elections totals for each candidate in states/years/districts meeting the criteria\nhouse_fusion1_actuals &lt;- house_fusion1 |&gt;\n  group_by(year, state, district, candidate.x) |&gt;\n  summarise(actual_total_votes = sum(candidatevotes)) |&gt;\n  mutate(max_votes = max(actual_total_votes)) |&gt;\n  mutate(is_actual_winner = case_when(\n    actual_total_votes == max_votes ~ 1,\n    TRUE ~ 0\n  )) |&gt;\n  ungroup()\n\n# get candidate votes from their primary party only and determine a winner\nhouse_fusion1_primaryonly &lt;- house_fusion1 |&gt;\n  filter(party == \"DEMOCRAT\" | party == \"REPUBLICAN\") |&gt;\n  group_by(year, state, district, candidate.x) |&gt;\n  summarise(actual_primaryparty_votes = sum(candidatevotes)) |&gt;\n  mutate(max_primary_votes = max(actual_primaryparty_votes)) |&gt;\n  mutate(is_primaryvotesonly_winner = case_when(\n    actual_primaryparty_votes == max_primary_votes ~ 1,\n    TRUE ~ 0\n  ))\n\n# merge 2 datasets\nhouse_fusion_merged &lt;- left_join(house_fusion1_actuals,\n  house_fusion1_primaryonly,\n  by = c(\n    \"state\" = \"state\",\n    \"year\" = \"year\",\n    \"district\" = \"district\",\n    \"candidate.x\" = \"candidate.x\"\n  )\n)\n# filter for records where primary party is either D or R and determine if results would have been different\nhouse_fusion_merged_filtered &lt;- house_fusion_merged |&gt;\n  select(year, state, district, candidate.x, actual_total_votes, actual_primaryparty_votes, is_actual_winner, is_primaryvotesonly_winner) |&gt;\n  mutate(same_winner = case_when(\n    is_actual_winner == is_primaryvotesonly_winner ~ 1,\n    TRUE ~ 0\n  )) |&gt;\n  filter((same_winner == 0) & !is.na(actual_primaryparty_votes))\n\n# display results\n# house_fusion_merged_filtered |&gt;\n#  rename(candidate=candidate.x) |&gt;\n#   gt() |&gt;\n#  tab_header(\n#    title = \"Elections With  Different Results In The Absense of Fusion System\"\n#  )\n\n\n# display a list of states, years and districts where election results would have been different\n\nhouse_fusion_merged_filtered |&gt;\n  select(year, state, district, is_actual_winner) |&gt;\n  group_by(year, state, district) |&gt;\n  summarise(num_elections = sum(is_actual_winner)) |&gt;\n  ungroup() |&gt;\n  select(-num_elections) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"List of Elections With  Different Results\"\n  )\n\n\n\n\n\n\n\n\nList of Elections With Different Results\n\n\nyear\nstate\ndistrict\n\n\n\n\n1976\nNEW YORK\n29\n\n\n1980\nNEW YORK\n3\n\n\n1980\nNEW YORK\n6\n\n\n1984\nNEW YORK\n20\n\n\n1986\nNEW YORK\n27\n\n\n1992\nCONNECTICUT\n2\n\n\n1992\nNEW YORK\n3\n\n\n1994\nNEW YORK\n1\n\n\n1996\nNEW YORK\n1\n\n\n1996\nNEW YORK\n30\n\n\n2000\nCONNECTICUT\n2\n\n\n2006\nNEW YORK\n25\n\n\n2006\nNEW YORK\n29\n\n\n2010\nNEW YORK\n13\n\n\n2010\nNEW YORK\n19\n\n\n2010\nNEW YORK\n24\n\n\n2010\nNEW YORK\n25\n\n\n2012\nNEW YORK\n27\n\n\n2018\nNEW YORK\n1\n\n\n2018\nNEW YORK\n24\n\n\n2018\nNEW YORK\n27\n\n\n2022\nNEW YORK\n4\n\n\n2022\nNEW YORK\n17\n\n\n2022\nNEW YORK\n22\n\n\n\n\n\n\n\n\n\nShow the code\ncnt_fusion_elections &lt;- sqldf(\n  \"\n  select 'all fusion elections' as elections,\n  count(distinct year||state||district) as count_elections\n  from house_fusion_merged\n  group by 1\n\n  union all\n\n  select 'fusion elections with different outcomes' as elections,\n  count(distinct year||state||district) as count_elections\n  from house_fusion_merged\n  where 1=1\n  and is_actual_winner!=is_primaryvotesonly_winner\n  group by 1\n  ;\n  \"\n)\n\ncnt_fusion_elections |&gt;\n  gt()\n\n\n\n\n\n\n\n\nelections\ncount_elections\n\n\n\n\nall fusion elections\n754\n\n\nfusion elections with different outcomes\n24\n\n\n\n\n\n\n\nBased on these results, we ascertain that the use of fusion system in elections has no discernible effect on the outcome as the results would have been different only in a handful of cases (24 out of 754 elections, or 3.2%).\n\nQ3. Do presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state? Does this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\nTo answer these questions, first we need to get results of Presidential and Congressional elections for every state for 12 years when Presidential elections were held. (You can look up results of individual states in the table below.)\n\n\nShow the code\n# get a df with results of presidential elections by state filtered to R and D candidates only\n\npres_df1 &lt;- sqldf(\n  \"\n  with a as(\n  select year,\n  state,\n  candidate,\n  party_simplified as party,\n  candidatevotes as votes\n  from pres\n  where 1=1\n  and PARTY_SIMPLIFIED in ('DEMOCRAT','REPUBLICAN')\n  GROUP BY 1,2,3,4\n  )\n  ,\n  b as (\n  select a.*,\n  row_number() over(partition by year,state order by votes desc) as is_winner\n  from a\n  )\n\n  select year,\n  state,\n  candidate,\n  party,\n  votes,\n  case\n  when is_winner=1 then 1 else 0 end as is_pres_winner\n  from b\n  ;\n  \"\n)\n\n\n# get a df with records for house elections filtered to D and R only\n\nhouse_prim_only &lt;- house |&gt;\n  filter(party == \"DEMOCRAT\" | party == \"REPUBLICAN\") |&gt;\n  group_by(year, state, party) |&gt;\n  summarize(total_party_votes = sum(candidatevotes)) |&gt;\n  ungroup()\n\n# determine  max votes by year/state elections\nhouse_prim_only_agg &lt;- house_prim_only %&gt;%\n  group_by(year, state) %&gt;%\n  summarize(max_votes = max(total_party_votes, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# merge 2 dfs\n\nhouse_prim_only_merged &lt;- left_join(house_prim_only,\n  house_prim_only_agg,\n  by = c(\"state\" = \"state\", \"year\" = \"year\")\n)\n\n# identify a winning party in congressional election\n\nhouse_prim_only_merged2 &lt;- house_prim_only_merged |&gt;\n  mutate(house_party_winner = case_when(\n    total_party_votes == max_votes ~ 1,\n    TRUE ~ 0\n  ))\n\n\n# join dfs with house and presidential results\n\nhouse_pres_merged &lt;- inner_join(pres_df1,\n  house_prim_only_merged2,\n  by = c(\n    \"year\" = \"year\",\n    \"state\" = \"state\",\n    \"party\" = \"party\"\n  )\n)\n# rename columns for clarity\n\nhouse_pres_merged_for_plot &lt;- house_pres_merged |&gt;\n  select(year, state, candidate, party, votes, is_pres_winner, total_party_votes, house_party_winner) |&gt;\n  rename(\n    presidential_votes = votes,\n    is_party_winner = house_party_winner\n  ) |&gt;\n  mutate(president_more_votes = case_when(\n    presidential_votes &gt; total_party_votes ~ 1,\n    TRUE ~ 0\n  )) |&gt;\n  mutate(delta_votes = presidential_votes - total_party_votes)\n\n# create a df for D party\ndem_party &lt;- house_pres_merged_for_plot |&gt;\n  filter(party == \"DEMOCRAT\") |&gt;\n  group_by(state) |&gt;\n  summarize(\n    D_president_more_popular_than_cogress = sum(president_more_votes),\n    D_president_more_popular_share = D_president_more_popular_than_cogress / 12,\n    D_avg_difference_votes = mean(delta_votes)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(D_avg_delta_votes_ranked = rank(-D_avg_difference_votes, ties.method = \"first\"))\n\n# create a df for R party\nrep_party &lt;- house_pres_merged_for_plot |&gt;\n  filter(party == \"REPUBLICAN\") |&gt;\n  group_by(state) |&gt;\n  summarize(\n    R_president_more_popular_than_cogress = sum(president_more_votes),\n    R_president_more_popular_share = R_president_more_popular_than_cogress / 12,\n    R_avg_difference_votes = mean(delta_votes)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(R_avg_delta_votes_ranked = rank(-R_avg_difference_votes, ties.method = \"first\"))\n\n\n\n# join 2 dfs\ndem_rep_df &lt;- inner_join(dem_party, rep_party, by = c(\"state\" = \"state\"))\n\n# display the data\ndem_rep_df |&gt;\n  mutate(\n    R_president_more_popular_share = scales::percent(R_president_more_popular_share),\n    D_president_more_popular_share = scales::percent(D_president_more_popular_share),\n    R_avg_difference_votes = format(round(as.numeric(R_avg_difference_votes), 0), nsmall = 0, big.mark = \",\"),\n    D_avg_difference_votes = format(round(as.numeric(D_avg_difference_votes), 0), nsmall = 0, big.mark = \",\")\n  ) |&gt;\n  DT::datatable(\n    options = list(pageLength = 5),\n    filter = \"top\"\n  )\n\n\n\n\n\n\nNow that we have records with Presidential and Congress election results for all states, we can answer this question. Across all states in 12 elections, Democratic candidates had more votes than all Congressional candidates from Democratic party in 53% of all cases. For Republican candidates, this number was even higher at 65%.\n\n\nShow the code\ndem_rep_df %&gt;%\n  summarise(D_president_more_popular = mean(D_president_more_popular_share, na.rm = TRUE), R_president_more_popular = mean(R_president_more_popular_share, na.rm = TRUE)) %&gt;%\n  mutate(\n    D_president_more_popular = scales::percent(D_president_more_popular),\n    R_president_more_popular = scales::percent(R_president_more_popular)\n  ) |&gt;\n  ungroup()\n\n\n# A tibble: 1 × 2\n  D_president_more_popular R_president_more_popular\n  &lt;chr&gt;                    &lt;chr&gt;                   \n1 53%                      65%                     \n\n\n\n\nShow the code\n## display df by state\n\n\n# display the data\ndem_rep_df_plot &lt;- dem_rep_df |&gt;\n  select(state, R_president_more_popular_share, D_president_more_popular_share) |&gt;\n  mutate(\n    D_president_more_popular_share = scales::percent(D_president_more_popular_share),\n    R_president_more_popular_share = scales::percent(R_president_more_popular_share)\n  )\n\ndem_rep_df_plot |&gt;\n  gt()\n\n\n\n\n\n\n\n\nstate\nR_president_more_popular_share\nD_president_more_popular_share\n\n\n\n\nALABAMA\n91.7%\n58.3%\n\n\nALASKA\n25.0%\n58.3%\n\n\nARIZONA\n50.0%\n66.7%\n\n\nARKANSAS\n66.7%\n75.0%\n\n\nCALIFORNIA\n75.0%\n58.3%\n\n\nCOLORADO\n58.3%\n75.0%\n\n\nCONNECTICUT\n75.0%\n66.7%\n\n\nDELAWARE\n41.7%\n75.0%\n\n\nFLORIDA\n75.0%\n83.3%\n\n\nGEORGIA\n50.0%\n58.3%\n\n\nHAWAII\n83.3%\n33.3%\n\n\nIDAHO\n66.7%\n25.0%\n\n\nILLINOIS\n58.3%\n66.7%\n\n\nINDIANA\n75.0%\n16.7%\n\n\nIOWA\n41.7%\n66.7%\n\n\nKANSAS\n33.3%\n66.7%\n\n\nKENTUCKY\n66.7%\n66.7%\n\n\nLOUISIANA\n91.7%\n100.0%\n\n\nMAINE\n50.0%\n25.0%\n\n\nMARYLAND\n58.3%\n58.3%\n\n\nMASSACHUSETTS\n83.3%\n0.0%\n\n\nMICHIGAN\n75.0%\n50.0%\n\n\nMINNESOTA\n66.7%\n41.7%\n\n\nMISSISSIPPI\n83.3%\n50.0%\n\n\nMISSOURI\n75.0%\n41.7%\n\n\nMONTANA\n58.3%\n16.7%\n\n\nNEBRASKA\n0.0%\n83.3%\n\n\nNEVADA\n66.7%\n58.3%\n\n\nNEW HAMPSHIRE\n66.7%\n66.7%\n\n\nNEW JERSEY\n75.0%\n66.7%\n\n\nNEW MEXICO\n50.0%\n50.0%\n\n\nNEW YORK\n83.3%\n91.7%\n\n\nNORTH CAROLINA\n75.0%\n25.0%\n\n\nNORTH DAKOTA\n75.0%\n16.7%\n\n\nOHIO\n66.7%\n66.7%\n\n\nOKLAHOMA\n83.3%\n58.3%\n\n\nOREGON\n75.0%\n25.0%\n\n\nPENNSYLVANIA\n58.3%\n66.7%\n\n\nRHODE ISLAND\n58.3%\n41.7%\n\n\nSOUTH CAROLINA\n66.7%\n66.7%\n\n\nSOUTH DAKOTA\n58.3%\n25.0%\n\n\nTENNESSEE\n91.7%\n75.0%\n\n\nTEXAS\n66.7%\n50.0%\n\n\nUTAH\n66.7%\n8.3%\n\n\nVERMONT\n50.0%\n66.7%\n\n\nVIRGINIA\n58.3%\n91.7%\n\n\nWASHINGTON\n66.7%\n41.7%\n\n\nWEST VIRGINIA\n100.0%\n0.0%\n\n\nWISCONSIN\n58.3%\n66.7%\n\n\nWYOMING\n58.3%\n33.3%\n\n\n\n\n\n\n\n\n\nShow the code\n# plot states data\n\ndem_rep_plot1 &lt;- plot_ly(\n  data = dem_rep_df,\n  x = ~R_president_more_popular_share,\n  y = ~D_president_more_popular_share,\n  type = \"scatter\",\n  mode = \"markers\",\n  marker = list(size = 5),\n  color = ~state\n) |&gt;\n  layout(\n    title = \"\",\n    xaxis = list(\n      title = \"Popularity of R president vs Congress\",\n      font = 8,\n      tickfont = list(size = 8),\n      titlefont = list(size = 8)\n    ),\n    yaxis = list(\n      title = \"Popularity of D president vs Congress\",\n      font = 8,\n      tickfont = list(size = 8),\n      titlefont = list(size = 8)\n    ),\n    legend = list(\n      font = list(size = 8),\n      orientation = \"h\", # Horizontal legend\n      x = 0.5, # Center horizontally\n      xanchor = \"center\", # Align center\n      y = -0.2,\n      font = 8\n    )\n  )\n\ndem_rep_plot1\n\n\n\n\n\n\nConsistently with our previous findings, most states tend to favor presidential candidates more so than Congressional candidates, with this trend being more pronounced for Republican candidates. Notable exceptions are Nebraska, Alaska, Kansas, Delaware and Iowa, where Republican presidential candidates tend to receive fewer votes than Congressional hopefuls.\n\n\nShow the code\ndem_win_year &lt;- house_pres_merged_for_plot |&gt;\n  filter((party == \"DEMOCRAT\") & (president_more_votes == 1)) |&gt;\n  group_by(year, party) |&gt;\n  summarise(share_states_president_popular = n() / 51) |&gt;\n  ungroup()\n\nrep_win_year &lt;- house_pres_merged_for_plot |&gt;\n  filter((party == \"REPUBLICAN\") & (president_more_votes == 1)) |&gt;\n  group_by(year, party) |&gt;\n  summarise(share_states_president_popular = n() / 51) |&gt;\n  ungroup()\n\ndem_rep_win_for_plot &lt;- bind_rows(dem_win_year, rep_win_year)\n\ndem_rep_win_for_plot2 &lt;- dem_rep_win_for_plot |&gt;\n  ungroup()\n\n\n\n\nShow the code\n# create a chart\n\ndrplot2 &lt;- plot_ly(\n  data = dem_rep_win_for_plot2,\n  x = ~year, y = ~share_states_president_popular,\n  color = ~party,\n  type = \"scatter\",\n  mode = \"lines+markers\"\n) |&gt;\n  layout(\n    title = \"Share of States Favoring Presidential Candidates over Congressional\",\n    xaxis = list(title = \"\"),\n    yaxis = list(\n      title = \"Share of States\",\n      tickformat = \".0%\",\n      range = c(0, 1)\n    ),\n    legend = list(\n      orientation = \"h\", # Horizontal legend\n      x = 0.5, # Center horizontally\n      xanchor = \"center\", # Align center\n      y = -0.2, # Position below the plot\n      font = list(size = 8) # Smaller font size\n    )\n  )\n\ndrplot2\n\n\n\n\n\n\nAs we can see on this chart, in Democratic party, presidential candidates are slowly but surely becoming more popular than their Congressional peers over last 30 years, changes in preferences of Republican electorate are more drastic.\n\n\nTask 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results\n\nUsing the data you downloaded earlier, create a chloropleth visualization of the electoral college results for the 2000 presidential election (Bush vs. Gore), coloring each state by the party that won the most votes in that state.\n\n\n\nShow the code\n# create a df with presidential election data\n\npres2000 &lt;- sqldf(\n  \"\n  with a as(\n  select year,state,state_po,\n  sum(case when party_simplified='DEMOCRAT' THEN candidatevotes else 0 end) as dem_votes,\n  sum(case when party_simplified='REPUBLICAN' THEN candidatevotes else 0 end) as rep_votes\n  from pres\n  where 1=1\n  and year=2000\n  and party_simplified in ('DEMOCRAT','REPUBLICAN')\n  group by 1,2,3\n  )\n  select year,\n  state_po,\n  dem_votes,\n  rep_votes,\n  case\n  when dem_votes&gt;rep_votes then 'Democrat' else 'Republican' end as party_won\n  from a\n  ;\n  \"\n)\n\n# create a df with ecv data\n\nhouse2000 &lt;- sqldf(\n  \"\n   with h20 as (\n   select\n   state_po,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=2000\n   group by 1\n   )\n  ,\n  base as (\n   select\n   state_po,\n   case\n   when num_seats=0 then 1\n   else num_seats\n   end as number_of_seats2000\n   from h20\n  )\n  select\n  state_po,\n  number_of_seats2000+2 as ecv\n  from base\n    ;\n  \"\n)\n\n# join 2 dfs\necv20_df &lt;- inner_join(house2000, pres2000, by = c(\"state_po\" = \"state_po\"))\n\n## -get a shapefile of us states\n\ntd &lt;- tempdir()\nzip_contents_task5 &lt;- unzip(\"tl_2020_us_state.zip\",\n  exdir = td\n)\n\nfname_shp_task5 &lt;- zip_contents_task5[grepl(\"shp$\", zip_contents_task5)]\ncongress2020_sf &lt;- read_sf(fname_shp_task5)\n\n# subset data - we only need state abbreviations and coordinates\nstate_map1 &lt;- congress2020_sf |&gt;\n  select(STUSPS, geometry)\n\n# create a df with state boundaries and election data\nel20_for_map &lt;- inner_join(state_map1, ecv20_df, by = c(\"STUSPS\" = \"state_po\"))\n\n\n# create a plot for 2000 presidential election\nggplot(\n  el20_for_map,\n  aes(\n    geometry = geometry,\n    fill = party_won\n  )\n) +\n  geom_sf() +\n  scale_fill_manual(values = c(\n    \"Democrat\" = \"blue\",\n    \"Republican\" = \"red\"\n  ))\n\n\n\n\n\n\n\n\n\n\n\nTask 6: Advanced Chloropleth Visualization of Electoral College Results\n\nModify your previous code to make either a faceted version showing election results over time.\n\n\n\nShow the code\n# create a df with presidential election data\n\npres_elections_temp &lt;- pres |&gt;\n  filter(party_simplified == \"DEMOCRAT\" | party_simplified == \"REPUBLICAN\") |&gt;\n  group_by(year, state_po, party_simplified) |&gt;\n  summarize(votes = sum(candidatevotes))\n\n# head(pres_elections_temp)\n\npres_elections_temp2 &lt;- pivot_wider(pres_elections_temp,\n  # id_cols=(year,state_po),\n  names_from = party_simplified,\n  values_from = votes\n)\n\npres_elections_temp2 &lt;- pres_elections_temp2 |&gt;\n  mutate(party_won = case_when(DEMOCRAT &gt; REPUBLICAN ~ \"Democrat\", TRUE ~ \"Republican\"))\n\n\n# create a df with state boundaries and election data\nel20_for_map_overtime &lt;- inner_join(state_map1, pres_elections_temp2, by = c(\"STUSPS\" = \"state_po\"))\n\n\n\n# create a plot for 2000 presidential election\n\np1 &lt;- ggplot(\n  el20_for_map_overtime,\n  aes(\n    geometry = geometry,\n    fill = party_won\n  )\n) +\n  geom_sf() +\n  scale_fill_manual(values = c(\n    \"Democrat\" = \"blue\",\n    \"Republican\" = \"red\"\n  )) +\n  facet_wrap(~ factor(year), labeller = as_labeller(function(x) paste(\"year:\", x)), ncol = 1) +\n  theme(\n    strip.text = element_text(size = 24),\n    legend.text = element_text(size = 24), # Increase legend label text size\n    legend.title = element_text(size = 24), # Increase legend title text size\n    legend.key.size = unit(3, \"lines\")\n  )\n\np1\n\n\n\n\n\n\n\n\n\n\nTask 7: Evaluating Fairness of ECV Allocation Schemes\n\nWrite a fact check evaluating the fairness of the different ECV electoral allocation schemes. To do so, you should first determine which allocation scheme you consider “fairest”. You should then see which schemes give different results, if they ever do. To make your fact check more compelling, select one election where the ECV scheme had the largest impact–if one exists–and explain how the results would have been different under a different ECV scheme. As you perform your analysis, you may assume that the District of Columbia has three ECVs, which are allocated to the Democratic candidate under all schemes except possibly national popular vote."
  },
  {
    "objectID": "mp3.html",
    "href": "mp3.html",
    "title": "Mini-Project 03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "In this paper, we will investigate the claim that the US Electoral College systematically biases election results away from the popular vote.\n\nData Prep\nIn this section, we obtain and prepare data for analysis.\nInstalling and Loading Libraries\n\n\nShow the code\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\nif (!require(\"psych\")) install.packages(\"psych\")\nlibrary(psych)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"sqldf\")) install.packages(\"sqldf\")\nlibrary(sqldf)\nif (!require(\"plotly\")) install.packages(\"plotly\")\nlibrary(plotly)\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nlibrary(ggplot2)\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\nlibrary(RColorBrewer)\n\n\n\n\nTask 3: Exploration of Vote Count Data\n\nQ1. Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\n## read in presidential elections data\n\npres&lt;-read.csv(\"president_1976_2020.csv\")\n#head(pres)\n\n# read in house election vote data \n\nhouse&lt;-read.csv(\"house_1976_2022.csv\")\n#head(house)\n\n\n## create a df with house results for 1976 and 2022\n\nhouse_1976_and_2022 &lt;- sqldf(\n  \"\n   with h76 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=1976\n   group by 1\n   )\n   ,\n   h22 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=2022\n   group by 1\n   )\n   , \n   base as (\n   select h76.state,\n   h76.num_seats,\n   case\n   when h76.num_seats=0 then 1 \n   else h76.num_seats\n   end as number_of_seats_1976,\n   h22.num_seats,\n   case\n   when h22.num_seats=0 then 1 \n   else h22.num_seats\n   end as number_of_seats_2022\n   from h76\n   left join h22\n   on h76.state=h22.state\n   )\n   \n   select state,\n   number_of_seats_1976,\n   number_of_seats_2022,\n   number_of_seats_2022 - number_of_seats_1976 as delta \n   from base \n    ;\n  \"\n)\n\n\n# display states with largest gains in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n   slice_max(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Gains in House Seats\"\n  )\n\n\n\n\n\n\n\nTop 5 States with Largest Gains in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nTEXAS\n24\n38\n14\n\n\nFLORIDA\n15\n28\n13\n\n\nCALIFORNIA\n43\n52\n9\n\n\nARIZONA\n4\n9\n5\n\n\nGEORGIA\n10\n14\n4\n\n\n\n\n\n\n\n\n# display states with largest losses in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n   slice_min(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Losses in House Seats\"\n  )\n\n\n\n\n\n\n\nTop 5 States with Largest Losses in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nNEW YORK\n39\n26\n-13\n\n\nOHIO\n23\n15\n-8\n\n\nPENNSYLVANIA\n25\n17\n-8\n\n\nILLINOIS\n24\n17\n-7\n\n\nMICHIGAN\n19\n13\n-6\n\n\n\n\n\n\n\n\n\nQ2. New York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent). Are there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\nFirst, let’s find states, years, and districts where fusion system was in place\n\n#get a count of political parties candidates received votes from\nhouse_temp1 &lt;- house %&gt;%\n  group_by(state, year, district, candidate) |&gt;\n  summarize(distinct_party_count = n_distinct(party))\n\n#get a list of districts where candidates received votes from more than 1 party\nhouse_temp2&lt;-house_temp1 |&gt;\n  filter(distinct_party_count&gt;1)\n\n#get a list of all years, states and districts where fusion system was used\nhouse_temp3&lt;- house_temp2 |&gt;\n  group_by(state, year, district)\n\n# subset house df to only include results from states, years and districts meeting the criteria \n\nhouse_fusion1 &lt;- inner_join(house,house_temp3, by=c(\"state\"=\"state\",\"year\"=\"year\",\"district\"=\"district\"))\n\n# get elections totals for each candidate in states/years/districts meeting the criteria\nhouse_fusion1_actuals&lt;-house_fusion1 |&gt;\n  group_by(year,state,district,candidate.x) |&gt;\n  summarise(actual_total_votes=sum(candidatevotes)) |&gt;\n  mutate(max_votes=max(actual_total_votes)) |&gt;\n  mutate(is_actual_winner=case_when(actual_total_votes==max_votes ~1,\n                             TRUE ~0)) |&gt;\n  ungroup()\n\n# get candidate votes from their primary party only and determine a winner\n house_fusion1_primaryonly&lt;-house_fusion1 |&gt;\n  filter(party=='DEMOCRAT' | party=='REPUBLICAN') |&gt;\n  group_by(year,state,district,candidate.x) |&gt;\n  summarise(actual_primaryparty_votes=sum(candidatevotes)) |&gt;\n  mutate(max_primary_votes=max(actual_primaryparty_votes)) |&gt;\n  mutate(is_primaryvotesonly_winner=case_when(actual_primaryparty_votes==max_primary_votes ~1,\n                             TRUE ~0)) \n\n#merge 2 datasets\nhouse_fusion_merged&lt;-left_join(house_fusion1_actuals,\n                               house_fusion1_primaryonly,\n                               by=c(\"state\"=\"state\",\n                                    \"year\"=\"year\",\n                                    \"district\"=\"district\",\n                                    \"candidate.x\"=\"candidate.x\")\n                               )\n#filter for records where primary party is either D or R and determine if results would have been different\nhouse_fusion_merged_filtered&lt;-house_fusion_merged |&gt;\n  select(year,state,district,candidate.x,actual_total_votes,actual_primaryparty_votes,is_actual_winner,is_primaryvotesonly_winner) |&gt;\n  mutate(same_winner=case_when(is_actual_winner==is_primaryvotesonly_winner ~1,\n                             TRUE ~0)) |&gt;\n  filter((same_winner==0) & !is.na(actual_primaryparty_votes))\n  \n#display results\nhouse_fusion_merged_filtered |&gt;\n  rename(candidate=candidate.x) |&gt;\n   gt() |&gt;\n  tab_header(\n    title = \"Elections With  Different Results In The Absense of Fusion System\"\n  )\n\n\n\n\n\n\n\nElections With Different Results In The Absense of Fusion System\n\n\nyear\nstate\ndistrict\ncandidate\nactual_total_votes\nactual_primaryparty_votes\nis_actual_winner\nis_primaryvotesonly_winner\nsame_winner\n\n\n\n\n1976\nNEW YORK\n29\nEDWARD W PATTISON\n100663\n95361\n1\n0\n0\n\n\n1976\nNEW YORK\n29\nJOSEPH A MARTINO\n96476\n96476\n0\n1\n0\n\n\n1980\nNEW YORK\n3\nGREGORY W CARMAN\n175904\n149736\n1\n0\n0\n\n\n1980\nNEW YORK\n3\nJEROME A AMBRO JR\n166778\n150778\n0\n1\n0\n\n\n1980\nNEW YORK\n6\nJOHN LEBOUTILLIER\n179524\n143676\n1\n0\n0\n\n\n1980\nNEW YORK\n6\nLESTER L WOLFF\n160418\n148638\n0\n1\n0\n\n\n1984\nNEW YORK\n20\nJOSEPH J DIOGUARDI\n106958\n93518\n1\n0\n0\n\n\n1984\nNEW YORK\n20\nOREN J TEICHER\n102842\n102842\n0\n1\n0\n\n\n1986\nNEW YORK\n27\nGEORGE C WORTLEY\n166860\n154350\n1\n0\n0\n\n\n1986\nNEW YORK\n27\nROSEMARY S POOLER\n164982\n162266\n0\n1\n0\n\n\n1992\nCONNECTICUT\n2\nEDWARD W MUNSTER\n119416\n119416\n0\n1\n0\n\n\n1992\nCONNECTICUT\n2\nSAM GEJDENSON\n123291\n83197\n1\n0\n0\n\n\n1992\nNEW YORK\n3\nPETER T KING\n124727\n108574\n1\n0\n0\n\n\n1992\nNEW YORK\n3\nSTEVE A ORLINS\n116915\n116915\n0\n1\n0\n\n\n1994\nNEW YORK\n1\nGEORGE J HOCHBRUECKNER\n160292\n157384\n0\n1\n0\n\n\n1994\nNEW YORK\n1\nMICHAEL P FORBES\n180982\n144090\n1\n0\n0\n\n\n1996\nNEW YORK\n1\nMICHAEL P FORBES\n233240\n180002\n1\n0\n0\n\n\n1996\nNEW YORK\n1\nNORA L BREDES\n192992\n187632\n0\n1\n0\n\n\n1996\nNEW YORK\n30\nFRANCIS J PORDUM\n200080\n195372\n0\n1\n0\n\n\n1996\nNEW YORK\n30\nJACK QUINN\n242738\n194640\n1\n0\n0\n\n\n2000\nCONNECTICUT\n2\nROB SIMMONS\n114380\n110239\n1\n0\n0\n\n\n2000\nCONNECTICUT\n2\nSAM GEJDENSON\n111520\n111520\n0\n1\n0\n\n\n2006\nNEW YORK\n25\nDAN MAFFEI\n214216\n201210\n0\n1\n0\n\n\n2006\nNEW YORK\n25\nJAMES T WALSH\n221050\n182374\n1\n0\n0\n\n\n2006\nNEW YORK\n29\nERIC J MASSA\n200088\n189218\n0\n1\n0\n\n\n2006\nNEW YORK\n29\nJOHN R \"RANDY\" KUHL JR\n212154\n182766\n1\n0\n0\n\n\n2010\nNEW YORK\n13\nMICHAEL E MCMAHON\n60773\n60773\n0\n1\n0\n\n\n2010\nNEW YORK\n13\nMICHAEL G GRIMM\n65024\n55821\n1\n0\n0\n\n\n2010\nNEW YORK\n19\nJOHN J HALL\n98766\n98766\n0\n1\n0\n\n\n2010\nNEW YORK\n19\nNAN HAYMORTH\n109956\n88734\n1\n0\n0\n\n\n2010\nNEW YORK\n24\nMICHAEL A ARCURI\n89809\n89809\n0\n1\n0\n\n\n2010\nNEW YORK\n24\nRICHARD L HANNA\n101599\n85702\n1\n0\n0\n\n\n2010\nNEW YORK\n25\nANN MARIE BUERKLE\n104602\n81380\n1\n0\n0\n\n\n2010\nNEW YORK\n25\nDANIEL B MAFFEI\n103954\n103954\n0\n1\n0\n\n\n2012\nNEW YORK\n27\nCHRIS COLLINS\n322440\n274500\n1\n0\n0\n\n\n2012\nNEW YORK\n27\nKATHLEEN C HOCHUL\n312438\n280016\n0\n1\n0\n\n\n2018\nNEW YORK\n1\nLEE M ZELDIN\n278054\n243124\n1\n0\n0\n\n\n2018\nNEW YORK\n1\nPERRY GERSHON\n255982\n248426\n0\n1\n0\n\n\n2018\nNEW YORK\n24\nDANA BALTER\n246452\n231804\n0\n1\n0\n\n\n2018\nNEW YORK\n24\nJOHN M KATKO\n273840\n227076\n1\n0\n0\n\n\n2018\nNEW YORK\n27\nCHRIS COLLINS\n280292\n229012\n1\n0\n0\n\n\n2018\nNEW YORK\n27\nNATHAN D MCMURRAY\n278118\n256334\n0\n1\n0\n\n\n2022\nNEW YORK\n4\nANTHONY P D’ESPOSITO\n140622\n129353\n1\n0\n0\n\n\n2022\nNEW YORK\n4\nLAURA A GILLEN\n130871\n130871\n0\n1\n0\n\n\n2022\nNEW YORK\n17\nMICHAEL V LAWLER\n287100\n251476\n1\n0\n0\n\n\n2022\nNEW YORK\n17\nSEAN PATRICK MALONEY\n283460\n266914\n0\n1\n0\n\n\n2022\nNEW YORK\n22\nBRANDON M WILLIAMS\n135544\n116529\n1\n0\n0\n\n\n2022\nNEW YORK\n22\nFRANCIS CONOLE\n132913\n132913\n0\n1\n0\n\n\n\n\n\n\n\n\n#display a list of states, years and districts where election results would have been different\n\nhouse_fusion_merged_filtered |&gt;\n  select(year,state,district,is_actual_winner) |&gt;\n  group_by(year,state,district)|&gt;\n  summarise(num_elections=sum(is_actual_winner)) |&gt;\n  ungroup() |&gt;\n  select(-num_elections) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Summary - Elections With  Different Results In The Absense of Fusion System\"\n  )\n\n\n\n\n\n\n\nSummary - Elections With Different Results In The Absense of Fusion System\n\n\nyear\nstate\ndistrict\n\n\n\n\n1976\nNEW YORK\n29\n\n\n1980\nNEW YORK\n3\n\n\n1980\nNEW YORK\n6\n\n\n1984\nNEW YORK\n20\n\n\n1986\nNEW YORK\n27\n\n\n1992\nCONNECTICUT\n2\n\n\n1992\nNEW YORK\n3\n\n\n1994\nNEW YORK\n1\n\n\n1996\nNEW YORK\n1\n\n\n1996\nNEW YORK\n30\n\n\n2000\nCONNECTICUT\n2\n\n\n2006\nNEW YORK\n25\n\n\n2006\nNEW YORK\n29\n\n\n2010\nNEW YORK\n13\n\n\n2010\nNEW YORK\n19\n\n\n2010\nNEW YORK\n24\n\n\n2010\nNEW YORK\n25\n\n\n2012\nNEW YORK\n27\n\n\n2018\nNEW YORK\n1\n\n\n2018\nNEW YORK\n24\n\n\n2018\nNEW YORK\n27\n\n\n2022\nNEW YORK\n4\n\n\n2022\nNEW YORK\n17\n\n\n2022\nNEW YORK\n22\n\n\n\n\n\n\n\nBased on these results, we can ascertain that the use of fusion system in election barely has any discernible effect on the outcome as the election results would have been different only in a handful of cases.\n\n\nQ3. Do presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state? Does this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\n# get a df with results of presidential elections by state. \n\npres_df1&lt;- sqldf(\n  \"\n  with a as(\n  select year,\n  state,\n  candidate,\n  party_simplified as party,\n  candidatevotes as votes\n  from pres\n  where 1=1\n  and PARTY_SIMPLIFIED in ('DEMOCRAT','REPUBLICAN')\n  GROUP BY 1,2,3,4\n  )\n  ,\n  b as (\n  select a.*,\n  row_number() over(partition by year,state order by votes desc) as is_winner\n  from a\n  )\n  \n  select year,\n  state,\n  candidate,\n  party,\n  votes,\n  case\n  when is_winner=1 then 1 else 0 end as is_pres_winner\n  from b\n  ;\n  \"\n)\n\n\n# get a df with records for house elections filtered to D and R only\n\nhouse_prim_only&lt;-house |&gt;\n  filter(party=='DEMOCRAT' | party=='REPUBLICAN') |&gt;\n  group_by(year,state,party) |&gt;\n  summarize(total_party_votes=sum(candidatevotes)) |&gt;\n  ungroup()\n\n#determine  max votes by year/state elections\nhouse_prim_only_agg &lt;- house_prim_only %&gt;%\n  group_by(year, state) %&gt;%\n  summarize(max_votes = max(total_party_votes, na.rm = TRUE)) |&gt;\n  ungroup()\n  \n#merge 2 dfs\n\nhouse_prim_only_merged&lt;-left_join(house_prim_only,\n                                  house_prim_only_agg,\n                                  by=c(\"state\"=\"state\",\"year\"=\"year\"))\n#identify a winning party\n\nhouse_prim_only_merged2&lt;-house_prim_only_merged |&gt;\n  mutate(house_party_winner=case_when(total_party_votes==max_votes ~1,\n                             TRUE ~0))\n\n\n#join dfs with house and presidential results \n\nhouse_pres_merged&lt;-inner_join(pres_df1,\n                              house_prim_only_merged2,\n                              by=c(\"year\"=\"year\",\n                                   \"state\"=\"state\",\n                                   \"party\"=\"party\"))\n#rename columns for clarity\n\nhouse_pres_merged_for_plot&lt;-house_pres_merged |&gt;\n  select(year,state,candidate,party,votes,is_pres_winner,total_party_votes,house_party_winner) |&gt;\n  rename(presidential_votes=votes,\n         is_party_winner=house_party_winner\n         ) |&gt;\n  mutate(president_more_votes=case_when(presidential_votes&gt;total_party_votes~1,\n                                        TRUE~0)) |&gt;\n  mutate(delta_votes=presidential_votes-total_party_votes)\n\n\n#create a df for D party\ndem_party&lt;-house_pres_merged_for_plot |&gt;\n  filter(party=='DEMOCRAT') |&gt;\n  group_by(state) |&gt;\n  summarize(D_president_more_popular_than_cogress=sum(president_more_votes),\n            D_pct_of_all_elections=D_president_more_popular_than_cogress/12,\n            D_avg_difference_votes=mean(delta_votes)\n            ) |&gt;\n  ungroup() |&gt;\n  mutate(D_avg_difference_rank=rank(-D_avg_difference_votes,ties.method='first'))\n  \n#create a df for R party\nrep_party&lt;-house_pres_merged_for_plot |&gt;\n  filter(party=='REPUBLICAN') |&gt;\n  group_by(state) |&gt;\n  summarize(R_president_more_popular_than_cogress=sum(president_more_votes),\n            R_pct_of_all_elections=R_president_more_popular_than_cogress/12,\n            R_avg_difference_votes=mean(delta_votes)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(R_avg_difference_rank=rank(-R_avg_difference_votes,ties.method='first'))\n            \n            \n\n#join 2 dfs\ndem_rep_df&lt;-inner_join(dem_party,rep_party,by=c(\"state\"=\"state\"))\n\n#display\ndem_rep_df |&gt;\n  DT::datatable(options = list(\n    pageLength = 51\n  ))\n\n\n\n\n\nLooking at Democratic party, we"
  },
  {
    "objectID": "mp_course_project.html",
    "href": "mp_course_project.html",
    "title": "xxxx",
    "section": "",
    "text": "Data Prep\nIn this section, we obtain and prepare data for analysis.\nInstalling and Loading Libraries\n\n\nShow the code\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\nif (!require(\"psych\")) install.packages(\"psych\")\nlibrary(psych)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"sqldf\")) install.packages(\"sqldf\")\nlibrary(sqldf)\nif (!require(\"plotly\")) install.packages(\"plotly\")\nlibrary(plotly)\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nlibrary(ggplot2)\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\nlibrary(RColorBrewer)\n\n\n\n#library(ggplot2)\nlibrary(sf)\n\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\",\n              method=\"curl\")\n}\n\n##-\ntd &lt;- tempdir(); \nzip_contents &lt;- unzip(\"nyc_borough_boundaries.zip\", \n                      exdir = td)\n    \nfname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\nnyc_sf &lt;- read_sf(fname_shp)\nnyc_sf\n\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 5\n  boro_code boro_name      shape_area shape_leng                        geometry\n      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;              &lt;MULTIPOLYGON [°]&gt;\n1         3 Brooklyn      1934142776.    728147. (((-73.86327 40.58388, -73.863…\n2         5 Staten Island 1623618684.    325910. (((-74.05051 40.56642, -74.050…\n3         1 Manhattan      636646082.    360038. (((-74.01093 40.68449, -74.011…\n4         2 Bronx         1187174772.    463181. (((-73.89681 40.79581, -73.896…\n5         4 Queens        3041418004.    888197. (((-73.82645 40.59053, -73.826…\n\n\n\nggplot(nyc_sf, \n       aes(geometry=geometry)) + \n    geom_sf()\n\n\n\n\n\n\n\n\n\n#read in unemployment data from fred\n\nnyc_unrate_all&lt;-read.csv(\"new_york_unemployment_rate_annual_monthly_county.csv\")\nhead(nyc_unrate_all)\n\n           county     date unemployment_rate   type\n1 new york county 1/1/1990               6.0 annual\n2 new york county 1/1/1991               7.8 annual\n3 new york county 1/1/1992               9.4 annual\n4 new york county 1/1/1993               9.0 annual\n5 new york county 1/1/1994               7.6 annual\n6 new york county 1/1/1995               7.0 annual\n\n\n\nnyc_unrate_annual&lt;-nyc_unrate_all |&gt;\n  filter(type==\"annual\") |&gt;\n  mutate(cal_date = mdy(date)) |&gt;\n  mutate(year = year(as.Date(cal_date))) |&gt;\n  mutate(county_name = case_when(\n    county == \"new york county\" ~ \"New York\",\n    county == \"bronx\" ~ \"Bronx\",\n    county == \"kings\" ~ \"Kings\",\n    county == \"queens\" ~ \"Queens\",\n    county == \"richmond\" ~ \"Richmond\",\n    TRUE ~ \"Unknown\"\n  ))\n\n\nglimpse(nyc_unrate_annual)\n\nRows: 170\nColumns: 7\n$ county            &lt;chr&gt; \"new york county\", \"new york county\", \"new york coun…\n$ date              &lt;chr&gt; \"1/1/1990\", \"1/1/1991\", \"1/1/1992\", \"1/1/1993\", \"1/1…\n$ unemployment_rate &lt;dbl&gt; 6.0, 7.8, 9.4, 9.0, 7.6, 7.0, 7.4, 7.8, 6.7, 5.9, 5.…\n$ type              &lt;chr&gt; \"annual\", \"annual\", \"annual\", \"annual\", \"annual\", \"a…\n$ cal_date          &lt;date&gt; 1990-01-01, 1991-01-01, 1992-01-01, 1993-01-01, 199…\n$ year              &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998…\n$ county_name       &lt;chr&gt; \"New York\", \"New York\", \"New York\", \"New York\", \"New…\n\n\n\n### \n\n#unique(nyc_unrate_annual$county)\n\nnyc_sf2&lt;-nyc_sf |&gt;\n  mutate(county_name = case_when(\n    boro_name == \"Manhattan\" ~ \"New York\",\n    boro_name == \"Staten Island\" ~ \"Richmond\",\n    boro_name == \"Brooklyn\" ~ \"Kings\",\n    boro_name == \"Queens\" ~ \"Queens\",\n    boro_name == \"Bronx\" ~ \"Bronx\",\n    TRUE ~ \"Unknown\"\n  ))\n\n## pivot wide for maps\nnyc_unrate_annual_wide&lt;-pivot_wider(nyc_unrate_annual,\n                               id_cols=county_name,\n                               names_from = year,\n                               values_from=unemployment_rate\n                               )\n \nnyc_unrate_annual_wide2&lt;-left_join(nyc_unrate_annual_wide,nyc_sf2,by=\"county_name\")   \n\nglimpse(nyc_unrate_annual_wide2)\n\nRows: 5\nColumns: 40\n$ county_name &lt;chr&gt; \"New York\", \"Bronx\", \"Kings\", \"Queens\", \"Richmond\"\n$ `1990`      &lt;dbl&gt; 6.0, 8.4, 7.8, 6.0, 6.1\n$ `1991`      &lt;dbl&gt; 7.8, 10.6, 9.7, 8.2, 8.1\n$ `1992`      &lt;dbl&gt; 9.4, 13.1, 12.1, 10.6, 9.9\n$ `1993`      &lt;dbl&gt; 9.0, 12.2, 11.5, 9.7, 9.4\n$ `1994`      &lt;dbl&gt; 7.6, 10.1, 9.8, 8.2, 7.8\n$ `1995`      &lt;dbl&gt; 7.0, 9.6, 9.2, 7.7, 7.5\n$ `1996`      &lt;dbl&gt; 7.4, 10.5, 10.0, 8.1, 7.8\n$ `1997`      &lt;dbl&gt; 7.8, 11.6, 10.6, 8.5, 8.3\n$ `1998`      &lt;dbl&gt; 6.7, 9.9, 9.3, 6.9, 6.8\n$ `1999`      &lt;dbl&gt; 5.9, 8.2, 8.0, 6.1, 5.8\n$ `2000`      &lt;dbl&gt; 5.1, 7.1, 6.4, 5.3, 5.1\n$ `2001`      &lt;dbl&gt; 5.8, 7.4, 6.6, 5.4, 5.2\n$ `2002`      &lt;dbl&gt; 7.6, 9.7, 8.7, 7.1, 7.0\n$ `2003`      &lt;dbl&gt; 7.4, 10.5, 9.0, 7.3, 7.4\n$ `2004`      &lt;dbl&gt; 6.1, 9.1, 7.5, 6.2, 6.3\n$ `2005`      &lt;dbl&gt; 4.9, 7.4, 6.1, 5.1, 5.1\n$ `2006`      &lt;dbl&gt; 4.2, 6.5, 5.3, 4.4, 4.4\n$ `2007`      &lt;dbl&gt; 4.2, 6.6, 5.3, 4.3, 4.4\n$ `2008`      &lt;dbl&gt; 4.9, 7.5, 6.0, 5.0, 5.1\n$ `2009`      &lt;dbl&gt; 8.4, 12.0, 9.9, 8.4, 8.2\n$ `2010`      &lt;dbl&gt; 8.6, 12.0, 10.0, 8.7, 9.5\n$ `2011`      &lt;dbl&gt; 7.9, 12.0, 9.6, 8.1, 9.2\n$ `2012`      &lt;dbl&gt; 8.1, 12.5, 9.9, 8.4, 9.6\n$ `2013`      &lt;dbl&gt; 7.5, 11.7, 9.3, 7.7, 8.9\n$ `2014`      &lt;dbl&gt; 6.0, 9.5, 7.4, 6.2, 7.3\n$ `2015`      &lt;dbl&gt; 4.8, 7.6, 5.8, 4.9, 5.7\n$ `2016`      &lt;dbl&gt; 4.5, 7.1, 5.3, 4.5, 5.2\n$ `2017`      &lt;dbl&gt; 4.0, 6.2, 4.6, 3.9, 4.6\n$ `2018`      &lt;dbl&gt; 3.7, 5.7, 4.2, 3.6, 4.1\n$ `2019`      &lt;dbl&gt; 3.5, 5.4, 4.1, 3.5, 3.9\n$ `2020`      &lt;dbl&gt; 9.5, 16.0, 12.5, 12.4, 10.5\n$ `2021`      &lt;dbl&gt; 7.8, 13.9, 10.4, 9.9, 9.0\n$ `2022`      &lt;dbl&gt; 4.6, 7.9, 5.9, 5.3, 5.6\n$ `2023`      &lt;dbl&gt; 4.6, 6.8, 5.5, 4.6, 4.9\n$ boro_code   &lt;dbl&gt; 1, 2, 3, 4, 5\n$ boro_name   &lt;chr&gt; \"Manhattan\", \"Bronx\", \"Brooklyn\", \"Queens\", \"Staten Island\"\n$ shape_area  &lt;dbl&gt; 636646082, 1187174772, 1934142776, 3041418004, 1623618684\n$ shape_leng  &lt;dbl&gt; 360037.5, 463180.6, 728147.1, 888197.0, 325910.3\n$ geometry    &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((-74.01093 4..., MULTIPOLYGON (((-73.89681 …\n\n\n\n##check plot\n  \nggplot(nyc_unrate_annual_wide2, \n       aes(geometry=geometry, \n           fill = `2004`)) + \n    geom_sf()\n\n\n\n\n\n\n\n\n\n## 2010-2023\n## Animated Chloropleth using gganimate\n\n## Add some time \"structure\" to our data for \n## demonstration purposes only\nnyc_counties_repeats &lt;- bind_rows(\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2010` , \n                     frame = 1), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2011` ,\n                     frame = 2), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2012` , \n                     frame = 3), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2013` ,\n                     frame = 4), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2014` ,\n                     frame = 5),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2015` , \n                     frame = 6), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2016` ,\n                     frame = 7), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2017` , \n                     frame = 8), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2018` ,\n                     frame = 9), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2019` ,\n                     frame = 10),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2020` , \n                     frame = 11), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2021` ,\n                     frame = 12), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2022` , \n                     frame = 13), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2023` ,\n                     frame = 14))\n\nlibrary(gganimate)\nggplot(nyc_counties_repeats, \n       aes(geometry=geometry, \n           fill = value)) + \n    geom_sf() + \n    theme_void()+\n    transition_time(frame)\n\n\n\n\n\n\n\n\n\n## 2000-2023\n## Animated Chloropleth using gganimate\n\n## Add some time \"structure\" to our data for \n## demonstration purposes only\nnyc_counties_repeats_v2 &lt;- bind_rows(\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2000` , \n                     frame = 1), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2001` ,\n                     frame = 2), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2002` , \n                     frame = 3), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2003` ,\n                     frame = 4), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2004` ,\n                     frame = 5),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2005` , \n                     frame = 6), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2006` ,\n                     frame = 7), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2007` , \n                     frame = 8), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2008` ,\n                     frame = 9), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2009` ,\n                     frame = 10),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2010` , \n                     frame = 11), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2011` ,\n                     frame = 12), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2012` , \n                     frame = 13), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2013` ,\n                     frame = 14),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2014` ,\n                     frame = 15), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2015` ,\n                     frame = 16),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2016` , \n                     frame = 17), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2017` ,\n                     frame = 18), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2018` , \n                     frame = 19), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2019` ,\n                     frame = 20),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2020` ,\n                     frame = 21),\n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2021` , \n                     frame = 22), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2022` ,\n                     frame = 23), \n    nyc_unrate_annual_wide2 |&gt; mutate(value =`2023` , \n                     frame = 24))\n\nlibrary(gganimate)\nggplot(nyc_counties_repeats_v2, \n       aes(geometry=geometry, \n           fill = value)) + \n    geom_sf() + \n    transition_time(frame)\n\n\n\n\n\n\n\n\n\npalette_5counties&lt;-c(\n  \"dodgerblue2\",\"green4\",\"black\",\"yellow\",\"#E31A1C\"\n)\n\n# create a chart\n\nnyc_unrate_annual2010&lt;-nyc_unrate_annual|&gt;\n  filter(year&gt;=2010)\n\nnyc_annual_unrate_year_plot &lt;- plot_ly(nyc_unrate_annual2010,\n  x = ~year, y = ~unemployment_rate,\n  color = ~county_name,\n  type = \"scatter\",\n  mode = \"lines\",\n  colors = palette_5counties\n) |&gt;\n  layout(\n    title = \"\",\n    xaxis = list(title = \"\"),\n    yaxis = list(\n      title = \"\"\n      #,\n  #    tickformat = \".0%\",\n  #    range = c(0, 1)\n    ),\n    legend = list(\n      orientation = \"h\", # Horizontal legend\n      x = 0.5, # Center horizontally\n      xanchor = \"center\", # Align center\n      y = -0.2, # Position below the plot\n      font = list(size = 8) # Smaller font size\n    )\n  )\n\n# Show the plot\n\nnyc_annual_unrate_year_plot"
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Mini-Project 03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "In this mini-project, we will investigate the claim that the US Electoral College systematically biases election results away from the popular vote.\n\nData Prep\nFirst, we will obtain and prepare data for analysis.\nInstalling and Loading Libraries\n\n\nShow the code\n# Installing and loading libraries\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\nif (!require(\"psych\")) install.packages(\"psych\")\nlibrary(psych)\nif (!require(\"gt\")) install.packages(\"gt\")\nlibrary(gt)\nif (!require(\"formattable\")) install.packages(\"formattable\")\nlibrary(formattable)\nif (!require(\"sqldf\")) install.packages(\"sqldf\")\nlibrary(sqldf)\nif (!require(\"plotly\")) install.packages(\"plotly\")\nlibrary(plotly)\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nlibrary(ggplot2)\nif (!require(\"RColorBrewer\")) install.packages(\"RColorBrewer\")\nlibrary(RColorBrewer)\nif (!require(\"sf\")) install.packages(\"sf\")\nlibrary(sf)\n\n\n\n\nTask 1.Download Congressional Shapefiles 1976-2012\n\n\nShow the code\ntd &lt;- tempdir()\n\nfor (i in 94:112) {\n  fname &lt;- paste0(\"districts\", formatC(i, width = 3, format = \"d\", flag = \"0\"), \".zip\")\n\n  if (!file.exists(fname)) {\n    url &lt;- paste0(\"https://cdmaps.polisci.ucla.edu/shp/\", fname)\n\n    download.file(url, destfile = fname)\n\n    zip_contents &lt;- unzip(fname, exdir = td)\n    shp_file &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\n    sf_data &lt;- read_sf(shp_file)\n\n    assign(paste0(\"districts\", formatC(i, width = 3, format = \"d\", flag = \"0\"), \"_sf\"), sf_data)\n  }\n}\n\n\n\n\nTask 2.Download Congressional Shapefiles 2014-2022\n\n\nShow the code\nfor (i in 2014:2022) {\n  BASE_URL &lt;- \"https://www2.census.gov/geo/tiger/\"\n  if (i &gt;= 2018) {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd116.zip\")\n  } else if (i &gt; 2015) {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd115.zip\")\n  } else {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd114.zip\")\n  }\n  download_name &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \".zip\")\n\n  if (!file.exists(download_name)) {\n    FILE_URL &lt;- paste0(BASE_URL, file)\n    print(FILE_URL)\n    download.file(FILE_URL, destfile = download_name, mode = \"wb\")\n  }\n}\n\n\n\n\nTask 3: Exploration of Vote Count Data\n\n\nQ1. Which states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\n\n\n\nShow the code\n## read in presidential elections data\n\npres &lt;- read.csv(\"president_1976_2020.csv\")\n# head(pres)\n\n# read in house election vote data\n\nhouse &lt;- read.csv(\"house_1976_2022.csv\")\n# head(house)\n\n## create a df with house results for 1976 and 2022\n\nhouse_1976_and_2022 &lt;- sqldf(\n  \"\n   with h76 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=1976\n   group by 1\n   )\n   ,\n   h22 as (\n   select state,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=2022\n   group by 1\n   )\n   ,\n   base as (\n   select h76.state,\n   h76.num_seats,\n   case\n   when h76.num_seats=0 then 1\n   else h76.num_seats\n   end as number_of_seats_1976,\n   h22.num_seats,\n   case\n   when h22.num_seats=0 then 1\n   else h22.num_seats\n   end as number_of_seats_2022\n   from h76\n   left join h22\n   on h76.state=h22.state\n   )\n\n   select state,\n   number_of_seats_1976,\n   number_of_seats_2022,\n   number_of_seats_2022 - number_of_seats_1976 as delta\n   from base\n    ;\n  \"\n)\n\n\n# display states with largest gains in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n  slice_max(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Gains in House Seats\"\n  )\n\n\n\n\n\n\n\n\nTop 5 States with Largest Gains in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nTEXAS\n24\n38\n14\n\n\nFLORIDA\n15\n28\n13\n\n\nCALIFORNIA\n43\n52\n9\n\n\nARIZONA\n4\n9\n5\n\n\nGEORGIA\n10\n14\n4\n\n\n\n\n\n\n\nTexas, Florida, California, Arizona and Georgia had largest gains in house seats between 1976 and 2022.\n\n\nShow the code\n# display states with largest losses in number of house seats from 1976 to 2022\n\nhouse_1976_and_2022 |&gt;\n  slice_min(delta, n = 5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top 5 States with Largest Losses in House Seats\"\n  )\n\n\n\n\n\n\n\n\nTop 5 States with Largest Losses in House Seats\n\n\nstate\nnumber_of_seats_1976\nnumber_of_seats_2022\ndelta\n\n\n\n\nNEW YORK\n39\n26\n-13\n\n\nOHIO\n23\n15\n-8\n\n\nPENNSYLVANIA\n25\n17\n-8\n\n\nILLINOIS\n24\n17\n-7\n\n\nMICHIGAN\n19\n13\n-6\n\n\n\n\n\n\n\nNew York, Ohio, Pennsylvania, Illinois and Michigan had largest losses in house seats between 1976 and 2022.\n\nQ2. New York State has a unique “fusion” voting system where one candidate can appear on multiple “lines” on the ballot and their vote counts are totaled. For instance, in 2022, Jerrold Nadler appeared on both the Democrat and Working Families party lines for NYS’ 12th Congressional District. He received 200,890 votes total (184,872 as a Democrat and 16,018 as WFP), easily defeating Michael Zumbluskas, who received 44,173 votes across three party lines (Republican, Conservative, and Parent). Are there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\n\nFirst, let’s find states, years, and districts where fusion system was used in elections.\n\n\nShow the code\n# get a count of political parties candidates received votes from\nhouse_temp1 &lt;- house %&gt;%\n  group_by(state, year, district, candidate) |&gt;\n  summarize(distinct_party_count = n_distinct(party))\n\n# get a list of districts where candidates received votes from more than 1 party\nhouse_temp2 &lt;- house_temp1 |&gt;\n  filter(distinct_party_count &gt; 1)\n\n# get a list of all years, states and districts where fusion system was used\nhouse_temp3 &lt;- house_temp2 |&gt;\n  group_by(state, year, district)\n\n# subset house df to only include results from states, years and districts meeting the criteria\n\nhouse_fusion1 &lt;- inner_join(house, house_temp3, by = c(\"state\" = \"state\", \"year\" = \"year\", \"district\" = \"district\"))\n\n# get elections totals for each candidate in states/years/districts meeting the criteria\nhouse_fusion1_actuals &lt;- house_fusion1 |&gt;\n  group_by(year, state, district, candidate.x) |&gt;\n  summarise(actual_total_votes = sum(candidatevotes)) |&gt;\n  mutate(max_votes = max(actual_total_votes)) |&gt;\n  mutate(is_actual_winner = case_when(\n    actual_total_votes == max_votes ~ 1,\n    TRUE ~ 0\n  )) |&gt;\n  ungroup()\n\n# get candidate votes from their primary party only and determine a winner\nhouse_fusion1_primaryonly &lt;- house_fusion1 |&gt;\n  filter(party == \"DEMOCRAT\" | party == \"REPUBLICAN\") |&gt;\n  group_by(year, state, district, candidate.x) |&gt;\n  summarise(actual_primaryparty_votes = sum(candidatevotes)) |&gt;\n  mutate(max_primary_votes = max(actual_primaryparty_votes)) |&gt;\n  mutate(is_primaryvotesonly_winner = case_when(\n    actual_primaryparty_votes == max_primary_votes ~ 1,\n    TRUE ~ 0\n  ))\n\n# merge 2 datasets\nhouse_fusion_merged &lt;- left_join(house_fusion1_actuals,\n  house_fusion1_primaryonly,\n  by = c(\n    \"state\" = \"state\",\n    \"year\" = \"year\",\n    \"district\" = \"district\",\n    \"candidate.x\" = \"candidate.x\"\n  )\n)\n# filter for records where primary party is either D or R and determine if results would have been different\nhouse_fusion_merged_filtered &lt;- house_fusion_merged |&gt;\n  select(year, state, district, candidate.x, actual_total_votes, actual_primaryparty_votes, is_actual_winner, is_primaryvotesonly_winner) |&gt;\n  mutate(same_winner = case_when(\n    is_actual_winner == is_primaryvotesonly_winner ~ 1,\n    TRUE ~ 0\n  )) |&gt;\n  filter((same_winner == 0) & !is.na(actual_primaryparty_votes))\n\n# display results\n# house_fusion_merged_filtered |&gt;\n#  rename(candidate=candidate.x) |&gt;\n#   gt() |&gt;\n#  tab_header(\n#    title = \"Elections With  Different Results In The Absense of Fusion System\"\n#  )\n\n\n# display a list of states, years and districts where election results would have been different\n\nhouse_fusion_merged_filtered |&gt;\n  select(year, state, district, is_actual_winner) |&gt;\n  group_by(year, state, district) |&gt;\n  summarise(num_elections = sum(is_actual_winner)) |&gt;\n  ungroup() |&gt;\n  select(-num_elections) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"List of Elections With  Different Results\"\n  )\n\n\n\n\n\n\n\n\nList of Elections With Different Results\n\n\nyear\nstate\ndistrict\n\n\n\n\n1976\nNEW YORK\n29\n\n\n1980\nNEW YORK\n3\n\n\n1980\nNEW YORK\n6\n\n\n1984\nNEW YORK\n20\n\n\n1986\nNEW YORK\n27\n\n\n1992\nCONNECTICUT\n2\n\n\n1992\nNEW YORK\n3\n\n\n1994\nNEW YORK\n1\n\n\n1996\nNEW YORK\n1\n\n\n1996\nNEW YORK\n30\n\n\n2000\nCONNECTICUT\n2\n\n\n2006\nNEW YORK\n25\n\n\n2006\nNEW YORK\n29\n\n\n2010\nNEW YORK\n13\n\n\n2010\nNEW YORK\n19\n\n\n2010\nNEW YORK\n24\n\n\n2010\nNEW YORK\n25\n\n\n2012\nNEW YORK\n27\n\n\n2018\nNEW YORK\n1\n\n\n2018\nNEW YORK\n24\n\n\n2018\nNEW YORK\n27\n\n\n2022\nNEW YORK\n4\n\n\n2022\nNEW YORK\n17\n\n\n2022\nNEW YORK\n22\n\n\n\n\n\n\n\n\n\nShow the code\ncnt_fusion_elections &lt;- sqldf(\n  \"\n  select 'all fusion elections' as elections,\n  count(distinct year||state||district) as count_elections\n  from house_fusion_merged\n  group by 1\n\n  union all\n\n  select 'fusion elections with different outcomes' as elections,\n  count(distinct year||state||district) as count_elections\n  from house_fusion_merged\n  where 1=1\n  and is_actual_winner!=is_primaryvotesonly_winner\n  group by 1\n  ;\n  \"\n)\n\ncnt_fusion_elections |&gt;\n  gt()\n\n\n\n\n\n\n\n\nelections\ncount_elections\n\n\n\n\nall fusion elections\n754\n\n\nfusion elections with different outcomes\n24\n\n\n\n\n\n\n\nBased on these results, we ascertain that the use of fusion system in elections has no discernible effect on the outcome as the results would have been different only in a handful of cases (24 out of 754 elections, or 3.2%).\n\nQ3. Do presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state? Does this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\nTo answer these questions, first we need to get results of Presidential and Congressional elections for every state for 12 years when Presidential elections were held. (You can look up results of individual states in the table below.)\n\n\nShow the code\n# get a df with results of presidential elections by state filtered to R and D candidates only\n\npres_df1 &lt;- sqldf(\n  \"\n  with a as(\n  select year,\n  state,\n  candidate,\n  party_simplified as party,\n  candidatevotes as votes\n  from pres\n  where 1=1\n  and PARTY_SIMPLIFIED in ('DEMOCRAT','REPUBLICAN')\n  GROUP BY 1,2,3,4\n  )\n  ,\n  b as (\n  select a.*,\n  row_number() over(partition by year,state order by votes desc) as is_winner\n  from a\n  )\n\n  select year,\n  state,\n  candidate,\n  party,\n  votes,\n  case\n  when is_winner=1 then 1 else 0 end as is_pres_winner\n  from b\n  ;\n  \"\n)\n\n\n# get a df with records for house elections filtered to D and R only\n\nhouse_prim_only &lt;- house |&gt;\n  filter(party == \"DEMOCRAT\" | party == \"REPUBLICAN\") |&gt;\n  group_by(year, state, party) |&gt;\n  summarize(total_party_votes = sum(candidatevotes)) |&gt;\n  ungroup()\n\n# determine  max votes by year/state elections\nhouse_prim_only_agg &lt;- house_prim_only %&gt;%\n  group_by(year, state) %&gt;%\n  summarize(max_votes = max(total_party_votes, na.rm = TRUE)) |&gt;\n  ungroup()\n\n# merge 2 dfs\n\nhouse_prim_only_merged &lt;- left_join(house_prim_only,\n  house_prim_only_agg,\n  by = c(\"state\" = \"state\", \"year\" = \"year\")\n)\n\n# identify a winning party in congressional election\n\nhouse_prim_only_merged2 &lt;- house_prim_only_merged |&gt;\n  mutate(house_party_winner = case_when(\n    total_party_votes == max_votes ~ 1,\n    TRUE ~ 0\n  ))\n\n\n# join dfs with house and presidential results\n\nhouse_pres_merged &lt;- inner_join(pres_df1,\n  house_prim_only_merged2,\n  by = c(\n    \"year\" = \"year\",\n    \"state\" = \"state\",\n    \"party\" = \"party\"\n  )\n)\n# rename columns for clarity\n\nhouse_pres_merged_for_plot &lt;- house_pres_merged |&gt;\n  select(year, state, candidate, party, votes, is_pres_winner, total_party_votes, house_party_winner) |&gt;\n  rename(\n    presidential_votes = votes,\n    is_party_winner = house_party_winner\n  ) |&gt;\n  mutate(president_more_votes = case_when(\n    presidential_votes &gt; total_party_votes ~ 1,\n    TRUE ~ 0\n  )) |&gt;\n  mutate(delta_votes = presidential_votes - total_party_votes)\n\n# create a df for D party\ndem_party &lt;- house_pres_merged_for_plot |&gt;\n  filter(party == \"DEMOCRAT\") |&gt;\n  group_by(state) |&gt;\n  summarize(\n    D_president_more_popular_than_cogress = sum(president_more_votes),\n    D_president_more_popular_share = D_president_more_popular_than_cogress / 12,\n    D_avg_difference_votes = mean(delta_votes)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(D_avg_delta_votes_ranked = rank(-D_avg_difference_votes, ties.method = \"first\"))\n\n# create a df for R party\nrep_party &lt;- house_pres_merged_for_plot |&gt;\n  filter(party == \"REPUBLICAN\") |&gt;\n  group_by(state) |&gt;\n  summarize(\n    R_president_more_popular_than_cogress = sum(president_more_votes),\n    R_president_more_popular_share = R_president_more_popular_than_cogress / 12,\n    R_avg_difference_votes = mean(delta_votes)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(R_avg_delta_votes_ranked = rank(-R_avg_difference_votes, ties.method = \"first\"))\n\n\n\n# join 2 dfs\ndem_rep_df &lt;- inner_join(dem_party, rep_party, by = c(\"state\" = \"state\"))\n\n# display the data\ndem_rep_df |&gt;\n  mutate(\n    R_president_more_popular_share = scales::percent(R_president_more_popular_share),\n    D_president_more_popular_share = scales::percent(D_president_more_popular_share),\n    R_avg_difference_votes = format(round(as.numeric(R_avg_difference_votes), 0), nsmall = 0, big.mark = \",\"),\n    D_avg_difference_votes = format(round(as.numeric(D_avg_difference_votes), 0), nsmall = 0, big.mark = \",\")\n  ) |&gt;\n  DT::datatable(\n    options = list(pageLength = 5),\n    filter = \"top\"\n  )\n\n\n\n\n\n\nNow that we have records with Presidential and Congress election results for all states, we can answer this question. Across all states in 12 elections, Democratic candidates had more votes than all Congressional candidates from Democratic party in 53% of all cases. For Republican candidates, this number was even higher at 65%.\n\n\nShow the code\ndem_rep_df %&gt;%\n  summarise(D_president_more_popular = mean(D_president_more_popular_share, na.rm = TRUE), R_president_more_popular = mean(R_president_more_popular_share, na.rm = TRUE)) %&gt;%\n  mutate(\n    D_president_more_popular = scales::percent(D_president_more_popular),\n    R_president_more_popular = scales::percent(R_president_more_popular)\n  ) |&gt;\n  ungroup()\n\n\n# A tibble: 1 × 2\n  D_president_more_popular R_president_more_popular\n  &lt;chr&gt;                    &lt;chr&gt;                   \n1 53%                      65%                     \n\n\n\n\nShow the code\n## display df by state\n\n\n# display the data\ndem_rep_df_plot &lt;- dem_rep_df |&gt;\n  select(state, R_president_more_popular_share, D_president_more_popular_share) |&gt;\n  mutate(\n    D_president_more_popular_share = scales::percent(D_president_more_popular_share),\n    R_president_more_popular_share = scales::percent(R_president_more_popular_share)\n  )\n\ndem_rep_df_plot |&gt;\n  gt()\n\n\n\n\n\n\n\n\nstate\nR_president_more_popular_share\nD_president_more_popular_share\n\n\n\n\nALABAMA\n91.7%\n58.3%\n\n\nALASKA\n25.0%\n58.3%\n\n\nARIZONA\n50.0%\n66.7%\n\n\nARKANSAS\n66.7%\n75.0%\n\n\nCALIFORNIA\n75.0%\n58.3%\n\n\nCOLORADO\n58.3%\n75.0%\n\n\nCONNECTICUT\n75.0%\n66.7%\n\n\nDELAWARE\n41.7%\n75.0%\n\n\nFLORIDA\n75.0%\n83.3%\n\n\nGEORGIA\n50.0%\n58.3%\n\n\nHAWAII\n83.3%\n33.3%\n\n\nIDAHO\n66.7%\n25.0%\n\n\nILLINOIS\n58.3%\n66.7%\n\n\nINDIANA\n75.0%\n16.7%\n\n\nIOWA\n41.7%\n66.7%\n\n\nKANSAS\n33.3%\n66.7%\n\n\nKENTUCKY\n66.7%\n66.7%\n\n\nLOUISIANA\n91.7%\n100.0%\n\n\nMAINE\n50.0%\n25.0%\n\n\nMARYLAND\n58.3%\n58.3%\n\n\nMASSACHUSETTS\n83.3%\n0.0%\n\n\nMICHIGAN\n75.0%\n50.0%\n\n\nMINNESOTA\n66.7%\n41.7%\n\n\nMISSISSIPPI\n83.3%\n50.0%\n\n\nMISSOURI\n75.0%\n41.7%\n\n\nMONTANA\n58.3%\n16.7%\n\n\nNEBRASKA\n0.0%\n83.3%\n\n\nNEVADA\n66.7%\n58.3%\n\n\nNEW HAMPSHIRE\n66.7%\n66.7%\n\n\nNEW JERSEY\n75.0%\n66.7%\n\n\nNEW MEXICO\n50.0%\n50.0%\n\n\nNEW YORK\n83.3%\n91.7%\n\n\nNORTH CAROLINA\n75.0%\n25.0%\n\n\nNORTH DAKOTA\n75.0%\n16.7%\n\n\nOHIO\n66.7%\n66.7%\n\n\nOKLAHOMA\n83.3%\n58.3%\n\n\nOREGON\n75.0%\n25.0%\n\n\nPENNSYLVANIA\n58.3%\n66.7%\n\n\nRHODE ISLAND\n58.3%\n41.7%\n\n\nSOUTH CAROLINA\n66.7%\n66.7%\n\n\nSOUTH DAKOTA\n58.3%\n25.0%\n\n\nTENNESSEE\n91.7%\n75.0%\n\n\nTEXAS\n66.7%\n50.0%\n\n\nUTAH\n66.7%\n8.3%\n\n\nVERMONT\n50.0%\n66.7%\n\n\nVIRGINIA\n58.3%\n91.7%\n\n\nWASHINGTON\n66.7%\n41.7%\n\n\nWEST VIRGINIA\n100.0%\n0.0%\n\n\nWISCONSIN\n58.3%\n66.7%\n\n\nWYOMING\n58.3%\n33.3%\n\n\n\n\n\n\n\n\n\nShow the code\n# plot states data\n\ndem_rep_plot1 &lt;- plot_ly(\n  data = dem_rep_df,\n  x = ~R_president_more_popular_share,\n  y = ~D_president_more_popular_share,\n  type = \"scatter\",\n  mode = \"markers\",\n  marker = list(size = 5),\n  color = ~state\n) |&gt;\n  layout(\n    title = \"\",\n    xaxis = list(\n      title = \"Popularity of R president vs Congress\",\n      font = 8,\n      tickfont = list(size = 8),\n      titlefont = list(size = 8)\n    ),\n    yaxis = list(\n      title = \"Popularity of D president vs Congress\",\n      font = 8,\n      tickfont = list(size = 8),\n      titlefont = list(size = 8)\n    ),\n    legend = list(\n      font = list(size = 8),\n      orientation = \"h\", # Horizontal legend\n      x = 0.5, # Center horizontally\n      xanchor = \"center\", # Align center\n      y = -0.2,\n      font = 8\n    )\n  )\n\ndem_rep_plot1\n\n\n\n\n\n\nConsistently with our previous findings, most states tend to favor presidential candidates more so than Congressional candidates, with this trend being more pronounced for Republican candidates. Notable exceptions are Nebraska, Alaska, Kansas, Delaware and Iowa, where Republican presidential candidates tend to receive fewer votes than Congressional hopefuls.\n\n\nShow the code\ndem_win_year &lt;- house_pres_merged_for_plot |&gt;\n  filter((party == \"DEMOCRAT\") & (president_more_votes == 1)) |&gt;\n  group_by(year, party) |&gt;\n  summarise(share_states_president_popular = n() / 51) |&gt;\n  ungroup()\n\nrep_win_year &lt;- house_pres_merged_for_plot |&gt;\n  filter((party == \"REPUBLICAN\") & (president_more_votes == 1)) |&gt;\n  group_by(year, party) |&gt;\n  summarise(share_states_president_popular = n() / 51) |&gt;\n  ungroup()\n\ndem_rep_win_for_plot &lt;- bind_rows(dem_win_year, rep_win_year)\n\ndem_rep_win_for_plot2 &lt;- dem_rep_win_for_plot |&gt;\n  ungroup()\n\n\n\n\nShow the code\n# create a chart\n\ndrplot2 &lt;- plot_ly(\n  data = dem_rep_win_for_plot2,\n  x = ~year, y = ~share_states_president_popular,\n  color = ~party,\n  type = \"scatter\",\n  mode = \"lines+markers\"\n) |&gt;\n  layout(\n    title = \"Share of States Favoring Presidential Candidates over Congressional\",\n    xaxis = list(title = \"\"),\n    yaxis = list(\n      title = \"Share of States\",\n      tickformat = \".0%\",\n      range = c(0, 1)\n    ),\n    legend = list(\n      orientation = \"h\", # Horizontal legend\n      x = 0.5, # Center horizontally\n      xanchor = \"center\", # Align center\n      y = -0.2, # Position below the plot\n      font = list(size = 8) # Smaller font size\n    )\n  )\n\ndrplot2\n\n\n\n\n\n\nAs we can see on this chart, in Democratic party, presidential candidates are slowly but surely becoming more popular than their Congressional peers over last 30 years, changes in preferences of Republican electorate are more drastic.\n\n\nTask 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results\n\nUsing the data you downloaded earlier, create a chloropleth visualization of the electoral college results for the 2000 presidential election (Bush vs. Gore), coloring each state by the party that won the most votes in that state.\n\n\n\nShow the code\n# create a df with presidential election data\n\npres2000 &lt;- sqldf(\n  \"\n  with a as(\n  select year,state,state_po,\n  sum(case when party_simplified='DEMOCRAT' THEN candidatevotes else 0 end) as dem_votes,\n  sum(case when party_simplified='REPUBLICAN' THEN candidatevotes else 0 end) as rep_votes\n  from pres\n  where 1=1\n  and year=2000\n  and party_simplified in ('DEMOCRAT','REPUBLICAN')\n  group by 1,2,3\n  )\n  select year,\n  state_po,\n  dem_votes,\n  rep_votes,\n  case\n  when dem_votes&gt;rep_votes then 'Democrat' else 'Republican' end as party_won\n  from a\n  ;\n  \"\n)\n\n# create a df with ecv data\n\nhouse2000 &lt;- sqldf(\n  \"\n   with h20 as (\n   select\n   state_po,\n   max(district) as num_seats\n   from house\n   where 1=1\n   and year=2000\n   group by 1\n   )\n  ,\n  base as (\n   select\n   state_po,\n   case\n   when num_seats=0 then 1\n   else num_seats\n   end as number_of_seats2000\n   from h20\n  )\n  select\n  state_po,\n  number_of_seats2000+2 as ecv\n  from base\n    ;\n  \"\n)\n\n# join 2 dfs\necv20_df &lt;- inner_join(house2000, pres2000, by = c(\"state_po\" = \"state_po\"))\n\n## -get a shapefile of us states\n\ntd &lt;- tempdir()\nzip_contents_task5 &lt;- unzip(\"tl_2020_us_state.zip\",\n  exdir = td\n)\n\nfname_shp_task5 &lt;- zip_contents_task5[grepl(\"shp$\", zip_contents_task5)]\ncongress2020_sf &lt;- read_sf(fname_shp_task5)\n\n# subset data - we only need state abbreviations and coordinates\nstate_map1 &lt;- congress2020_sf |&gt;\n  select(STUSPS, geometry)\n\n# create a df with state boundaries and election data\nel20_for_map &lt;- inner_join(state_map1, ecv20_df, by = c(\"STUSPS\" = \"state_po\"))\n\n\n# create a plot for 2000 presidential election\nggplot(\n  el20_for_map,\n  aes(\n    geometry = geometry,\n    fill = party_won\n  )\n) +\n  geom_sf() +\n  scale_fill_manual(values = c(\n    \"Democrat\" = \"blue\",\n    \"Republican\" = \"red\"\n  ))\n\n\n\n\n\n\n\n\n\n\n\nTask 6: Advanced Chloropleth Visualization of Electoral College Results\n\nModify your previous code to make either a faceted version showing election results over time.\n\n\n\nShow the code\n# create a df with presidential election data\n\npres_elections_temp &lt;- pres |&gt;\n  filter(party_simplified == \"DEMOCRAT\" | party_simplified == \"REPUBLICAN\") |&gt;\n  group_by(year, state_po, party_simplified) |&gt;\n  summarize(votes = sum(candidatevotes))\n\n# head(pres_elections_temp)\n\npres_elections_temp2 &lt;- pivot_wider(pres_elections_temp,\n  # id_cols=(year,state_po),\n  names_from = party_simplified,\n  values_from = votes\n)\n\npres_elections_temp2 &lt;- pres_elections_temp2 |&gt;\n  mutate(party_won = case_when(DEMOCRAT &gt; REPUBLICAN ~ \"Democrat\", TRUE ~ \"Republican\"))\n\n\n# create a df with state boundaries and election data\nel20_for_map_overtime &lt;- inner_join(state_map1, pres_elections_temp2, by = c(\"STUSPS\" = \"state_po\"))\n\n\n\n# create a plot for 2000 presidential election\n\np1 &lt;- ggplot(\n  el20_for_map_overtime,\n  aes(\n    geometry = geometry,\n    fill = party_won\n  )\n) +\n  geom_sf() +\n  scale_fill_manual(values = c(\n    \"Democrat\" = \"blue\",\n    \"Republican\" = \"red\"\n  )) +\n  facet_wrap(~ factor(year), labeller = as_labeller(function(x) paste(\"year:\", x)), ncol = 1) +\n  theme(\n    strip.text = element_text(size = 24),\n    legend.text = element_text(size = 24), # Increase legend label text size\n    legend.title = element_text(size = 24), # Increase legend title text size\n    legend.key.size = unit(3, \"lines\")\n  )\n\np1\n\n\n\n\n\n\n\n\n\n\nTask 7: Evaluating Fairness of ECV Allocation Schemes\n\nWrite a fact check evaluating the fairness of the different ECV electoral allocation schemes. To do so, you should first determine which allocation scheme you consider “fairest”. You should then see which schemes give different results, if they ever do. To make your fact check more compelling, select one election where the ECV scheme had the largest impact–if one exists–and explain how the results would have been different under a different ECV scheme. As you perform your analysis, you may assume that the District of Columbia has three ECVs, which are allocated to the Democratic candidate under all schemes except possibly national popular vote."
  }
]